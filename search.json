[
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "proks-salehin-et-al",
    "section": "",
    "text": "Deep Learning Based Models for Preimplantation Mouse and Human Development"
  },
  {
    "objectID": "README.html#installation",
    "href": "README.html#installation",
    "title": "proks-salehin-et-al",
    "section": "1 Installation",
    "text": "1 Installation\nmamba env create -p /home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0 -f environment.yml\nPackage f2 has to be installed manually, follow these steps.\nNote: If you have issues with cuda make sure the loaded modules are on the same version as the pip jaxlib and nvidia-cudnn-cu11."
  },
  {
    "objectID": "README.html#running",
    "href": "README.html#running",
    "title": "proks-salehin-et-al",
    "section": "2 Running",
    "text": "2 Running\nmodule load cuda/11.8-dangpu cudnn/8.6.0-dangpu miniconda/latest && source activate brickman\njupyter-lab --no-browser"
  },
  {
    "objectID": "notebooks/00_figures_common.html",
    "href": "notebooks/00_figures_common.html",
    "title": "00 - Figures (common)",
    "section": "",
    "text": "%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport scvi\nfrom scvi.model import SCANVI\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport scanpy as sc\nimport cellrank as cr\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=UserWarning)\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\nplt.rcParams['svg.fonttype'] = 'none'\n%run ../scripts/helpers.py\ndef get_symbol(features: list[str]) -&gt; np.ndarray:\n    ENSG_to_SYMBOL = pd.read_csv('../data/external/human/Homo_sapiens.GRCh38.110.ENSG_to_SYMBOL.tsv', delimiter=\" \", header=None)\n    ENSG_to_SYMBOL.columns = ['ensembl','symbol']\n    ENSG_to_SYMBOL_noName = pd.read_csv('../data/external/human/Homo_sapiens.GRCh38.110.ENSG_to_SYMBOL_noName.tsv', delimiter=\" \", header=None)\n    nameless_df = pd.DataFrame(\n        data = {\n            'ensembl' : list(set(ENSG_to_SYMBOL_noName[0].tolist()) - set(ENSG_to_SYMBOL.ensembl.tolist())),\n            'symbol' : list(set(ENSG_to_SYMBOL_noName[0].tolist()) - set(ENSG_to_SYMBOL.ensembl.tolist())),\n        })\n    ENSG_to_SYMBOL = pd.concat([ENSG_to_SYMBOL, nameless_df])\n    ENSG_to_SYMBOL.set_index('ensembl', inplace=True)\n\n    df = pd.DataFrame(features, index=features, columns=['symbol'])\n    common_genes = features.intersection(ENSG_to_SYMBOL.index)\n    df.loc[common_genes, 'symbol'] = ENSG_to_SYMBOL.loc[common_genes, 'symbol']\n\n    return df.symbol.values\nmouse_ct_colors = {\n    'Zygote': '#7985A5',\n    '2C': '#B3C81E',\n    '4C': '#67BB30',\n    '8C': '#028A46',\n    '16C': '#657cbd',\n    'E3.25-ICM': '#fadc8f',\n    'E3.25-TE': '#5185b9',\n    'E3.5-ICM': '#f8d06a',\n    'E3.5-TE': '#7ba9d8',\n    'E3.5-EPI': '#c38cb0',\n    'E3.5-PrE': '#d97c81',\n    'E3.75-ICM': '#F6C445',\n    'E4.5-TE': '#5a94ce',\n    'E4.5-EPI': '#B46F9C',\n    'E4.5-PrE': '#D05B61'\n}\n\nhuman_ct_colors = {\n    'Prelineage': '#7985A5',\n    '8C_3.0': '#028A46',\n    'Morula_4.0': '#657cbd',\n    'Inner Cell Mass': '#F6C445',\n    'Primitive Endoderm': '#D05B61',\n    'Epiblast_6.0': '#d6b2ca',\n    'Epiblast_7.0': '#c38db1',\n    'Late epiblast': '#aa5c8f',\n    'Trophectoderm_5.0': '#cddff0',\n    'Trophectoderm_6.0': '#bdd4eb',\n    'Trophectoderm_7.0': '#acc9e6',\n    'Trophectoderm_8.0': '#9cbfe2',\n    'Trophectoderm_9.0': '#8bb4dd',\n    'Trophectoderm_10.0': '#5a94ce',\n    'Unknown': '#F1BD93',\n}\nsc.settings.figdir = '../figures/'\nsc.set_figure_params(dpi=120, dpi_save = 300, format='svg', transparent=True, figsize=(6,5))\nmouse = sc.read(\"../results/03_mouse.processed.h5ad\")\nmouse.obs.stage = mouse.obs.stage.astype('category').cat.reorder_categories(['Zygote', '2C', '4C', '8C', '16C', 'ICM', 'TE', 'EPI', 'PrE'])\nhuman = sc.read('../results/02_human_integration/05_scanvi_ns15/adata.h5ad')\nhuman.obs.C_scANVI_nsamples = human.obs.C_scANVI_nsamples.astype('category')\nhuman.obs.C_scANVI_nsamples = human.obs.C_scANVI_nsamples.cat.reorder_categories(list(human_ct_colors.keys())[:-1], ordered=True)"
  },
  {
    "objectID": "notebooks/00_figures_common.html#qc",
    "href": "notebooks/00_figures_common.html#qc",
    "title": "00 - Figures (common)",
    "section": "1 QC",
    "text": "1 QC\n\nfig, ax = plt.subplots(1, 4, figsize=[20, 4])\n\nqc_human = sc.read(\"../data/processed/32_human_adata.h5ad\")\n\nsc.pl.violin(mouse, 'n_genes_by_counts', jitter=0.4, show=False, ax=ax[0])\nsc.pl.violin(mouse, 'total_counts', jitter=0.4, show=False, ax=ax[1], c='black')\nsc.pl.violin(qc_human, 'n_genes', jitter=0.4, show=False, ax=ax[2])\nsc.pl.violin(qc_human, 'n_counts', jitter=0.4, show=False, ax=ax[3])\n\nfig.tight_layout()"
  },
  {
    "objectID": "notebooks/00_figures_common.html#suppl.-table-1-autotune",
    "href": "notebooks/00_figures_common.html#suppl.-table-1-autotune",
    "title": "00 - Figures (common)",
    "section": "2 Suppl. Table 1 (autotune)",
    "text": "2 Suppl. Table 1 (autotune)\n\nmouse_autotune = pd.read_csv(\"../results/02_mouse_integration/tunning.csv\", index_col=0)\nmouse_autotune['0'] = mouse_autotune['0'].fillna(0)\nmouse_autotune['1'] = mouse_autotune['1'].str.replace('gene_likelihood=', '')\nmouse_autotune['2'] = mouse_autotune['2'].str.replace('lr=', '')\nmouse_autotune['3'] = mouse_autotune['3'].str.replace('n_hidden=', '')\nmouse_autotune['4'] = mouse_autotune['4'].str.replace('n_layers=', '').str.split('_', expand=True)[0]\nmouse_autotune.columns=['Validation loss', 'Distribution', 'Learning Rate', 'Num. of layers', 'Num. of hidden layers']\n\nhuman_autotune = pd.read_csv(\"../results/02_human_integration/tunning.csv\", index_col=0)\nhuman_autotune['0'] = human_autotune['0'].fillna(0)\nhuman_autotune['1'] = human_autotune['1'].str.replace('gene_likelihood=', '')\nhuman_autotune['2'] = human_autotune['2'].str.replace('lr=', '')\nhuman_autotune['3'] = human_autotune['3'].str.replace('n_hidden=', '')\nhuman_autotune['4'] = human_autotune['4'].str.replace('n_layers=', '').str.split('_', expand=True)[0]\nhuman_autotune.columns=['Validation loss', 'Distribution', 'Learning Rate', 'Num. of layers', 'Num. of hidden layers']\n\nwriter = pd.ExcelWriter(\"../results/suppl-tab-1.xlsx\", engine=\"xlsxwriter\")\nmouse_autotune.to_excel(writer, sheet_name=\"mouse\")\nhuman_autotune.to_excel(writer, sheet_name=\"human\")\nwriter.close()"
  },
  {
    "objectID": "notebooks/00_figures_common.html#stats",
    "href": "notebooks/00_figures_common.html#stats",
    "title": "00 - Figures (common)",
    "section": "3 Stats",
    "text": "3 Stats\n\nmouse.obs['stats'] = mouse.obs.stage\n\nhuman.obs.experiment = human.obs.experiment.str.replace('_', ' et al., ').astype('category')\nhuman.obs['stats'] = human.obs['ct'].cat.rename_categories({\n    'Epiblast': 'EPI', 'Inner Cell Mass': 'ICM',\n    'Morula': '16C', 'Primitive Endoderm': 'PrE',\n    'Trophectoderm': 'TE'\n})\n\n\npub_stats = pd.concat([\n    mouse.obs.groupby(['experiment', 'stats']).apply(len).unstack().fillna(0).pipe(lambda df: df.loc[df.sum(axis=1).sort_values(ascending=False).index]),\n    human.obs.groupby(['experiment', 'stats']).apply(len).unstack().fillna(0).pipe(lambda df: df.loc[df.sum(axis=1).sort_values(ascending=False).index])\n])\npub_stats.sum(axis=1).plot(kind='bar', color='grey')\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.xticks(rotation=45, ha='right')\nplt.legend('', frameon=False)\n_ = plt.ylabel('Publications')\n_ = plt.xlabel('Number of cells')\n# plt.savefig(\"../figures/cells_per_publication.svg\")\n\n\npub_stats = pd.concat([\n    human.obs.groupby(['experiment', 'stats']).apply(len).unstack().fillna(0).pipe(lambda df: df.loc[df.sum(axis=1).sort_values(ascending=False).index]),\n    mouse.obs.groupby(['experiment', 'stats']).apply(len).unstack().fillna(0).pipe(lambda df: df.loc[df.sum(axis=1).sort_values(ascending=False).index]),\n])\npub_colors = np.concatenate([np.repeat('black', human.obs.experiment.cat.categories.size), np.repeat('grey', mouse.obs.experiment.cat.categories.size)])\npub_stats.sum(axis=1).plot(kind='barh', color=pub_colors)\nplt.gca().spines[['right', 'top']].set_visible(False)\n_ = plt.ylabel('Publications')\n_ = plt.xlabel('Number of cells')\n# plt.savefig(\"../figures/cells_per_publication.svg\")\n\n\npub_stats = pd.concat([\n    human.obs.groupby(['experiment', 'stats']).apply(len).unstack().fillna(0).pipe(lambda df: df.loc[df.sum(axis=1).sort_values(ascending=False).index]),\n    mouse.obs.groupby(['experiment', 'stats']).apply(len).unstack().fillna(0).pipe(lambda df: df.loc[df.sum(axis=1).sort_values(ascending=False).index]),\n])\n\nfig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [7, 1]})\npub_colors = np.concatenate([np.repeat('black', human.obs.experiment.cat.categories.size-1), np.repeat('grey', mouse.obs.experiment.cat.categories.size-1)])\npub_stats[~pub_stats.index.isin(['Nowotschin et al., 2019', 'Petropoulos et al., 2016'])].sum(axis=1).plot(kind='barh', color=pub_colors, ax=ax[0])\nax[0].spines[['right', 'top']].set_visible(False)\n_ = ax[0].set_ylabel('')\n\npub_stats.loc[['Petropoulos et al., 2016', 'Nowotschin et al., 2019']].sum(axis=1).plot(kind='barh', color=['black', 'grey'], ax=ax[1])\nplt.gca().spines[['right', 'top']].set_visible(False)\n_ = ax[1].set_ylabel('')\n\nfig.supxlabel('Number of cells')\nfig.supylabel('Experiments')\nfig.tight_layout()\n\n# plt.savefig(\"../figures/cells_per_publication.svg\")\n\n\nsns.barplot(x='experiment', y='technology', hue='dataset', data=technology_stats.reset_index())\n\n&lt;Axes: xlabel='experiment', ylabel='technology'&gt;\n\n\n\n\n\n\nhuman.obs.technology = human.obs.technology.cat.rename_categories(['SMART-seq', 'SMART-seq2', 'mRNA-seq'])\ntechnology_stats = mouse.obs.groupby('technology').count()[['experiment']].rename(columns={\"experiment\": \"mouse\"}).merge(\n    human.obs.groupby('technology').count()[['experiment']].rename(columns={\"experiment\": \"human\"}), \n    how='outer', left_index=True, right_index=True).fillna(0).loc[[\"SUPeR-seq\", \"mRNA-seq\", \"qRT-PCR\", \"SMART-seq\", \"10X 3' v2\", \"SMART-seq2\"]]\n\ntechnology_stats.plot(kind='barh', color=['black', 'grey'])\nfor idx, row in technology_stats.reset_index().iterrows():\n    if row['mouse'] != 0:\n        plt.annotate(str(int(row['mouse'])), xy=(row['mouse'] + 20, idx - 0.18), va='center')\n    if row['human'] != 0:\n        plt.annotate(str(int(row['human'])), xy=(row['human'] + 20, idx + 0.1), va='center')\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.legend(loc='lower right', frameon=False)\nplt.grid(False)\n_ = plt.ylabel('Technology')\n_ = plt.xlabel('Number of cells')\nplt.savefig(\"../figures/stats_technology.svg\")\n\n\n\n\n\n# experiment_stats = mouse.obs.groupby(['experiment', 'stage']).apply(len).unstack().fillna(0).iloc[::-1]\n# experiment_stats.plot(kind='barh', stacked=True)\n\n# for y, x in enumerate(experiment_stats.sum(axis=1).astype(int)):\n#     plt.annotate(str(x), xy=(x + 10, y), va='center')\n\n# plt.gca().spines[['right', 'top']].set_visible(False)\n# plt.xticks(rotation=45, ha='right')\n# plt.gca().legend(frameon=False)\n# _ = plt.ylabel('Publications')\n# _ = plt.xlabel('Number of cells')"
  },
  {
    "objectID": "notebooks/00_figures_common.html#scanvi-ns15-mouse-and-human",
    "href": "notebooks/00_figures_common.html#scanvi-ns15-mouse-and-human",
    "title": "00 - Figures (common)",
    "section": "4 scANVI ns[15] mouse and human",
    "text": "4 scANVI ns[15] mouse and human\n\nlvae_mouse = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\")\nlvae_human = scvi.model.SCANVI.load(\"../results/02_human_integration/05_scanvi_ns15/\")\n\n\nlvae_mouse.adata.obsm['X_scANVI'] = lvae_mouse.get_latent_representation()\nlvae_human.adata.obsm['X_scANVI'] = lvae_human.get_latent_representation()\n\n\nlvae_mouse.adata.obs[\"predictions\"] = lvae_mouse.predict()\nlvae_mouse.adata.obs.predictions = lvae_mouse.adata.obs.predictions.astype('category')\nlvae_mouse.adata.obs['entropy'] = 1 - lvae_mouse.predict(soft=True).max(axis=1)\n\nlvae_human.adata.obs[\"predictions\"] = lvae_human.predict()\nlvae_human.adata.obs.predictions = lvae_human.adata.obs.predictions.astype('category')\nlvae_human.adata.obs['entropy'] = 1 - lvae_human.predict(soft=True).max(axis=1)\n\n\nsc.pp.neighbors(lvae_mouse.adata, use_rep='X_scANVI')\nsc.tl.diffmap(lvae_mouse.adata)\nsc.tl.paga(lvae_mouse.adata, groups='predictions')\nsc.pl.paga(lvae_mouse.adata)\nsc.tl.draw_graph(lvae_mouse.adata, init_pos='paga', n_jobs=10)\n\nsc.pp.neighbors(lvae_human.adata, use_rep='X_scANVI')\nsc.tl.diffmap(lvae_human.adata)\nsc.tl.paga(lvae_human.adata, groups='predictions')\nsc.pl.paga(lvae_human.adata)\nsc.tl.draw_graph(lvae_human.adata, init_pos='paga', n_jobs=10)\n\n\nlvae_mouse.adata.obs.predictions = lvae_mouse.adata.obs.predictions.cat.reorder_categories(mouse_ct_colors.keys())\nlvae_human.adata.obs.predictions = lvae_human.adata.obs.predictions.cat.reorder_categories(list(human_ct_colors.keys())[:-1])\n\nlvae_mouse.adata.uns['predictions_colors'] = [mouse_ct_colors[ct] for ct in lvae_mouse.adata.obs.predictions.cat.categories]\nlvae_human.adata.uns['predictions_colors'] = [human_ct_colors[ct] for ct in lvae_human.adata.obs.predictions.cat.categories]\n\n\nsc.pl.draw_graph(lvae_mouse.adata, color='predictions', save=\"00_mouse_scANVI_ns15.svg\")\nsc.pl.draw_graph(lvae_human.adata, color='predictions', save=\"00_human_scANVI_ns15.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_common.html#shap-features-of-scanvi-classifiers",
    "href": "notebooks/00_figures_common.html#shap-features-of-scanvi-classifiers",
    "title": "00 - Figures (common)",
    "section": "5 SHAP features of scANVI classifiers",
    "text": "5 SHAP features of scANVI classifiers\n\n%run ../scripts/deep_scanvi.py\n\n\ndef get_shap_feature(adata: sc.AnnData, shaps: np.ndarray, clf_name: str, groupby: str = 'ct'):\n    \"\"\"\n    Generic helper function to extract SHAP features with their according expected value (weight).\n    adata: \n        scRNAseq dataset\n    shaps:\n        List of shap value (each index represents one cell type classifier)\n    clf_name:\n        Name of the classifier\n    \n    \"\"\"\n    result = []\n    \n    for idx, ct in enumerate(adata.obs[groupby].cat.categories):\n        vals = pd.DataFrame(shaps[idx], index=adata.obs_names, columns=adata.var_names)\n        vals['ct'] = adata.obs[groupby].cat.codes.values\n        vals = vals.query('ct == @idx').iloc[:, :-1]\n        \n        weights = vals\\\n            .mean(axis=0)\\\n            .sort_values(ascending=False)\\\n            .reset_index()\\\n            .rename(columns={'index':'feature',0:'weight'})\n            # .query('weight &gt; 0.5')\n        \n        weights['ct'] = adata.obs[groupby].cat.categories[idx]\n        result.append(weights)\n    \n    result = pd.concat(result)\n    result['clf'] = clf_name\n    \n    return result\n\n\ndef run_clf_scanvi(clf, clf_name: str, n: int=10, quantile: float = 0.75, groupby: str = 'ct') -&gt; pd.DataFrame:\n    \"\"\"\n    The objective is to gather SHAP features for N iterations. We are interested only\n    in features which appear N times, this way these features can be considered as conserved.\n    clf:\n       SCANVI object\n    clf_name:\n        name of the classifier\n    n:\n        Number of iterations\n    quantile:\n        Quantile cuttoff for weight\n    \"\"\"\n    results = []\n    \n    for i in tqdm(range(n)):\n        background_idx, background, test_idx, test = train_test_split_by_group_torch(clf.adata, groupby=groupby)\n        shap_values = SCANVIDeep(clf.module, background).shap_values(test)\n        weights = get_shap_feature(clf.adata[test_idx], shap_values, clf_name, groupby=groupby)\n        weights['iteration'] = i + 1\n        results.append(weights)\n    res = pd.concat(results)\n\n    # res_means = pd.DataFrame(res.query('weight &gt; 0').groupby(['ct', 'feature']).weight.mean())\n    # res_means['n'] = res.query('weight &gt; 0').groupby(['ct', 'feature']).count().loc[res_means.index, 'iteration']\n    # res_means = res_means.query('n == @n')\n    # res_th = res.query('weight &gt; 0').groupby(['clf', 'ct']).weight.quantile(quantile).unstack().T\n    # res_means = pd.merge(res_means.reset_index(), res_th, left_on='ct', right_index=True)\n    # res_means = res_means[res_means['weight'] &gt;= res_means[clf_name]]\n\n    return res\n\n\ndef filter_SHAP(ds_file: str, n: int = 10):\n\n    df = pd.read_feather(ds_file).query('weight &gt; 0')\n    df.feature = df.feature.str.capitalize()\n\n    filtered = df.groupby(['ct', 'feature']).count()[['iteration']].query('iteration == @n')\n    df_subset = df.set_index(['ct', 'feature']).loc[filtered.index].reset_index()\n    \n    filtered['weight_mean'] = df_subset.groupby(['ct', 'feature']).mean().loc[filtered.index, 'weight']\n    filtered['weight_std'] = df_subset.groupby(['ct', 'feature']).std().loc[filtered.index, 'weight']\n    filtered['weight_ci_upper'] = filtered.weight_mean + filtered.weight_std\n    filtered['weight_ci_lower'] = filtered.weight_mean - filtered.weight_std\n\n    return filtered\n\n\n5.1 Mouse\n\n# mouse_SHAP_scANVI = run_clf_scanvi(scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\"), 'scANVI_ns15', n=10)\n# mouse_SHAP_scANVI.reset_index(drop=True).to_feather(\"../results/00_mouse_scANVI_deepexplainer.feather\")\n\nmouse_SHAP_scANVI = pd.read_feather(\"../results/00_mouse_scANVI_deepexplainer.feather\")\n\nmouse.uns['log1p']['base'] = None\nsc.tl.rank_genes_groups(mouse, groupby='ct', n_genes=-1)\n\nmouse_SHAP_all = filter_SHAP(\"../results/00_mouse_scANVI_deepexplainer.feather\")\\\n    .sort_values('weight_mean', ascending=False)\\\n    .groupby('ct')\\\n    .head(-1)\\\n    .reset_index()\\\n    .set_index(['ct', 'feature'])\\\n    .loc[mouse.obs.ct.cat.categories]\n\nmouse_SHAP_top_3 = filter_SHAP(\"../results/00_mouse_scANVI_deepexplainer.feather\")\\\n    .sort_values('weight_mean', ascending=False)\\\n    .groupby('ct')\\\n    .head(3)\\\n    .reset_index()\\\n    .set_index(['ct', 'feature'])\\\n    .loc[mouse.obs.ct.cat.categories]\n\nWARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'\n\n\n\nfig, ax = plt.subplots(mouse.obs.ct.cat.categories.size, 1, figsize=[5, 20])\nfor idx, ct in enumerate(mouse.obs.ct.cat.categories):\n    ct_df = mouse_SHAP_top_3.loc[ct].sort_values(by='weight_mean')\n    ct_df['weight_mean'].plot.barh(ax=ax[idx], ylabel=ct, xerr=ct_df['weight_std'], color=mouse_ct_colors[ct], capsize=3)\nfig.tight_layout()\n\n\n\n\n\ndf_heatmap = pd.DataFrame(np.nan, \n                          index=mouse_SHAP_top_3.reset_index().feature.str.lower().values, \n                          columns=mouse.obs.ct.cat.categories)\nfor ct in df_heatmap.columns:\n    df = sc.get.rank_genes_groups_df(mouse, group=ct).set_index('names')\n    common_genes = df.index.intersection(mouse_SHAP_top_3.reset_index().feature.str.lower().values)\n    df_heatmap[ct] = df.loc[common_genes, 'logfoldchanges']\n\ng = sns.clustermap(\n    pd.DataFrame(MinMaxScaler(feature_range=(-1, 1)).fit_transform(df_heatmap.values), \n                     index=df_heatmap.index.str.capitalize(), columns=df_heatmap.columns).fillna(0),\n    cmap='RdBu_r', linewidth=.3, col_cluster=False, row_cluster=False, yticklabels=True,\n    row_colors=sum([[mouse_ct_colors[ct]] * 3 for ct in df_heatmap.columns], []),\n    cbar_pos=(.02, .32, .03, .2), figsize=(10,10)\n)\n_ = plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\ng.ax_heatmap.tick_params(axis='y', labelright=False, labelleft=True, right=False, left=True)\n\nax_row_colors = g.ax_row_colors\nbox = ax_row_colors.get_position()\nbox_heatmap = g.ax_heatmap.get_position()\nax_row_colors.set_position([box_heatmap.max[0], box.y0, box.width*1.5, box.height])\n# plt.savefig(\"../figures/mouse/00_SHAP_top3.svg\")\n\n\n\n\n\ndf_heatmap = pd.DataFrame(np.nan, \n                          index=mouse_SHAP_top_3.reset_index().feature.str.lower().values, \n                          columns=mouse.obs.ct.cat.categories)\nfor ct in df_heatmap.columns:\n    df = sc.get.rank_genes_groups_df(mouse, group=ct).set_index('names')\n    common_genes = df.index.intersection(mouse_SHAP_top_3.reset_index().feature.str.lower().values)\n    df_heatmap[ct] = df.loc[common_genes, 'logfoldchanges']\n\ndf_heatmap = pd.DataFrame(\n    MinMaxScaler(feature_range=(-1, 1)).fit_transform(df_heatmap.values), \n    index=df_heatmap.index.str.capitalize(), columns=df_heatmap.columns).fillna(0)\n\ndf_heatmap['group'] = sum([[mouse_ct_colors[ct]] * 3 for ct in df_heatmap.columns], [])\n\nn_categories = df_heatmap.shape[0] // 3\nfig, ax = plt.subplots(n_categories, 1, figsize=[20,20])\n\nfor idx in range(n_categories):\n    g = sns.heatmap(df_heatmap.iloc[idx*3: idx*3 + 3, :-1], cbar=None, vmin=-1, vmax=1, cmap='RdBu_r', ax=ax[idx], xticklabels=(idx == n_categories - 1), linewidth=.3)\n    for i, color in enumerate(df_heatmap.iloc[idx*3: idx*3 + 3, -1].values):\n        g.add_patch(plt.Rectangle(xy=(1.001, i), width=0.05, height=1, color=color, lw=0, transform=g.get_yaxis_transform(), clip_on=False))\n\nax[n_categories - 1].set_xticklabels(list(df_heatmap.columns[:-1]), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\nfig.tight_layout()\nplt.savefig(\"../figures/mouse/00_SHAP_top3_v2.svg\")\n\n\n\n\n\n# plt.figure(figsize=(12,8))\n# sns.heatmap(\n#     pd.DataFrame(MinMaxScaler(feature_range=(-1, 1)).fit_transform(df_heatmap.values), \n#                  index=df_heatmap.index, columns=df_heatmap.columns).fillna(0),\n#     cmap='viridis', linewidth=.5, yticklabels=True)\n\n# sns.clustermap(\n#     df_heatmap.fillna(0), \n#     z_score=0,\n#     dendrogram_ratio=(.1, .2),\n#     cmap='viridis', linewidths=.5, col_cluster=False, row_cluster=False, yticklabels=True,\n#     cbar_pos=(.02, .32, .03, .2), figsize=(10, 12),\n#     row_colors=sum([[mouse_ct_colors[ct]] * 3 for ct in df_heatmap.columns], []))\n\n\n\n5.2 Human\n\nlvae_human = scvi.model.SCANVI.load(\"../results/02_human_integration/05_scanvi_ns15/\")\n\nINFO     File ../results/02_human_integration/05_scanvi_ns15/model.pt already downloaded                           \n\n\n\n# human_SHAP_scANVI = run_clf_scanvi(lvae_human, 'scANVI_human', n=10, groupby='C_scANVI_nsamples')\n# human_SHAP_scANVI.reset_index(drop=True).to_feather(\"../results/00_human_scANVI_deepexplainer.feather\")\nhuman_SHAP_scANVI = pd.read_feather(\"../results/00_human_scANVI_deepexplainer.feather\")\n\nhuman.uns['log1p'] = {'base': None}\nsc.tl.rank_genes_groups(human, groupby='C_scANVI_nsamples', n_genes=-1)\n\nhuman_SHAP_all = filter_SHAP(\"../results/00_human_scANVI_deepexplainer.feather\")\\\n    .sort_values('weight_mean', ascending=False)\\\n    .groupby('ct')\\\n    .head(-1)\\\n    .reset_index()\\\n    .assign(feature = lambda x: x.feature.str.upper())\\\n    .set_index(['ct', 'feature'])\\\n    .loc[human.obs.C_scANVI_nsamples.cat.categories]\n\nhuman_SHAP_top_3 = filter_SHAP(\"../results/00_human_scANVI_deepexplainer.feather\")\\\n    .sort_values('weight_mean', ascending=False)\\\n    .groupby('ct')\\\n    .head(3)\\\n    .reset_index()\\\n    .assign(feature = lambda x: x.feature.str.upper())\\\n    .set_index(['ct', 'feature'])\\\n    .loc[human.obs.C_scANVI_nsamples.cat.categories]\n\nWARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'\n\n\n\n# human_SHAP_top_3 = human_SHAP_top_3.reset_index()\n# human_SHAP_top_3.feature = ENSG_to_SYMBOL.loc[human_SHAP_top_3.feature.str.upper(), 'symbol'].values\n# human_SHAP_top_3 = human_SHAP_top_3.set_index(['ct', 'feature'])\n\n\ndf_heatmap = pd.DataFrame(np.nan, \n                          index=human_SHAP_top_3.reset_index().feature.str.upper().values, \n                          columns=human.obs.C_scANVI_nsamples.cat.categories)\nfor ct in df_heatmap.columns:\n    df = sc.get.rank_genes_groups_df(human, group=ct).set_index('names')\n    common_genes = df.index.intersection(human_SHAP_top_3.index.get_level_values(1))\n    df_heatmap[ct] = df.loc[common_genes, 'logfoldchanges']\n\ng = sns.clustermap(\n    pd.DataFrame(MinMaxScaler(feature_range=(-1, 1)).fit_transform(df_heatmap.values), \n                     index=get_symbol(df_heatmap.index), columns=df_heatmap.columns).fillna(0),\n    cmap='RdBu_r', linewidth=.3, col_cluster=False, row_cluster=False, yticklabels=True,\n    row_colors=sum([[human_ct_colors[ct]] * 3 for ct in df_heatmap.columns], []),\n    cbar_pos=(.02, .32, .03, .2), figsize=(10,10)\n)\n_ = plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\ng.ax_heatmap.tick_params(axis='y', labelright=False, labelleft=True, right=False, left=True)\n\nax_row_colors = g.ax_row_colors\nbox = ax_row_colors.get_position()\nbox_heatmap = g.ax_heatmap.get_position()\nax_row_colors.set_position([box_heatmap.max[0], box.y0, box.width*1.5, box.height])\nplt.savefig(\"../figures/human/00_SHAP_top3.svg\")\n\n\ndf_heatmap = pd.DataFrame(np.nan, \n                          index=human_SHAP_top_3.reset_index().feature.str.upper().values, \n                          columns=human.obs.C_scANVI_nsamples.cat.categories)\nfor ct in df_heatmap.columns:\n    df = sc.get.rank_genes_groups_df(human, group=ct).set_index('names')\n    common_genes = df.index.intersection(human_SHAP_top_3.index.get_level_values(1))\n    df_heatmap[ct] = df.loc[common_genes, 'logfoldchanges']\n\ndf_heatmap = pd.DataFrame(\n    MinMaxScaler(feature_range=(-1, 1)).fit_transform(df_heatmap.values), \n    index=get_symbol(df_heatmap.index), columns=df_heatmap.columns).fillna(0)\n\ndf_heatmap['group'] = sum([[human_ct_colors[ct]] * 3 for ct in df_heatmap.columns], [])\n\nn_categories = df_heatmap.shape[0] // 3\nfig, ax = plt.subplots(n_categories, 1, figsize=[20,20])\n\nfor idx in range(n_categories):\n    g = sns.heatmap(df_heatmap.iloc[idx*3: idx*3 + 3, :-1], cbar=None, vmin=-1, vmax=1, cmap='RdBu_r', ax=ax[idx], xticklabels=(idx == n_categories - 1), linewidth=.3)\n    for i, color in enumerate(df_heatmap.iloc[idx*3: idx*3 + 3, -1].values):\n        g.add_patch(plt.Rectangle(xy=(1.001, i), width=0.05, height=1, color=color, lw=0, transform=g.get_yaxis_transform(), clip_on=False))\n\nax[n_categories - 1].set_xticklabels(list(df_heatmap.columns[:-1]), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\nfig.tight_layout()\nplt.savefig(\"../figures/human/00_SHAP_top3_v2.svg\")\n\n\n\n\n\n\n5.3 Suppl Table 4\n\nmouse_SHAP_all = filter_SHAP(\"../results/00_mouse_scANVI_deepexplainer.feather\")\\\n    .sort_values('weight_mean', ascending=False)\\\n    .groupby('ct')\\\n    .head(-1)\\\n    .reset_index()\\\n    .set_index(['ct', 'feature'])\\\n    .loc[mouse.obs.ct.cat.categories]\n\nhuman_SHAP_all = filter_SHAP(\"../results/00_human_scANVI_deepexplainer.feather\")\\\n    .sort_values('weight_mean', ascending=False)\\\n    .groupby('ct')\\\n    .head(-1)\\\n    .reset_index()\\\n    .assign(feature = lambda x: x.feature.str.upper())\\\n    .set_index(['ct', 'feature'])\\\n    .loc[human.obs.C_scANVI_nsamples.cat.categories]\\\n    .assign(symbol = get_symbol(human_SHAP_all.index.get_level_values(1)))\n\n\nwriter = pd.ExcelWriter(\"../results/suppl-tab-4.xlsx\", engine=\"xlsxwriter\")\nmouse_SHAP_all.reset_index().to_excel(writer, sheet_name=\"mouse\")\nhuman_SHAP_all.reset_index().to_excel(writer, sheet_name=\"human\")\nwriter.close()"
  },
  {
    "objectID": "notebooks/00_figures_common.html#diff.-expressed-genes",
    "href": "notebooks/00_figures_common.html#diff.-expressed-genes",
    "title": "00 - Figures (common)",
    "section": "6 Diff. expressed genes",
    "text": "6 Diff. expressed genes\n\ndef filter_markers(df: pd.DataFrame, n_genes: int = 5, upper: bool = False):\n    # significant only\n    df = df[\n        (df[\"is_de_fdr_0.05\"])\n        & (df[\"bayes_factor\"] &gt; 3)\n        & (df[\"non_zeros_proportion1\"] &gt; 0.1)\n        & (df[\"lfc_median\"] &gt; 0)\n    ]\n    comparisons = df.comparison.unique()\n\n    deg_df = {}\n    for comparison in comparisons:\n        cluster = comparison.split(\" \")[0]\n        markers = (\n            df.query(\"comparison == @comparison\")\n            .sort_values(by=\"lfc_median\", ascending=False)\n            .head(n_genes)\n        )\n        deg_df[cluster] = (\n            markers.index.str.upper().tolist() if upper else markers.index.tolist()\n        )\n\n    return deg_df\n\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi/\")\nm_ct = vae.differential_expression(groupby=\"ct\")\nm_ct_filt = filter_markers(m_ct, n_genes=100)\npd.DataFrame.from_dict(m_ct_filt, orient='index').transpose().to_csv(\"../results/00_mouse_ct_markers.csv\")\n\n\nm_ct = vae.differential_expression(groupby=\"stage\")\nm_ct_filt = filter_markers(m_ct, n_genes=10)\npd.DataFrame.from_dict(m_ct_filt, orient='index').transpose().to_csv(\"../results/00_mouse_stage_markers.csv\")"
  },
  {
    "objectID": "notebooks/00_figures_common.html#suppl.-table-5-query",
    "href": "notebooks/00_figures_common.html#suppl.-table-5-query",
    "title": "00 - Figures (common)",
    "section": "7 Suppl. Table 5 [query]",
    "text": "7 Suppl. Table 5 [query]\n\nwriter = pd.ExcelWriter(\"../results/suppl-tab-5.xlsx\", engine=\"xlsxwriter\")\npd.read_csv(\"../results/00_mouse_query.csv\", index_col=0).to_excel(writer, sheet_name=\"Mouse invitro\")\npd.read_csv(\"../results/00_human_query.csv\", index_col=0).to_excel(writer, sheet_name=\"Human invitro\")\nwriter.close()"
  },
  {
    "objectID": "notebooks/00_figures_common.html#suppl.-fig.-4",
    "href": "notebooks/00_figures_common.html#suppl.-fig.-4",
    "title": "00 - Figures (common)",
    "section": "8 Suppl. Fig. 4",
    "text": "8 Suppl. Fig. 4\n\nmouse_SHAP_top_3 = filter_SHAP(\"../results/00_mouse_scANVI_deepexplainer.feather\")\\\n    .sort_values('weight_mean', ascending=False)\\\n    .groupby('ct')\\\n    .head(3)\\\n    .reset_index()\\\n    .set_index(['ct', 'feature'])\\\n    .loc[mouse.obs.ct.cat.categories]\n\nhuman_SHAP_top_3 = filter_SHAP(\"../results/00_human_scANVI_deepexplainer.feather\")\\\n    .sort_values('weight_mean', ascending=False)\\\n    .groupby('ct')\\\n    .head(3)\\\n    .reset_index()\\\n    .assign(feature = lambda x: x.feature.str.upper())\\\n    .set_index(['ct', 'feature'])\\\n    .loc[human.obs.C_scANVI_nsamples.cat.categories]\n\n\ncats = mouse.obs.ct.cat.categories\nfig, ax = plt.subplots(5, 3, figsize=(11.69,8.27))\n\nfor idx, ct in enumerate(cats):\n    df = mouse_SHAP_top_3.loc[mouse_SHAP_top_3.index.get_level_values(0) == ct].reset_index().set_index('feature').sort_values(by='weight_mean', ascending=True)\n    df['weight_mean'].plot.barh(ylabel=ct, color=mouse_ct_colors[ct], ax=ax[idx // 3, idx % 3])\n    ax[idx // 3, idx % 3].errorbar(df['weight_mean'], df.index, xerr=df['weight_std'], color=\"black\", capthick=2, elinewidth=2,capsize=2, yerr = None, ls='none')\nfig.tight_layout()\nfig.savefig(\"../figures/mouse/00_SHAP_top3_bar.svg\")\n\n\ncats = human.obs.C_scANVI_nsamples.cat.categories\nfig, ax = plt.subplots(5, 3, figsize=(11.69,8.27))\n\nfor idx, ct in enumerate(cats):\n    df = human_SHAP_top_3.loc[human_SHAP_top_3.index.get_level_values(0) == ct].reset_index().set_index('feature').sort_values(by='weight_mean', ascending=True)\n    df.index = get_symbol(df.index)\n    df['weight_mean'].plot.barh(ylabel=ct, color=human_ct_colors[ct], ax=ax[idx // 3, idx % 3])\n    ax[idx // 3, idx % 3].errorbar(df['weight_mean'], df.index, xerr=df['weight_std'], color=\"black\", capthick=2, elinewidth=2,capsize=2, yerr = None, ls='none')\nfig.tight_layout()\nfig.savefig(\"../figures/human/00_SHAP_top3_bar.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_common.html#xgboost-vs-scanvi",
    "href": "notebooks/00_figures_common.html#xgboost-vs-scanvi",
    "title": "00 - Figures (common)",
    "section": "9 XGBoost vs scANVI",
    "text": "9 XGBoost vs scANVI\n\nstats = pd.read_excel(\"../results/suppl-tab-3.xlsx\", index_col=0)\n\nfig, ax = plt.subplots(1, 4, figsize=[14, 3.5], sharey=True, sharex=True)\n\nstats.query('clf == \"XGBoost\" & species == \"mouse\"').plot.line(marker='x', ylim=(-0.1,1), title='Mouse [XGBoost]', legend=None, ax=ax[0])\nstats.query('clf == \"scANVI\" & species == \"mouse\"').plot.line(marker='x', ylim=(-0.1,1), title='Mouse [scANVI]', legend=None, ax=ax[1])\nstats.query('clf == \"XGBoost\" & species == \"human\"').plot.line(marker='x', ylim=(-0.1,1), title='Human [XGBoost]', legend=None, ax=ax[2])\nstats.query('clf == \"scANVI\" & species == \"human\"').plot.line(marker='x', ylim=(-0.1,1), title='Human [scANVI]', legend=None, ax=ax[3])\n\nfor i in range(4):\n    ax[i].set_xticklabels(['', '0', '10', '20', '50', '100', '200', '500'])\n    ax[i].axhline(0.5, c='r', ls='--')\n\nax[3].legend(('Accuracy','Bal. accuracy', 'F1 (micro)', 'F1 (macro)'), ncol=4)\n\nfig.supxlabel('Number of dropouts')\nfig.supylabel('Prediction score')\nfig.tight_layout()\nfig.savefig('../figures/00_xgboost_vs_scanvi_v2.svg')"
  },
  {
    "objectID": "notebooks/00_figures_human.html",
    "href": "notebooks/00_figures_human.html",
    "title": "00 - Figures",
    "section": "",
    "text": "Figure 1\n\nFA plot\nPAGA\nPseudotime\nCelltype/Stage density\nCellRank\nMarkers (literature)\nDEGs\nLeiden clusters\nCelltype compositions\nscib (yosef lab)\n\nFig 2\n\nSchematics of different classifications\nSHAP values\n\nFig 3\n\nQuery datasets (in vitro)\nClassification predictions\nAUROC curves/Entropy\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport scvi\nimport scanpy as sc\nimport cellrank as cr\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nimport scvelo as scv\nscv.set_figure_params('scvelo')\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=UserWarning)\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\nfrom scvi.model import SCANVI\n%run ../scripts/helpers.py\nplt.rcParams['svg.fonttype'] = 'none'\n\nsc.settings.figdir = '../figures/human/'\nsc.set_figure_params(dpi=120, dpi_save = 300, format='svg', transparent=True, figsize=(6,5))\n\nscv.settings.figdir = '../figures/human/'\nscv.set_figure_params(dpi=120, dpi_save = 300, format='svg', transparent=True, figsize=(6,5))\nhuman = sc.read(\"../results/03_human.processed.h5ad\")"
  },
  {
    "objectID": "notebooks/00_figures_human.html#figures",
    "href": "notebooks/00_figures_human.html#figures",
    "title": "00 - Figures",
    "section": "1 Figures",
    "text": "1 Figures\n\nlineage_colors = {\n    'Oocyte': '#000000',\n    'Zygote': '#7985A5',\n    'Pronucleus': '#555d73',\n    '2C': '#B3C81E',\n    '4C': '#67BB30',\n    '8C': '#028A46',\n    'Morula': '#657cbd',\n    'ICM': '#F6C445',\n    'TE': '#5a94ce',\n    'EPI': '#B46F9C',\n    'PrE': '#D05B61',\n    'Unknown': '#F1BD93'\n}\n\nct_colors = {\n    'Prelineage': '#7985A5',\n    '8C_3.0': '#028A46',\n    'Morula_4.0': '#657cbd',\n    'Inner Cell Mass': '#F6C445',\n    'Primitive Endoderm': '#D05B61',\n    'Epiblast_6.0': '#d6b2ca',\n    'Epiblast_7.0': '#c38db1',\n    'Late epiblast': '#aa5c8f',\n    'Trophectoderm_5.0': '#cddff0',\n    'Trophectoderm_6.0': '#bdd4eb',\n    'Trophectoderm_7.0': '#acc9e6',\n    'Trophectoderm_8.0': '#9cbfe2',\n    'Trophectoderm_9.0': '#8bb4dd',\n    'Trophectoderm_10.0': '#5a94ce',\n    'Unknown': '#F1BD93',\n}\n\nextras = { 'add_outline': True, 'outline_width': (0.16, 0.02) }\nhuman.uns['stage_colors'] = [lineage_colors[x] for x in human.obs.stage.cat.categories]\nhuman.uns['ct_colors'] = [ct_colors[x] for x in human.obs.ct.cat.categories]\n\n\nsc.pp.neighbors(human, use_rep='X_scVI')\nsc.tl.diffmap(human)\nsc.tl.paga(human, groups='ct')\nsc.tl.draw_graph(human, init_pos='paga', n_jobs=10)\n\n2024-02-02 13:57:05.851053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"
  },
  {
    "objectID": "notebooks/00_figures_human.html#dr",
    "href": "notebooks/00_figures_human.html#dr",
    "title": "00 - Figures",
    "section": "2 DR",
    "text": "2 DR\n\nsc.pl.draw_graph(human, color=['stage', 'leiden', 'ct'], frameon=True, wspace=0.2, save=\"_dr_.svg\")\n\nWARNING: saving figure to file ../figures/human/draw_graph_fa_dr_.svg\n\n\n\n\n\n\nsc.pl.tsne(human, color=['stage', 'leiden', 'ct'], frameon=True, wspace=0.2, save=\"_dr_.svg\")\n\nWARNING: saving figure to file ../figures/human/tsne_dr_.svg\n\n\n\n\n\n\nsc.pl.umap(human, color=['stage', 'leiden', 'ct'], frameon=True, wspace=0.2, save=\"_dr_.svg\")\n\nWARNING: saving figure to file ../figures/human/umap_dr_.svg\n\n\n\n\n\n\n2.1 FA plot\n\nsc.pl.embedding(human, basis='X_draw_graph_fa', color=['stage'], title='', legend_loc=None,\n                frameon=False, **extras, save=\"_stage.svg\")\n\nWARNING: saving figure to file ../figures/human/X_draw_graph_fa_stage.svg\n\n\n\n\n\n\nsc.pl.embedding(human, basis='X_draw_graph_fa', color='leiden', title='', legend_loc='on data', legend_fontoutline=2,\n                frameon=False, **extras, save=\"_leiden.svg\")\n\nWARNING: saving figure to file ../figures/human/X_draw_graph_fa_leiden.svg\n\n\n\n\n\n\nsc.pl.embedding(human, basis='X_draw_graph_fa', color='leiden', title='', frameon=False, **extras, save=\"_leiden_2.svg\")\n\nWARNING: saving figure to file ../figures/human/X_draw_graph_fa_leiden_2.svg\n\n\n\n\n\n\nhuman.obs['t_scaled'] = MinMaxScaler().fit_transform(human.obs['t'].values.reshape(-1, 1)).flatten()\n\nsc.pl.embedding(human, basis='X_draw_graph_fa', color=['t_scaled', 'dpt_pseudotime'], title=['scFates pseudotime', 'dpt_pseudotime'], \n                legend_loc=None, colorbar_loc='right', frameon=True, cmap='viridis', **extras, save=\"_pseudotimes.svg\")\n\nWARNING: saving figure to file ../figures/human/X_draw_graph_fa_pseudotimes.svg\n\n\n\n\n\n\nsc.tl.embedding_density(human, basis='draw_graph_fa', groupby='stage')\nsc.pl.embedding_density(human, basis='draw_graph_fa', key='draw_graph_fa_density_stage', ncols=3, save='.svg')\n\nWARNING: saving figure to file ../figures/human/draw_graph_fa_density_stage_.svg\n\n\n\n\n\n\nsc.tl.embedding_density(human, basis='draw_graph_fa', groupby='ct')\nsc.pl.embedding_density(human, basis='draw_graph_fa', key='draw_graph_fa_density_ct', ncols=3, save='.svg')\n\nWARNING: saving figure to file ../figures/human/draw_graph_fa_density_ct_.svg\n\n\n\n\n\n\n\n2.2 PAGA\n\nscv.pl.paga(human, basis='draw_graph_fa', title=\"\", **extras, frameon=True, save=\"ct.svg\")\n\nWARNING: transitions_confidence not found, using connectivites instead.\nWARNING: Invalid color key. Using grey instead.\nsaving figure to file ../figures/human/scvelo_ct.svg\n\n\n\n\n\n\n\n2.3 scGEN\n\nhuman_scgen = sc.read(\"../results/02_human_integration/scgen/adata.h5ad\")\n\nsc.pp.neighbors(human_scgen, use_rep='X_scgen')\nsc.tl.diffmap(human_scgen)\nsc.tl.paga(human_scgen, groups='ct')\nsc.pl.paga(human_scgen)\nsc.tl.draw_graph(human_scgen, init_pos='paga', n_jobs=10)\n\n\n\n\n\nhuman_scgen.uns['stage_colors'] = list(lineage_colors.values())[1:] + [lineage_colors['Zygote']]\nsc.pl.embedding(human_scgen, basis='X_draw_graph_fa', color=['stage'], title='scGen',\n                **extras, save=\"_scgen_stage.svg\")\n\nWARNING: saving figure to file ../figures/human/X_draw_graph_fa_scgen_stage.svg"
  },
  {
    "objectID": "notebooks/00_figures_human.html#trajectory-segmentation",
    "href": "notebooks/00_figures_human.html#trajectory-segmentation",
    "title": "00 - Figures",
    "section": "3 Trajectory segmentation",
    "text": "3 Trajectory segmentation\n\nimport scFates as scf\n\n\n# with plt.rc_context({\"figure.figsize\": (6, 6)}):\nfig, ax = plt.subplots(1, 3, figsize=[18, 5])\nscf.pl.dendrogram(human,color=\"seg\", show=False, ax=ax[0])\nscf.pl.dendrogram(human,color=\"ct\", legend_loc=\"on data\", color_milestones=True, legend_fontoutline=True, show=False, ax=ax[1])\nsc.pl.embedding(human, basis='X_draw_graph_fa', color='seg', ax=ax[2])\nfig.tight_layout()\nfig.savefig(\"../figures/human/scfates.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_human.html#cellrank",
    "href": "notebooks/00_figures_human.html#cellrank",
    "title": "00 - Figures",
    "section": "4 CellRank",
    "text": "4 CellRank\n\nfrom cellrank.kernels import PseudotimeKernel\n\npk = PseudotimeKernel(human, time_key=\"t\")\npk.compute_transition_matrix()\ng = cr.estimators.GPCCA(pk)\ng.fit(cluster_key=\"stage\", n_states=[4, 12])\ng.predict_terminal_states(n_states=3)\ng.predict_initial_states(allow_overlap=True)\ng.compute_fate_probabilities()\n\n\nhuman.uns['clusters_gradients_colors'] = [lineage_colors['Zygote'], lineage_colors['TE'], lineage_colors['PrE'], lineage_colors['EPI']]\ng.plot_fate_probabilities(same_plot=True, basis='X_draw_graph_fa', **extras, legend_loc=False, save=\"human_terminal_stages.svg\")\n\n\ng.plot_fate_probabilities(same_plot=False, basis='X_draw_graph_fa', legend_loc=False, **extras, save=\"human_terminal_stages_all.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_human.html#stats-cell-compositions",
    "href": "notebooks/00_figures_human.html#stats-cell-compositions",
    "title": "00 - Figures",
    "section": "5 Stats: Cell compositions",
    "text": "5 Stats: Cell compositions\n\nexperiment_stats = human.obs.groupby(['experiment', 'stage']).apply(len).unstack().fillna(0).iloc[::-1]\nexperiment_stats.plot(kind='barh', stacked=True, color=lineage_colors)\n\nfor y, x in enumerate(experiment_stats.sum(axis=1).astype(int)):\n    plt.annotate(str(x), xy=(x + 10, y), va='center')\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(frameon=False)\n_ = plt.ylabel('Publications')\n_ = plt.xlabel('Number of cells')\nplt.savefig(\"../figures/human/stats_publications.svg\")\n\n\nlineage_stats = human.obs.groupby('stage').apply(len).iloc[::-1]\nlineage_stats.plot(kind='barh', color=list(lineage_colors.values()))\n\nfor y, x in enumerate(lineage_stats.astype(int)):\n    plt.annotate(str(x), xy=(x + 10, y), va='center')\n\nplt.gca().spines[['right', 'top']].set_visible(False)\n_ = plt.ylabel('Lineage')\n_ = plt.xlabel('Number of cells')\nplt.savefig(\"../figures/human/stats_stages.svg\")\n\n\nleiden_stats = sc.metrics.confusion_matrix('stage', 'leiden', data=human.obs) * 100\nleiden_stats.plot(kind='barh', stacked=True)\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(title='Clusters', bbox_to_anchor=(0.99, 1.02), loc='upper left', frameon=False)\n_ = plt.ylabel('Lineages')\n_ = plt.xlabel('Cluster %')\nplt.savefig(\"../figures/human/stats_cluster_vs_lineages.svg\")\n\n\nleiden_stats = sc.metrics.confusion_matrix('leiden', 'stage', data=human.obs) * 100\nleiden_stats.plot(kind='barh', stacked=True, color=lineage_colors)\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(title='Clusters', bbox_to_anchor=(0.99, 1.02), loc='upper left', frameon=False)\n_ = plt.ylabel('Lineages')\n_ = plt.xlabel('Cluster %')\nplt.savefig(\"../figures/human/stats_cluster_vs_lineages.svg\")\n\n\nsc.pl.embedding(human, basis='X_draw_graph_fa', color=['stage', 'leiden'], title='', frameon=False)\n\n\nleiden_stats = sc.metrics.confusion_matrix('leiden', 'stage', data=human.obs) * 100\nleiden_stats_order = ['17', '9', '1', '6', '15', '4', '2', '8', '0', '12', '11', '5', '16', '7', '3', '13', '10', '14']\nleiden_stats.loc[leiden_stats_order[::-1]].plot(kind='barh', stacked=True, color=lineage_colors)\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(title='Clusters', bbox_to_anchor=(0.99, 1.02), loc='upper left', frameon=False)\n_ = plt.ylabel('Lineages')\n_ = plt.xlabel('Cluster %')\nplt.savefig(\"../figures/human/stats_cluster_vs_lineages.svg\")\n\n\ntechnology_stats = human.obs.groupby('technology').apply(len).sort_values()\ntechnology_stats.plot(kind='barh', color='grey')\n\nfor y, x in enumerate(technology_stats.astype(int)):\n    plt.annotate(str(x), xy=(x + 10, y), va='center')\n\nplt.gca().spines[['right', 'top']].set_visible(False)\n_ = plt.ylabel('Technology')\n_ = plt.xlabel('Number of cells')\nplt.savefig(\"../figures/human/stats_technology.svg\")\n\n\nfig, ax = plt.subplots(1, 4, figsize=[20, 4])\n\n# Plot #1\nexperiment_stats = experiment_stats.loc[experiment_stats.sum(axis=1).sort_values().index.tolist()]\nexperiment_stats.plot(kind='barh', stacked=True, color=lineage_colors, ax=ax[0])\nfor y, x in enumerate(experiment_stats.sum(axis=1).astype(int)):\n    ax[0].annotate(str(x), xy=(x + 10, y), va='center')\nax[0].spines[['right', 'top']].set_visible(False)\nax[0].legend(frameon=False)\nax[0].set_ylabel('Publications')\nax[0].set_xlabel('Number of cells')\n\n# Plot #2\nlineage_stats = human.obs.groupby('stage').apply(len)\nlineage_stats.plot(kind='barh', color=list(lineage_colors.values()), ax=ax[1])\nfor y, x in enumerate(lineage_stats.astype(int)):\n    ax[1].annotate(str(x), xy=(x + 10, y), va='center')\nax[1].spines[['right', 'top']].set_visible(False)\nax[1].set_ylabel('Lineage')\nax[1].set_xlabel('Number of cells')\n\n# Plot #3\ntechnology_stats = human.obs.groupby('technology').apply(len).sort_values()\ntechnology_stats.plot(kind='barh', color='grey', ax=ax[2])\nfor y, x in enumerate(technology_stats.astype(int)):\n    ax[2].annotate(str(x), xy=(x + 10, y), va='center')\nax[2].spines[['right', 'top']].set_visible(False)\nax[2].set_ylabel('Technology')\nax[2].set_xlabel('Number of cells')\n\n# Plot #4\nleiden_stats = sc.metrics.confusion_matrix('leiden', 'stage', data=human.obs) * 100\nleiden_stats.plot(kind='barh', stacked=True, ax=ax[3])\nax[3].spines[['right', 'top']].set_visible(False)\nax[3].legend(title='Clusters', bbox_to_anchor=(0.99, 1.02), loc='upper left', frameon=False)\nax[3].set_ylabel('Lineages')\nax[3].set_xlabel('Cluster %')\n\nfig.tight_layout(w_pad=1)\nfig.savefig(\"../figures/human/stats_all.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_human.html#scvi-dges",
    "href": "notebooks/00_figures_human.html#scvi-dges",
    "title": "00 - Figures",
    "section": "6 SCVI DGEs",
    "text": "6 SCVI DGEs\n\nm_lineage = vae.differential_expression(groupby=\"stage\")\nm_lineage_filt = filter_markers(m_lineage, n_genes=10)\n\ndisplay(pd.DataFrame.from_dict(m_lineage_filt, orient='index').transpose())\n\nsc.pl.dotplot(human, m_lineage_filt, groupby='stage', dendrogram=False, standard_scale='var')\nsc.pl.matrixplot(human, m_lineage_filt, groupby='stage', dendrogram=False, standard_scale='var')"
  },
  {
    "objectID": "notebooks/00_figures_human.html#markers",
    "href": "notebooks/00_figures_human.html#markers",
    "title": "00 - Figures",
    "section": "7 Markers",
    "text": "7 Markers\n\nsc.pl.embedding(human, basis='X_draw_graph_fa', color=['t_scaled', 'day'], legend_loc=None, colorbar_loc='right', frameon=True, cmap='viridis')\n\n\n# vae = scvi.model.SCVI.load(\"../results/02_human_integration/scvi/\", human)\n\n\nENSG_to_SYMBOL = pd.read_csv('../data/external/human/Homo_sapiens.GRCh38.110.ENSG_to_SYMBOL.tsv', delimiter=\" \", header=None)\nENSG_to_SYMBOL.columns = ['ensembl','symbol']\nENSG_to_SYMBOL_noName = pd.read_csv('../data/external/human/Homo_sapiens.GRCh38.110.ENSG_to_SYMBOL_noName.tsv', delimiter=\" \", header=None)\nnameless_df = pd.DataFrame(\n    data = {\n        'ensembl' : list(set(ENSG_to_SYMBOL_noName[0].tolist()) - set(ENSG_to_SYMBOL.ensembl.tolist())),\n        'symbol' : list(set(ENSG_to_SYMBOL_noName[0].tolist()) - set(ENSG_to_SYMBOL.ensembl.tolist())),\n    })\nENSG_to_SYMBOL = pd.concat([ENSG_to_SYMBOL, nameless_df])\nENSG_to_SYMBOL.set_index('ensembl', inplace=True)\n\n\n# markers: \n# oocytes: https://www.sciencedirect.com/science/article/pii/S2451965021000417\n# everything: https://rep.bioscientifica.com/view/journals/rep/135/5/635.xml\n\nhuman_raw = human.raw.to_adata()\nhuman_raw = human_raw[human_raw.obs.stage != \"Unknown\"].copy()\nhuman_raw.var_names = ENSG_to_SYMBOL.loc[human_raw.var_names, 'symbol']\nhuman_raw.var_names_make_unique()\n\npub_markers = {\n    'Oocyte': ['DAZL', 'SOHLH2'],\n    'Zygote': ['PADI6', 'DDX4'],\n    'Pronucleus': ['ERBB4'],\n    '2C': ['ZFP3'],\n    '4C': ['SOX2'],\n    '8C': ['LEUTX', 'ZSCAN4'],\n    'Morula': ['FOXD3', 'GATA6'],\n    'ICM': ['KLF4'],\n    'TE': ['GATA3', 'CDX2'],\n    'EPI': ['KLF7', 'NANOG'],\n    'PrE': ['SOX17', 'GATA4'],\n    # 'Unknown': [],\n}\nax = sc.pl.dotplot(human_raw, sum(pub_markers.values(), []), groupby='stage', standard_scale='var', cmap='GnBu', figsize=[12, 3.5], show=False, use_raw=False)\n_ = ax['mainplot_ax'].set_xticklabels(sum(pub_markers.values(), []), rotation = 45, ha=\"right\", rotation_mode=\"anchor\")\nplt.savefig(\"../figures/human/dotplot_pub_markers.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_human.html#classifiers",
    "href": "notebooks/00_figures_human.html#classifiers",
    "title": "00 - Figures",
    "section": "8 Classifiers",
    "text": "8 Classifiers\n\nimport matplotlib.cm as cm\nfrom matplotlib.colors import Normalize\n\nhuman_adata = sc.read('../results/02_human_integration/05_scanvi_ns15/adata.h5ad')\nhuman_adata.obs.day = human_adata.obs.day.astype('category')\nhuman_adata.obs.ct_fine = human_adata.obs.ct_fine.cat.reorder_categories(ct_colors.keys(), ordered=True)\n\nhuman_adata.obs.C_scANVI_nsamples = human_adata.obs.C_scANVI_nsamples.cat.reorder_categories(list(ct_colors.keys())[:-1], ordered=True)\n\n\nfig, ax = plt.subplots(1, 3, figsize=[15, 5])\nCMAP = 'Reds'\n\ndf = pd.DataFrame(0, index=human_adata.obs.ct_fine.cat.categories, columns=human_adata.obs.ct_fine.cat.categories) + sc.metrics.confusion_matrix(\"ct_fine\", \"C_scANVI_nsamples\", human_adata.obs)\ndf = df[human_adata.obs.ct_fine.cat.categories]\ndf[df == 0] = np.nan\nsns.heatmap(df, linewidths=0.2, cmap=CMAP, ax=ax[0], square=True, cbar=None, linewidth=.5, linecolor='black')\\\n    .set(xlabel='', ylabel='', yticklabels=human_adata.obs.ct_fine.cat.categories.str.replace('_', ' '))\nax[0].set_xticklabels(df.columns.str.replace('_', ' '), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\nunknown_cells_adata = human_adata[human_adata.obs['ct_fine'].isin(['Unknown'])].copy()\nunknown_cells_adata.obs['day_str'] = unknown_cells_adata.obs['day'].astype(str)\ndf = sc.metrics.confusion_matrix(\"day_str\", \"C_scANVI_nsamples\", unknown_cells_adata.obs)\ndf = df[human_adata.obs.ct_fine.cat.categories.intersection(df.columns)]\ndf[df == 0] = np.nan\nsns.heatmap(df, linewidths=0.2, cmap=CMAP, ax=ax[1], square=True, cbar=None, linewidth=.5, linecolor='black').set(xlabel='', ylabel='')\nax[1].set_yticklabels(df.index, rotation=0, ha=\"right\", rotation_mode=\"anchor\")\nax[1].set_xticklabels(df.columns.str.replace('_', ' '), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\nknown_cells_adata = human_adata[~human_adata.obs['ct_fine'].isin(['Unknown'])].copy()\nknown_cells_adata.obs['day_str'] = known_cells_adata.obs['day'].astype(str)\ndf = sc.metrics.confusion_matrix(\"day_str\", \"C_scANVI_nsamples\", known_cells_adata.obs)\ndf = df[known_cells_adata.obs.ct_fine.cat.categories]\ndf[df == 0] = np.nan\nsns.heatmap(df, linewidths=0.2, cmap=CMAP, ax=ax[2], square=True, cbar=True, linewidth=.5, linecolor='black').set(xlabel='', ylabel='')\nax[2].set_yticklabels(df.index, rotation=0, ha=\"right\", rotation_mode=\"anchor\")\nax[2].set_xticklabels(df.columns.str.replace('_', ' '), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\nfig.supxlabel('Predicted')\nfig.supylabel('Observed')\nfig.tight_layout()\nfig.savefig(\"../figures/human/00_clf_confusion_mat.svg\")\n\n\n\n\n\n8.1 ICM re-annotation\n\nicm_adata = human_adata[human_adata.obs['ct_orig'].isin(['Inner Cell Mass', 'Primitive Endoderm', 'Epiblast'])].copy()\n\nicm_adata.uns['ct_fine_colors'] = [ct_colors[x] for x in icm_adata.obs.ct_fine.cat.categories]\nicm_adata.uns['C_scANVI_nsamples_colors'] = [ct_colors[x] for x in icm_adata.obs.C_scANVI_nsamples.cat.categories]\n\nsc.tl.pca(icm_adata, svd_solver='arpack')\nsc.pp.neighbors(icm_adata, use_rep='X_scVI')\nsc.tl.umap(icm_adata)\nsc.tl.leiden(icm_adata)\n\n\nfig = plt.figure(figsize=[12,10])\n\ngs = fig.add_gridspec(2,2)\nax1 = fig.add_subplot(gs[0, 0])\nax2 = fig.add_subplot(gs[0, 1])\nax3 = fig.add_subplot(gs[1, :])\n\nsc.pl.umap(icm_adata, color = 'ct_fine', ax=ax1, show=False, title='Original')\nsc.pl.umap(icm_adata, color = 'C_scANVI_nsamples', ax=ax2, show=False, title='Predicted')\nsc.metrics.confusion_matrix('ct_fine', 'C_scANVI_nsamples', icm_adata.obs).plot(kind='barh', stacked=True, ax=ax3, color=ct_colors, ylabel='Original', xlabel='Predicted', legend=None)\n\nfig.savefig(\"../figures/human/00_ICM_prediction.svg\")\n\n\n\n\n\ndf = pd.DataFrame(icm_adata.obsm['X_umap'], columns = ['UMAP1', 'UMAP2'])\\\n        .assign(Publication = icm_adata.obs.experiment.values)\\\n        .assign(Predictions = icm_adata.obs.C_scANVI_nsamples.values)\n\ng = sns.scatterplot(x='UMAP1', y='UMAP2', hue='Predictions', style='Publication', s=80, palette=ct_colors, linewidth=0, data=df)\ng.set(xticks=[], yticks=[], xticklabels=[])\nplt.savefig(\"../figures/human/00_ICM_prediction_2.svg\")\n\n\n\n\n\nfig, ax = plt.subplots(1,4, figsize=[20, 4])\n\nsc.metrics.confusion_matrix('ct_fine', 'C_scANVI_nsamples', icm_adata.obs).plot(kind='barh', stacked=True, ax=ax[0], color=ct_colors, ylabel='Original', xlabel='Predicted', legend=None)\nsc.pl.umap(icm_adata, color = 'ct_fine', show=False, title='Original', legend_loc=None, ax=ax[1])\nsc.pl.umap(icm_adata, color = 'C_scANVI_nsamples', show=False, title='Predicted', ax=ax[2])\nsc.pl.umap(icm_adata, color = 'day', show=False, title='Day', ax=ax[3])\nfig.savefig(\"../figures/human/00_ICM_prediction_suppl.svg\")\n\n\n\n\n\nsc.pl.umap(icm_adata, color = ['ENSG00000107485', 'ENSG00000171872', 'ENSG00000204531', 'ENSG00000181449','ENSG00000164736','ENSG00000111704'], \n           title=['GATA3', 'KLF17', 'POU5F1', 'SOX2', 'SOX17', 'NANOG'], ncols=3, save=\"00_ICM_prediction_suppl.svg\")\n\nWARNING: saving figure to file ../figures/human/umap00_ICM_prediction_suppl.svg\n\n\n\n\n\n\n# sc.pl.umap(icm_adata, color = ['ct_fine', 'ENSG00000107485', 'ENSG00000171872', 'ENSG00000204531', 'C_scANVI_nsamples', 'ENSG00000181449','ENSG00000164736','ENSG00000111704'], \n#            title=['Original annotation', 'GATA3', 'KLF17', 'POU5F1', 'Predicted', 'SOX2', 'SOX17', 'NANOG'], ncols=4, save=\"00_ICM_prediction_suppl.svg\", frameon=False, wspace=0.2)"
  },
  {
    "objectID": "notebooks/00_figures_human.html#c_scanvi_nsamples",
    "href": "notebooks/00_figures_human.html#c_scanvi_nsamples",
    "title": "00 - Figures",
    "section": "9 C_scANVI_nsamples",
    "text": "9 C_scANVI_nsamples\n\nimport scFates as scf\n\n\nhuman_scfates = human.copy()\nhuman_scfates.obs['C_scANVI_nsamples'] = scvi.model.SCANVI.load(\"../results/02_human_integration/05_scanvi_ns15/\").adata.obs.C_scANVI_nsamples\nhuman_scfates.uns['C_scANVI_nsamples_colors'] = [ct_colors[x] for x in human_scfates.obs.C_scANVI_nsamples.cat.categories]\n\nINFO     File ../results/02_human_integration/05_scanvi_ns15/model.pt already downloaded                           \n\n\n\nsc.tl.paga(human_scfates, groups='C_scANVI_nsamples')\nsc.pl.paga(human_scfates, color=['C_scANVI_nsamples'], frameon=False, fontoutline=True)\nsc.tl.draw_graph(human_scfates, init_pos='paga', n_jobs=10)\n\n\n\n\n\nsc.pp.neighbors(human_scfates, use_rep=\"X_scVI\")\nsc.tl.draw_graph(human_scfates, n_jobs=10, random_state=9)\n\n\nsig = scf.tl.explore_sigma(human_scfates,\n                         # Nodes=20,\n                         Nodes=60,\n                         use_rep=\"X_draw_graph_fa\",\n                         sigmas=[1000,500,400,300,200,100,50,10,1],\n                         seed=42,plot=True)\n\n\n\n\n\nscf.tl.tree(human_scfates,\n            # Nodes=30,\n            Nodes=70,\n            use_rep=\"X_draw_graph_fa\",\n            method=\"ppt\",\n            ppt_nsteps=10,\n            ppt_sigma=sig,\n            ppt_lambda=100,\n            seed=42)\n\ninferring a principal tree --&gt; parameters used \n    70 principal points, sigma = 500, lambda = 100, metric = euclidean\n    fitting: 100%|| 10/10 [00:00&lt;00:00, 249.68it/s]\n    not converged (error: 0.182933549445047)\n    finished (0:00:00) --&gt; added \n    .uns['ppt'], dictionnary containing inferred tree.\n    .obsm['X_R'] soft assignment of cells to principal points.\n    .uns['graph']['B'] adjacency matrix of the principal points.\n    .uns['graph']['F'] coordinates of principal points in representation space.\n\n\n\nscf.pl.graph(human_scfates)\n\n\n\n\n\nscf.tl.root(human_scfates, 68)\n\nnode 68 selected as a root --&gt; added\n    .uns['graph']['root'] selected root.\n    .uns['graph']['pp_info'] for each PP, its distance vs root and segment assignment.\n    .uns['graph']['pp_seg'] segments network information.\n\n\n\nscf.tl.pseudotime(human_scfates,n_jobs=10,n_map=10,seed=42)\n\nprojecting cells onto the principal graph\n    mappings: 100%|| 10/10 [00:15&lt;00:00,  1.53s/it]\n    finished (0:00:16) --&gt; added\n    .obs['edge'] assigned edge.\n    .obs['t'] pseudotime value.\n    .obs['seg'] segment of the tree assigned.\n    .obs['milestones'] milestone assigned.\n    .uns['pseudotime_list'] list of cell projection from all mappings.\n\n\n\nscf.pl.trajectory(human_scfates)\n\n\n\n\n\nsc.pl.draw_graph(human_scfates, color=['stage', 'seg', 'dpt_pseudotime', 't'], frameon=False, ncols=2, cmap='tab20')\n\n\n\n\n\nfig, ax = plt.subplots(1, 4, figsize=[25, 5])\n\nhuman_scfates.obs['t_scaled'] = MinMaxScaler().fit_transform(human_scfates.obs['t'].values.reshape(-1, 1)).flatten()\nscf.pl.dendrogram(human_scfates,color=\"seg\", show=False, ax=ax[0])\nscf.pl.dendrogram(human_scfates,color=\"C_scANVI_nsamples\",legend_loc=\"on data\",color_milestones=True,legend_fontoutline=True, show=False, ax=ax[1])\nsc.pl.embedding(human_scfates, basis='X_draw_graph_fa', color='seg', show=False, ax=ax[2])\nsc.pl.embedding(human_scfates, basis='X_draw_graph_fa', color='t_scaled', show=False, ax=ax[3], cmap='viridis')\n\n&lt;Axes: title={'center': 't_scaled'}, xlabel='X_FA1', ylabel='X_FA2'&gt;\n\n\n\n\n\n\nhuman_scfates.uns.keys()\n\ndict_keys(['_scvi_manager_uuid', '_scvi_uuid', 'ct_colors', 'ct_sizes', 'dendro_segments', 'diffmap_evals', 'draw_graph', 'draw_graph_fa_density_ct_params', 'experiment_colors', 'graph', 'hvg', 'iroot', 'leiden', 'milestones_colors', 'neighbors', 'paga', 'pca', 'ppt', 'pseudotime_list', 'stage_colors', 'timepoint_colors', 'tsne', 'umap', 'leiden_colors', 'draw_graph_fa_density_stage_params', 'C_scANVI_nsamples_colors', 'C_scANVI_nsamples_sizes', 'seg_colors'])\n\n\n\nfig, ax = plt.subplots(2, 3, figsize=[16, 8])\n\nsc.pl.embedding(human_scfates, basis='X_draw_graph_fa', color='C_scANVI_nsamples', show=False, ax=ax[0, 0], legend_loc=None)\nscv.pl.paga(human_scfates, basis='draw_graph_fa', title=\"\", frameon=True, show=False, ax=ax[0, 1])\nsc.pl.embedding(human_scfates, basis='X_draw_graph_fa', color='t_scaled', show=False, ax=ax[0, 2], cmap='viridis')\n\nscf.pl.dendrogram(human_scfates,color=\"seg\", show=False, ax=ax[1, 0])\nscf.pl.dendrogram(human_scfates,color=\"C_scANVI_nsamples\",legend_loc=\"on data\",color_milestones=True,legend_fontoutline=True, show=False, ax=ax[1, 1])\nsc.pl.embedding(human_scfates, basis='X_draw_graph_fa', color='seg', show=False, ax=ax[1, 2])\nfig.tight_layout()\nfig.savefig(\"../figures/human/00_C_scANVI_nsamples.svg\")\n\nWARNING: transitions_confidence not found, using connectivites instead.\nWARNING: Invalid color key. Using grey instead."
  },
  {
    "objectID": "notebooks/00_figures_human.html#query-rivron-et-al.",
    "href": "notebooks/00_figures_human.html#query-rivron-et-al.",
    "title": "00 - Figures",
    "section": "10 Query [Rivron et al.,]",
    "text": "10 Query [Rivron et al.,]\n\nlvae = scvi.model.SCANVI.load(\"../results/02_human_integration/05_scanvi_ns15/\")\n\nquery = sc.read_h5ad('../results/06_human_Rivron.h5ad')\nquery.obs['experiment'] = 'Rivron'\n\nscvi.model.SCVI.prepare_query_anndata(query, lvae)\nlvae_q = scvi.model.SCANVI.load_query_data(query, lvae)\nlvae_q.train(\n    max_epochs=100,\n    plan_kwargs=dict(weight_decay=0.0),\n    check_val_every_n_epoch=10,\n    early_stopping=True\n)\n\nquery.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nquery.obs[\"predictions\"] = lvae_q.predict()\nquery.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\nINFO     File ../results/02_human_integration/05_scanvi_ns15/model.pt already downloaded                           \nINFO     Found 100.0% reference vars in query data.                                                                \nINFO     Training for 100 epochs.                                                                                  \nEpoch 100/100: 100%|| 100/100 [00:20&lt;00:00,  5.47it/s, v_num=1, train_loss_step=4.71e+3, train_loss_epoch=4.74e+3]Epoch 100/100: 100%|| 100/100 [00:20&lt;00:00,  4.80it/s, v_num=1, train_loss_step=4.71e+3, train_loss_epoch=4.74e+3]\n\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n\n\n\nsc.pp.highly_variable_genes(\n    query,\n    flavor=\"seurat_v3\",\n    n_top_genes=5_000,\n    layer=\"counts\",\n    batch_key=\"batch\",\n    subset=True,\n)\nsc.pp.neighbors(query)\nsc.tl.umap(query)\nquery.obs.predictions = query.obs.predictions.astype('category')\nquery.obs.predictions = query.obs.predictions.cat.reorder_categories([ct for ct in ct_colors if ct in query.obs.predictions.cat.categories], ordered=True)\n\nWARNING: Youre trying to run this on 3000 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n         Falling back to preprocessing with `sc.pp.pca` and default params.\n\n\n\nquery.uns['flow_colors'] = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#D3D3D3', '#8c564b']\nquery.uns['predictions_colors'] = [ct_colors[ct] for ct in query.obs.predictions.cat.categories]\n\n\nsc.pl.umap(query, color=['flow', 'time', 'predictions', 'entropy'], ncols=2, vmax=1, cmap='viridis', title=['FACS', 'Stage', 'Prediction', 'Entropy'],\n           save='00_query_rivron.svg')\n\nWARNING: saving figure to file ../figures/human/umap00_query_rivron.svg\n\n\n\n\n\n\npd.crosstab(query.obs.predictions, query.obs.flow)\n\n\n\n\n\n\n\nflow\nDouble-neg\nPDGFRA+\nTROP2+\nTROP2-\nna\nnaive\n\n\npredictions\n\n\n\n\n\n\n\n\n\n\n8C_3.0\n1\n0\n0\n1\n0\n0\n\n\nMorula_4.0\n1\n0\n0\n0\n0\n0\n\n\nInner Cell Mass\n0\n1\n0\n0\n0\n0\n\n\nPrimitive Endoderm\n33\n121\n33\n34\n17\n5\n\n\nEpiblast_6.0\n141\n7\n44\n81\n65\n42\n\n\nEpiblast_7.0\n89\n7\n73\n47\n74\n32\n\n\nLate epiblast\n160\n15\n47\n33\n51\n56\n\n\nTrophectoderm_5.0\n0\n0\n1\n0\n4\n0\n\n\nTrophectoderm_6.0\n4\n0\n76\n5\n7\n1\n\n\nTrophectoderm_7.0\n14\n0\n125\n1\n1\n0\n\n\nTrophectoderm_8.0\n14\n2\n55\n0\n0\n1\n\n\nTrophectoderm_9.0\n8\n0\n123\n0\n0\n1\n\n\nTrophectoderm_10.0\n3\n0\n5\n0\n0\n0\n\n\n\n\n\n\n\n\nconf_mat = sc.metrics.confusion_matrix('flow', 'predictions', query.obs) * 100\nconf_mat.index = ['Double-negative', 'PDGFRA+', 'TROP2+', 'TROP2-', 'Unknown', 'Naive']\nconf_mat.plot.barh(stacked=True, color=ct_colors)\nplt.legend(conf_mat.columns.str.replace('_', ' '), loc='center right', bbox_to_anchor=(1.42, 0.5), frameon=False)\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.xlabel('% of cells')\nplt.ylabel('FACS labeled cells')\nplt.title('in vitro human blastoid conpositional prediction')\n\nplt.savefig(\"../figures/human/00_query_flow_predictions.svg\")\nsc.metrics.confusion_matrix('flow', 'predictions', query.obs, normalize=False).to_csv(\"../results/00_human_query.csv\")\n\n\n\n\n\npd.crosstab(query.obs.predictions, query.obs.time)\n\n\n\n\n\n\n\ntime\n0h\n24h\n60h\n96h\n\n\npredictions\n\n\n\n\n\n\n\n\n8C_3.0\n0\n0\n1\n1\n\n\nMorula_4.0\n0\n0\n0\n1\n\n\nInner Cell Mass\n0\n0\n1\n0\n\n\nPrimitive Endoderm\n5\n17\n63\n158\n\n\nEpiblast_6.0\n42\n65\n116\n157\n\n\nEpiblast_7.0\n32\n74\n96\n120\n\n\nLate epiblast\n56\n51\n54\n201\n\n\nTrophectoderm_5.0\n0\n4\n1\n0\n\n\nTrophectoderm_6.0\n1\n7\n64\n21\n\n\nTrophectoderm_7.0\n0\n1\n29\n111\n\n\nTrophectoderm_8.0\n1\n0\n6\n65\n\n\nTrophectoderm_9.0\n1\n0\n6\n125\n\n\nTrophectoderm_10.0\n0\n0\n1\n7"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html",
    "href": "notebooks/00_figures_mouse.html",
    "title": "00 - Figures",
    "section": "",
    "text": "Figure 1\n\nFA plot\nPAGA\nPseudotime\nCelltype/Stage density\nCellRank\nMarkers (literature)\nDEGs\nLeiden clusters\nCelltype compositions\nscib (yosef lab)\n\nFig 2\n\nSchematics of different classifications\nSHAP values\n\nFig 3\n\nQuery datasets (in vitro)\nClassification predictions\nAUROC curves/Entropy\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport scvi\nimport scanpy as sc\nimport cellrank as cr\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nimport scvelo as scv\nscv.set_figure_params('scvelo')\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=UserWarning)\nfrom scvi.model import SCANVI\n%run ../scripts/helpers.py\nplt.rcParams['svg.fonttype'] = 'none'\n\nsc.settings.figdir = '../figures/mouse/'\nsc.set_figure_params(dpi=120, dpi_save = 300, format='svg', transparent=True, figsize=(6,5))\n\nscv.settings.figdir = '../figures/mouse/'\nscv.set_figure_params(dpi=120, dpi_save = 300, format='svg', transparent=True, figsize=(6,5))\nmouse = sc.read(\"../results/03_mouse.processed.h5ad\")\nmouse.obs.stage = mouse.obs.stage.astype('category').cat.reorder_categories(['Zygote', '2C', '4C', '8C', '16C', 'ICM', 'TE', 'EPI', 'PrE'])"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#oocyte-counts",
    "href": "notebooks/00_figures_mouse.html#oocyte-counts",
    "title": "00 - Figures",
    "section": "1 Oocyte counts",
    "text": "1 Oocyte counts\n\nBorensztein contains 32 and 64 cell cells (also contains oocytes, how many?)\nDeng # of occytes\nXu et al., oocyte + pronuclear\n\n\nn_oocytes = 0\n\n\nborenszrtein_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE80nnn/GSE80810/matrix/GSE80810_series_matrix.txt.gz\",\n                                      skiprows=31, index_col=0).T\nborenszrtein_metadata['SRX'] = borenszrtein_metadata[['!Sample_relation']].iloc[:, :2].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\nborenszrtein_metadata['ct'] = borenszrtein_metadata['!Sample_characteristics_ch1'].iloc[:, 1].values\nborenszrtein_metadata = borenszrtein_metadata.reset_index()\n\n\ndeng_oocytes = ['GSM1112766', 'GSM1112767', 'GSM1112768', 'GSM1112769']\n\n\nxue_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE44nnn/GSE44183/matrix/GSE44183-GPL13112_series_matrix.txt.gz\",\n                               skiprows=35, index_col=0).T\nxue_metadata['SRX'] = xue_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\nxue_metadata['ct'] = xue_metadata['!Sample_source_name_ch1']\nxue_metadata = xue_metadata.reset_index()\n\n\nn_oocytes += borenszrtein_metadata[borenszrtein_metadata.ct.str.contains('Oocyte')].shape[0]\nn_oocytes += len(deng_oocytes)\nn_oocytes += xue_metadata[xue_metadata.ct == 'oocyte'].shape[0]\n\n\nprint(f'Number of Oocytes in from experiments: {n_oocytes}')\n\n\nmouse.obs.ct.value_counts()"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#figures",
    "href": "notebooks/00_figures_mouse.html#figures",
    "title": "00 - Figures",
    "section": "2 Figures",
    "text": "2 Figures\n\n# lineage_colors = {\n#     'Zygote': '#a24f99',\n#     '2C': '#55ae6c',\n#     '4C': '#93b43e',\n#     '8C': '#ba4a50',\n#     '16C': '#657cbd',\n#     'ICM': '#ffcb5d',\n#     'TE': '#5a94ce',\n#     'EPI': '#d22a45',\n#     'PrE': '#a377b4'\n# }\nlineage_colors = {\n    'Zygote': '#7985A5',\n    '2C': '#B3C81E',\n    '4C': '#67BB30',\n    '8C': '#028A46',\n    '16C': '#657cbd',\n    'ICM': '#F6C445',\n    'TE': '#5a94ce',\n    'EPI': '#B46F9C',\n    'PrE': '#D05B61'\n}\n\n# ct_colors = {\n#     'Zygote': '#7985A5',\n#     '2C': '#B3C81E',\n#     '4C': '#67BB30',\n#     '8C': '#028A46',\n#     '16C': '#657cbd',\n#     'E3.25-ICM': '#e5b653',\n#     'E3.25-TE': '#5185b9',\n#     'E3.5-ICM': '#cca24a',\n#     'E3.5-TE': '#406a94',\n#     'E3.5-EPI': '#bd253e',\n#     'E3.5-PrE': '#926ba2',\n#     'E3.75-ICM': '#F6C445',\n#     'E4.5-TE': '#5a94ce',\n#     'E4.5-EPI': '#B46F9C',\n#     'E4.5-PrE': '#D05B61'\n# }\nct_colors = {\n    'Zygote': '#7985A5',\n    '2C': '#B3C81E',\n    '4C': '#67BB30',\n    '8C': '#028A46',\n    '16C': '#657cbd',\n    'E3.25-ICM': '#fadc8f',\n    'E3.25-TE': '#5185b9',\n    'E3.5-ICM': '#f8d06a',\n    'E3.5-TE': '#7ba9d8',\n    'E3.5-EPI': '#c38cb0',\n    'E3.5-PrE': '#d97c81',\n    'E3.75-ICM': '#F6C445',\n    'E4.5-TE': '#5a94ce',\n    'E4.5-EPI': '#B46F9C',\n    'E4.5-PrE': '#D05B61'\n}\n\nextras = { 'add_outline': True, 'outline_width': (0.16, 0.02) }\n\nmouse.uns['stage_colors'] = list(lineage_colors.values())\nmouse.uns['ct_colors'] = list(ct_colors.values())\n\n\nsc.pp.neighbors(mouse, use_rep='X_scVI')\nsc.tl.diffmap(mouse)\nsc.tl.paga(mouse, groups='ct')\nsc.tl.draw_graph(mouse, init_pos='paga', n_jobs=10)\n\n\nsc.pl.draw_graph(mouse, color=['stage', 'timepoint', 'ct'], frameon=True, wspace=0.2)"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#dr",
    "href": "notebooks/00_figures_mouse.html#dr",
    "title": "00 - Figures",
    "section": "3 DR",
    "text": "3 DR\n\nsc.pl.draw_graph(mouse, color=['stage', 'leiden', 'ct'], frameon=True, wspace=0.2, save=\"_dr_.svg\")\n\n\nsc.pl.tsne(mouse, color=['stage', 'leiden', 'ct'], frameon=True, wspace=0.2, save=\"_dr_.svg\")\n\n\nsc.pl.umap(mouse, color=['stage', 'leiden', 'ct'], frameon=True, wspace=0.2, save=\"_dr_.svg\")\n\n\n3.1 FA plot\n\nsc.pl.embedding(mouse, basis='X_draw_graph_fa', color=['stage'], title='', legend_loc=None,\n                frameon=False, **extras, save=\"_stage.svg\")\n\n\nsc.pl.embedding(mouse, basis='X_draw_graph_fa', color='leiden', title='', legend_loc='on data', legend_fontoutline=2,\n                frameon=False, **extras, save=\"_leiden.svg\")\n\n\nsc.pl.embedding(mouse, basis='X_draw_graph_fa', color='leiden', title='', frameon=False, **extras, save=\"_leiden_2.svg\")\n\n\nmouse.obs['t_scaled'] = MinMaxScaler().fit_transform(mouse.obs['t'].values.reshape(-1, 1)).flatten()\n\nsc.pl.embedding(mouse, basis='X_draw_graph_fa', color=['t_scaled', 'dpt_pseudotime'], title=['scFates pseudotime', 'dpt_pseudotime'], \n                legend_loc=None, colorbar_loc='right', frameon=True, cmap='viridis', **extras, save=\"_pseudotimes.svg\")\n\n\nsc.tl.embedding_density(mouse, basis='draw_graph_fa', groupby='stage')\nsc.pl.embedding_density(mouse, basis='draw_graph_fa', key='draw_graph_fa_density_stage', ncols=3, save='.svg')\n\n\nsc.tl.embedding_density(mouse, basis='draw_graph_fa', groupby='ct')\nsc.pl.embedding_density(mouse, basis='draw_graph_fa', key='draw_graph_fa_density_ct', ncols=3, save='.svg')\n\n\n\n3.2 PAGA\n\nscv.pl.paga(mouse, basis='draw_graph_fa', title=\"\", **extras, frameon=True, save=\"ct.svg\")\n\n\n\n3.3 scGEN\n\nmouse_scgen = sc.read(\"../results/02_mouse_integration/scgen/adata.h5ad\")\n\nsc.pp.neighbors(mouse_scgen, use_rep='X_scgen')\nsc.tl.diffmap(mouse_scgen)\nsc.tl.paga(mouse_scgen, groups='ct')\nsc.pl.paga(mouse_scgen)\nsc.tl.draw_graph(mouse_scgen, init_pos='paga', n_jobs=10)\n\n\nmouse_scgen.uns['stage_colors'] = list(lineage_colors.values())[1:] + [lineage_colors['Zygote']]\nsc.pl.embedding(mouse_scgen, basis='X_draw_graph_fa', color=['stage'], title='scGen',\n                **extras, save=\"_scgen_stage.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#trajectory-segmentation",
    "href": "notebooks/00_figures_mouse.html#trajectory-segmentation",
    "title": "00 - Figures",
    "section": "4 Trajectory segmentation",
    "text": "4 Trajectory segmentation\n\nimport scFates as scf\n\n\n# with plt.rc_context({\"figure.figsize\": (6, 6)}):\nfig, ax = plt.subplots(1, 3, figsize=[18, 5])\nscf.pl.dendrogram(mouse,color=\"seg\", show=False, ax=ax[0])\nscf.pl.dendrogram(mouse,color=\"ct\", legend_loc=\"on data\", color_milestones=True, legend_fontoutline=True, show=False, ax=ax[1])\nsc.pl.embedding(mouse, basis='X_draw_graph_fa', color='seg', ax=ax[2])\nfig.tight_layout()\nfig.savefig(\"../figures/mouse/scfates.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#cellrank",
    "href": "notebooks/00_figures_mouse.html#cellrank",
    "title": "00 - Figures",
    "section": "5 CellRank",
    "text": "5 CellRank\n\nfrom cellrank.kernels import PseudotimeKernel\n\npk = PseudotimeKernel(mouse, time_key=\"t\")\npk.compute_transition_matrix()\ng = cr.estimators.GPCCA(pk)\ng.fit(cluster_key=\"stage\", n_states=[4, 12])\ng.predict_terminal_states(n_states=3)\ng.predict_initial_states(allow_overlap=True)\ng.compute_fate_probabilities()\n\n\nmouse.uns['clusters_gradients_colors'] = [lineage_colors['Zygote'], lineage_colors['TE'], lineage_colors['PrE'], lineage_colors['EPI']]\ng.plot_fate_probabilities(same_plot=True, basis='X_draw_graph_fa', **extras, legend_loc=False, save=\"mouse_terminal_stages.svg\")\n\n\ng.plot_fate_probabilities(same_plot=False, basis='X_draw_graph_fa', legend_loc=False, **extras, save=\"mouse_terminal_stages_all.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#stats-cell-compositions",
    "href": "notebooks/00_figures_mouse.html#stats-cell-compositions",
    "title": "00 - Figures",
    "section": "6 Stats: Cell compositions",
    "text": "6 Stats: Cell compositions\n\nexperiment_stats = mouse.obs.groupby(['experiment', 'stage']).apply(len).unstack().fillna(0).iloc[::-1]\nexperiment_stats.plot(kind='barh', stacked=True, color=lineage_colors)\n\nfor y, x in enumerate(experiment_stats.sum(axis=1).astype(int)):\n    plt.annotate(str(x), xy=(x + 10, y), va='center')\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(frameon=False)\n_ = plt.ylabel('Publications')\n_ = plt.xlabel('Number of cells')\nplt.savefig(\"../figures/mouse/stats_publications.svg\")\n\n\nlineage_stats = mouse.obs.groupby('stage').apply(len).iloc[::-1]\nlineage_stats.plot(kind='barh', color=list(lineage_colors.values()))\n\nfor y, x in enumerate(lineage_stats.astype(int)):\n    plt.annotate(str(x), xy=(x + 10, y), va='center')\n\nplt.gca().spines[['right', 'top']].set_visible(False)\n_ = plt.ylabel('Lineage')\n_ = plt.xlabel('Number of cells')\nplt.savefig(\"../figures/mouse/stats_stages.svg\")\n\n\nleiden_stats = sc.metrics.confusion_matrix('stage', 'leiden', data=mouse.obs) * 100\nleiden_stats.plot(kind='barh', stacked=True)\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(title='Clusters', bbox_to_anchor=(0.99, 1.02), loc='upper left', frameon=False)\n_ = plt.ylabel('Lineages')\n_ = plt.xlabel('Cluster %')\nplt.savefig(\"../figures/mouse/stats_cluster_vs_lineages.svg\")\n\n\nleiden_stats = sc.metrics.confusion_matrix('leiden', 'stage', data=mouse.obs) * 100\nleiden_stats.plot(kind='barh', stacked=True, color=lineage_colors)\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(title='Clusters', bbox_to_anchor=(0.99, 1.02), loc='upper left', frameon=False)\n_ = plt.ylabel('Lineages')\n_ = plt.xlabel('Cluster %')\nplt.savefig(\"../figures/mouse/stats_cluster_vs_lineages.svg\")\n\n\nsc.pl.embedding(mouse, basis='X_draw_graph_fa', color=['stage', 'leiden'], title='', frameon=False)\n\n\nleiden_stats = sc.metrics.confusion_matrix('leiden', 'stage', data=mouse.obs) * 100\nleiden_stats_order = ['13', '12', '7', '1', '11', '6', '0', '14', '2', '5', '4', '9', '8', '3', '10']\nleiden_stats.loc[leiden_stats_order[::-1]].plot(kind='barh', stacked=True, color=lineage_colors)\n\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(title='Clusters', bbox_to_anchor=(0.99, 1.02), loc='upper left', frameon=False)\n_ = plt.ylabel('Lineages')\n_ = plt.xlabel('Cluster %')\nplt.savefig(\"../figures/mouse/stats_cluster_vs_lineages.svg\")\n\n\ntechnology_stats = mouse.obs.groupby('technology').apply(len).sort_values()\ntechnology_stats.plot(kind='barh', color='grey')\n\nfor y, x in enumerate(technology_stats.astype(int)):\n    plt.annotate(str(x), xy=(x + 10, y), va='center')\n\nplt.gca().spines[['right', 'top']].set_visible(False)\n_ = plt.ylabel('Technology')\n_ = plt.xlabel('Number of cells')\nplt.savefig(\"../figures/mouse/stats_technology.svg\")\n\n\nfig, ax = plt.subplots(1, 4, figsize=[20, 4])\n\n# Plot #1\nexperiment_stats = experiment_stats.loc[experiment_stats.sum(axis=1).sort_values().index.tolist()]\nexperiment_stats.plot(kind='barh', stacked=True, color=lineage_colors, ax=ax[0])\nfor y, x in enumerate(experiment_stats.sum(axis=1).astype(int)):\n    ax[0].annotate(str(x), xy=(x + 10, y), va='center')\nax[0].spines[['right', 'top']].set_visible(False)\nax[0].legend(frameon=False)\nax[0].set_ylabel('Publications')\nax[0].set_xlabel('Number of cells')\n\n# Plot #2\nlineage_stats = mouse.obs.groupby('stage').apply(len)\nlineage_stats.plot(kind='barh', color=list(lineage_colors.values()), ax=ax[1])\nfor y, x in enumerate(lineage_stats.astype(int)):\n    ax[1].annotate(str(x), xy=(x + 10, y), va='center')\nax[1].spines[['right', 'top']].set_visible(False)\nax[1].set_ylabel('Lineage')\nax[1].set_xlabel('Number of cells')\n\n# Plot #3\ntechnology_stats = mouse.obs.groupby('technology').apply(len).sort_values()\ntechnology_stats.plot(kind='barh', color='grey', ax=ax[2])\nfor y, x in enumerate(technology_stats.astype(int)):\n    ax[2].annotate(str(x), xy=(x + 10, y), va='center')\nax[2].spines[['right', 'top']].set_visible(False)\nax[2].set_ylabel('Technology')\nax[2].set_xlabel('Number of cells')\n\n# Plot #4\nleiden_stats = sc.metrics.confusion_matrix('leiden', 'stage', data=mouse.obs) * 100\nleiden_stats.plot(kind='barh', stacked=True, ax=ax[3])\nax[3].spines[['right', 'top']].set_visible(False)\nax[3].legend(title='Clusters', bbox_to_anchor=(0.99, 1.02), loc='upper left', frameon=False)\nax[3].set_ylabel('Lineages')\nax[3].set_xlabel('Cluster %')\n\nfig.tight_layout(w_pad=1)\nfig.savefig(\"../figures/mouse/stats_all.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#markers",
    "href": "notebooks/00_figures_mouse.html#markers",
    "title": "00 - Figures",
    "section": "7 Markers",
    "text": "7 Markers\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi/\", mouse)\n\n\nmouse.layers['scVI_denoised'] = vae.get_normalized_expression(n_samples=10, return_mean=True)\n\n\n7.0.1 Literature\n\nlineage_markers = pd.read_excel(\"../data/external/mouse_lineage_markers.xlsx\", sheet_name=\"Sheet1\").fillna('')[lineage_colors.keys()]\ndisplay(lineage_markers)\n\nlineage_markers = { \n    lineage : mouse.var_names.intersection([str.lower(g) for g in genes])\n    for lineage, genes in lineage_markers.T.iterrows()\n}\n\n\nlineage_markers\n\n\nsc.pl.dotplot(mouse, lineage_markers, groupby='stage', standard_scale='var')\nsc.pl.dotplot(mouse, lineage_markers, groupby='stage', standard_scale='var', layer='scVI_denoised')\n\n\nsc.pl.matrixplot(mouse, lineage_markers, groupby='stage', standard_scale='var', cmap='viridis')\nsc.pl.matrixplot(mouse, lineage_markers, groupby='stage', standard_scale='var', cmap='viridis', layer='scVI_denoised')\n\n\npub_markers = {\n    'Zygote': ['zswim3', 'padi6'],\n    '2C': ['zfp352', 'zscan4d'],\n    '4C': ['sox21'],\n    '8C': ['prdm14', 'pou5f1'],\n    '16C': ['tfap2c', 'gata3'],\n    'ICM': ['tfcp2l1', 'pou5f1'],\n    'TE': ['eomes', 'cdx2'],\n    'EPI': ['sox2', 'nanog'],\n    'PrE': ['gata6', 'pdgfra']\n}\nax = sc.pl.dotplot(mouse, sum(pub_markers.values(), []), groupby='stage', standard_scale='var', cmap='GnBu', figsize=[12, 3.5], show=False)\n_ = ax['mainplot_ax'].set_xticklabels(sum(pub_markers.values(), []), rotation = 45, ha=\"right\", rotation_mode=\"anchor\")\nplt.savefig(\"../figures/mouse/dotplot_pub_markers.svg\")"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#scvi-dges",
    "href": "notebooks/00_figures_mouse.html#scvi-dges",
    "title": "00 - Figures",
    "section": "8 SCVI DGEs",
    "text": "8 SCVI DGEs\n\nm_lineage = vae.differential_expression(groupby=\"stage\")\nm_lineage_filt = filter_markers(m_lineage, n_genes=10)\n\ndisplay(pd.DataFrame.from_dict(m_lineage_filt, orient='index').transpose())\n\nsc.pl.dotplot(mouse, m_lineage_filt, groupby='stage', dendrogram=False, standard_scale='var')\nsc.pl.matrixplot(mouse, m_lineage_filt, groupby='stage', dendrogram=False, standard_scale='var')"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#classifiers",
    "href": "notebooks/00_figures_mouse.html#classifiers",
    "title": "00 - Figures",
    "section": "9 Classifiers",
    "text": "9 Classifiers\n\nimport scgen\nimport squarify\nimport matplotlib.cm as cm\nfrom matplotlib.colors import Normalize\nimport xgboost as xgb\n\n\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n\nLABELS = ['scANVI', 'scANVI [ns=15]', 'XGBoost [scVI]', 'XGBoost [scANVI]', 'XGBoost [scGEN]']\n\n\nmouse.obs.ct.value_counts()\n\nE3.5-ICM     459\nE3.5-PrE     254\nE4.5-PrE     207\n16C          198\nE3.5-EPI     175\n8C           115\n4C           114\nE4.5-EPI     108\nE3.5-TE      107\n2C            86\nE3.75-ICM     48\nE3.25-TE      47\nE3.25-ICM     40\nE4.5-TE       28\nZygote        18\nName: ct, dtype: int64\n\n\n\npredictions = mouse.obs[['ct']].copy()\nxg_clf = xgb.XGBClassifier()\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\npredictions['scANVI'] = lvae.predict()\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\")\npredictions['scANVI_ns15'] = lvae.predict()\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi/\")\nxg_clf.load_model(\"../results/02_mouse_integration/05_scVI_xgboost.json\")\npredictions['xg_scVI'] = predictions.ct.cat.categories[xg_clf.predict(vae.get_normalized_expression(return_mean=True, return_numpy=True))]\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\nxg_clf.load_model(\"../results/02_mouse_integration/05_scANVI_xgboost.json\")\npredictions['xg_scANVI'] = predictions.ct.cat.categories[xg_clf.predict(lvae.get_normalized_expression(return_mean=True, return_numpy=True))]\n\nmscgen = scgen.SCGEN.load(\"../results/02_mouse_integration/scgen/\")\nxg_clf.load_model(\"../results/02_mouse_integration/05_scGEN_xgboost.json\")\npredictions['xg_scGEN'] = predictions.ct.cat.categories[xg_clf.predict(mscgen.get_decoded_expression())]\n\nINFO     File ../results/02_mouse_integration/scanvi/model.pt already downloaded                                   \nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded                             \nINFO     File ../results/02_mouse_integration/scvi/model.pt already downloaded                                     \nINFO     File ../results/02_mouse_integration/scanvi/model.pt already downloaded                                   \nINFO     File ../results/02_mouse_integration/scgen/model.pt already downloaded                                    \n\n\n\nmouse_accuracy = pd.DataFrame([\n    [\n        accuracy_score(predictions.ct.tolist(), predictions[clf].tolist()), \n        balanced_accuracy_score(predictions.ct.tolist(), predictions[clf].tolist()),\n        f1_score(predictions.ct.tolist(), predictions[clf].tolist(), average=\"micro\"),\n        f1_score(predictions.ct.tolist(), predictions[clf].tolist(), average=\"macro\")\n    ] for clf in predictions.columns[1:]\n], index=predictions.columns[1:], columns=['Accuracy', 'Bal. Accuracy', 'F1 (micro)', 'F1 (macro)'])\n\nmouse_accuracy\n\n\n\n\n\n\n\n\nAccuracy\nBal. Accuracy\nF1 (micro)\nF1 (macro)\n\n\n\n\nscANVI\n0.830339\n0.649818\n0.830339\n0.634290\n\n\nscANVI_ns15\n0.793413\n0.879503\n0.793413\n0.777624\n\n\nxg_scVI\n0.963074\n0.975837\n0.963074\n0.976084\n\n\nxg_scANVI\n0.941617\n0.960426\n0.941617\n0.963795\n\n\nxg_scGEN\n0.983034\n0.984459\n0.983034\n0.986173\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(1, 5, figsize=[20, 6], sharey=True, sharex=False)\nfor idx, clf in enumerate(mouse_accuracy.index):\n    conf_df = pd.DataFrame(0, index=predictions.ct.cat.categories, columns=predictions.ct.cat.categories) + sc.metrics.confusion_matrix('ct', clf, data=predictions)\n    conf_df = conf_df[predictions.ct.cat.categories]\n    conf_df[conf_df == 0] = np.nan\n    sns.heatmap(conf_df, linewidths=0.2, cmap='Reds', ax=ax[idx], square=True, cbar=None, linewidth=.5, linecolor='black')\n    ax[idx].set_title(LABELS[idx])\n    ax[idx].set_xticklabels(predictions.ct.cat.categories.tolist(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\nfig.colorbar(cm.ScalarMappable(norm=Normalize(0,1), cmap='Reds'), ax=ax.ravel(), fraction=0.048)\nfig.supxlabel('Predicted')\nfig.supylabel('Observed')\nfig.tight_layout()\nfig.savefig(\"../figures/mouse/00_clf_confusion_mat.svg\")\n\n# fig, ax = plt.subplots(2, 2, figsize=[9, 9], sharey=True, sharex=True)\n# for idx, clf in enumerate(['xg_scVI', 'xg_scANVI', 'xg_scGEN', 'scANVI']):\n#     sns.heatmap(sc.metrics.confusion_matrix('ct', clf, data=predictions)[predictions.ct.cat.categories], \n#                 linewidths=0.2, cmap='viridis', ax=ax[idx // 2, idx % 2], square=True, cbar=None)\n#     ax[idx // 2, idx % 2].set_xlabel('')\n#     ax[idx // 2, idx % 2].set_ylabel('')\n#     ax[idx // 2, idx % 2].set_title(f'XGBoost [{clf[3:]}]')\n#     ax[idx // 2, idx % 2].set_xticklabels(predictions.ct.cat.categories.tolist(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n# ax[1, 1].set_title('scANVI')\n\n# fig.colorbar(cm.ScalarMappable(norm=Normalize(0,1), cmap='viridis'), ax=ax.ravel(), fraction=0.048)\n# fig.supxlabel('Predicted')\n# fig.supylabel('Observed')\n# fig.tight_layout()\n# # fig.savefig(\"../figures/mouse/00_clf_confusion_mat.svg\")\n\n\n\n\n\nfig, ax = plt.subplots(1, 5, figsize=[30, 5])\n\nmouse_accuracy_csv = pd.read_csv(\"../results/05_mouse_classifier_stats.csv\", index_col=0)\nmouse_accuracy_csv.columns = ['Accuracy', 'Bal. Accuracy', 'F1 (micro)', 'F1 (macro)', 'Cross Validation']\nmouse_accuracy_csv.plot(kind='barh', ax=ax[0])\nax[0].spines[['right', 'top']].set_visible(False)\nax[0].legend(loc='lower center', ncols=3)\nax[0].set_yticklabels(LABELS)\n\n# XGBoost scANVI\nconf_df = pd.DataFrame(0, index=predictions.ct.cat.categories, columns=predictions.ct.cat.categories) + sc.metrics.confusion_matrix('ct', 'xg_scANVI', data=predictions)\nconf_df = conf_df[predictions.ct.cat.categories]\nconf_df[conf_df == 0] = np.nan\nsns.heatmap(conf_df, linewidths=0.2, cmap='Reds', ax=ax[1], square=True, cbar=None, linewidth=.5, linecolor='black')\nax[1].set_title(LABELS[3])\nax[1].set_xticklabels(predictions.ct.cat.categories.tolist(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n# scANVI\nconf_df = pd.DataFrame(0, index=predictions.ct.cat.categories, columns=predictions.ct.cat.categories) + sc.metrics.confusion_matrix('ct', 'scANVI', data=predictions)\nconf_df = conf_df[predictions.ct.cat.categories]\nconf_df[conf_df == 0] = np.nan\nsns.heatmap(conf_df, linewidths=0.2, cmap='Reds', ax=ax[2], square=True, cbar=True, linewidth=.5, linecolor='black')\nax[2].set_title(LABELS[0])\nax[2].set_xticklabels(predictions.ct.cat.categories.tolist(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\nax[2].set_yticklabels([' '] * predictions.ct.cat.categories.size)\n\n# scANVI_ns15\nconf_df = pd.DataFrame(0, index=predictions.ct.cat.categories, columns=predictions.ct.cat.categories) + sc.metrics.confusion_matrix('ct', 'scANVI_ns15', data=predictions)\nconf_df = conf_df[predictions.ct.cat.categories]\nconf_df[conf_df == 0] = np.nan\nsns.heatmap(conf_df, linewidths=0.2, cmap='Reds', ax=ax[3], square=True, cbar=None, linewidth=.5, linecolor='black')\nax[3].set_title(LABELS[1])\nax[3].set_xticklabels(predictions.ct.cat.categories.tolist(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\nax[3].set_yticklabels([' '] * predictions.ct.cat.categories.size)\n\n# ICM zoom\nicm_accuracy = (conf_df.loc['E3.5-ICM'].dropna() * 100).sort_values(ascending=True)\nsquarify.plot(sizes=icm_accuracy, \n              label=icm_accuracy.index + '\\n(' + icm_accuracy.round().values.astype(str) + ')%', \n              color=[ct_colors[ct] for ct in icm_accuracy.index],\n              text_kwargs={'fontsize': '10'}, ax=ax[4]\n             )\nax[4].axis(\"off\")\nax[4].set_title('ICM prediction composition')\nfig.tight_layout()\nfig.savefig(\"../figures/mouse/00_clf_accuracy.svg\")\n\n\n\n\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\")\n\nlvae.adata.obsm['x_scANVI'] = lvae.get_latent_representation()\nsc.pp.neighbors(lvae.adata, use_rep='x_scANVI')\nsc.tl.paga(lvae.adata, groups='ct')\nsc.tl.draw_graph(lvae.adata)\nlvae.adata.obs[\"predictions\"] = lvae.predict()\nlvae.adata.obs[\"predictions\"] = lvae.adata.obs[\"predictions\"].astype('category')\nlvae.adata.obs.predictions = lvae.adata.obs.predictions.cat.reorder_categories(ct_colors.keys())\nlvae.adata.obs['entropy'] = 1 - lvae.predict(soft=True).max(axis=1)\n\nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded                             \n\n\n\nicm_entropy = predictions.query('ct == \"E3.5-ICM\"')[['scANVI_ns15']].copy()\nicm_entropy['Score'] = lvae.predict(soft=True).loc[icm_entropy.index, 'E3.5-ICM']\nicm_entropy.scANVI_ns15 = icm_entropy.scANVI_ns15.astype('category')\n\n\nfig, ax = plt.subplots(1, 3, figsize=[15, 4])\n\nsns.swarmplot(x='scANVI_ns15', y='Score', palette=[ct_colors[ct] for ct in icm_entropy.scANVI_ns15.cat.categories], data=icm_entropy, ax=ax[0])\nax[0].set_xticklabels(icm_entropy.scANVI_ns15.cat.categories, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\nax[0].legend(frameon=False)\nax[0].axhline(y=0.5, c='r', linestyle='--')\nax[0].set_xlabel('')\nax[0].set_title('Certainity of predicted cell types in E3.5 ICM')\n\n# plot 2, 3\nlvae.adata.uns['predictions_colors'] = [ct_colors[ct] for ct in lvae.adata.obs.predictions.cat.categories]\nsc.pl.draw_graph(lvae.adata, color='predictions', title='Prediction', show=False, ax=ax[1])\nsc.pl.draw_graph(lvae.adata, color='entropy', vmax=1, cmap='viridis', title='Entropy', show=False, ax=ax[2])\n\nplt.savefig(\"../figures/mouse/00_ICM_prediction_score.svg\")\n\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument."
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#supl.-table-2",
    "href": "notebooks/00_figures_mouse.html#supl.-table-2",
    "title": "00 - Figures",
    "section": "10 Supl. Table 2",
    "text": "10 Supl. Table 2\n\nwriter = pd.ExcelWriter(\"../results/suppl-tab-2.xlsx\", engine=\"xlsxwriter\")\n\npd.read_csv(\"../results/05_mouse_classifier_stats.csv\", index_col=0).to_excel(writer, sheet_name=\"mouse_overall\")\nfor clf in mouse_accuracy.index:\n    df = pd.DataFrame(0, index=predictions.ct.cat.categories, columns=predictions.ct.cat.categories) + sc.metrics.confusion_matrix('ct', clf, data=predictions)\n    df = df.fillna(0)[predictions.ct.cat.categories]\n    df.to_excel(writer, sheet_name=f\"mouse_{clf}\")\nwriter.close()"
  },
  {
    "objectID": "notebooks/00_figures_mouse.html#figure-3-suppl",
    "href": "notebooks/00_figures_mouse.html#figure-3-suppl",
    "title": "00 - Figures",
    "section": "11 Figure 3 + suppl",
    "text": "11 Figure 3 + suppl\n\n11.1 Proks et al.,\n\nvitro = sc.read(\"../results/06_proks_et_al.h5ad\")\nvitro.uns['predictions_colors'] = [ct_colors[x] for x in vitro.obs.predictions.cat.categories]\n\n\nvitro.uns['FACS_colors'] = ['#ff7f0e', '#1f77b4', '#D3D3D3']\n\n\nsc.pl.umap(vitro, ncols=3, cmap='viridis',\n           color=['Stage', 'leiden', 'predictions', 'FACS', 'All.Events.GFP-A.Geo.Mean', 'All.Events.mCherry.561D-A.Geo.Mean'])\n\n\n\n\n\nsc.pl.umap(vitro, color=['FACS', 'Stage', 'predictions', 'entropy'], ncols=2, vmax=1, cmap='viridis', title=['FACS', 'Stage', 'Prediction', 'Entropy'], save='00_query_proks.svg')\n\nWARNING: saving figure to file ../figures/mouse/umap00_query_proks.svg\n\n\n\n\n\n\nfig, ax = plt.subplots(1, 3, figsize=[20, 6])\nsns.heatmap(sc.metrics.confusion_matrix(\"Stage\", \"predictions\", vitro.obs), annot=True, fmt='.2%', cmap='Blues', ax=ax[0], cbar=False)\nsns.heatmap(sc.metrics.confusion_matrix(\"leiden\", \"predictions\", vitro.obs), annot=True, fmt='.2%', cmap='Blues', ax=ax[1], cbar=False)\nsns.heatmap(sc.metrics.confusion_matrix(\"FACS\", \"predictions\", vitro.obs), annot=True, fmt='.2%', cmap='Blues', ax=ax[2])\n\n&lt;Axes: xlabel='predictions', ylabel='FACS'&gt;\n\n\n\n\n\n\nconf_mat = (sc.metrics.confusion_matrix('FACS', 'predictions', vitro.obs) * 100)\nconf_mat.plot.barh(stacked=True, color=ct_colors)\nplt.legend(conf_mat.columns.str.replace('_', ' '), loc='center right', bbox_to_anchor=(1.25, 0.5), frameon=False)\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.xlabel('% of cells')\nplt.ylabel('FACS labeled cells')\nplt.title('in vitro mouse PrE conpositional prediction')\n\nplt.savefig(\"../figures/mouse/00_query_facs_predictions.svg\")\nsc.metrics.confusion_matrix('FACS', 'predictions', vitro.obs, normalize=False).to_csv(\"../results/00_mouse_query.csv\")"
  },
  {
    "objectID": "notebooks/01_fetchngs_human-invitro.html",
    "href": "notebooks/01_fetchngs_human-invitro.html",
    "title": "01 - NGS collection [human]",
    "section": "",
    "text": "import pandas as pd"
  },
  {
    "objectID": "notebooks/01_fetchngs_human-invitro.html#kagawa-et-al.-2022-gse177616",
    "href": "notebooks/01_fetchngs_human-invitro.html#kagawa-et-al.-2022-gse177616",
    "title": "01 - NGS collection [human]",
    "section": "1 Kagawa et al., 2022 [GSE177616]",
    "text": "1 Kagawa et al., 2022 [GSE177616]\n\nKAGAWA_URL='https://ftp.ncbi.nlm.nih.gov/geo/series/GSE177nnn/GSE177616/matrix/GSE177616_series_matrix.txt.gz'\nkagawa_metadata = pd.read_table(KAGAWA_URL, skiprows=16, nrows=1, index_col = 0).T\n\n\nkagawa_gsm = pd.DataFrame({'GSM': kagawa_metadata.index.values[0].split(' ')})\n\n\nkagawa_gsm\n\n\n\n\n\n\n\n\nGSM\n\n\n\n\n0\nGSM5375527\n\n\n1\nGSM5375528\n\n\n2\nGSM5375529\n\n\n3\nGSM5375530\n\n\n4\nGSM5375531\n\n\n...\n...\n\n\n2711\nGSM5378537\n\n\n2712\nGSM5378538\n\n\n2713\nGSM5378539\n\n\n2714\nGSM5378540\n\n\n2715\n\n\n\n\n\n2716 rows  1 columns\n\n\n\n\nkagawa_gsm.to_csv(\"../pipeline/fetchngs/human_GSE177616.txt\", index=None,header=None)\n\nsh ~/Brickman/helper-scripts/nf-core_tower.sh \\\n    Kagawa_2022 \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/human_GSE177616.txt\nnf-core_tower.sh Meistermann_2021 nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.human.config \\\n    --input /scratch/Brickman/pipelines/Meistermann_2021/results/samplesheet/samplesheet.csv"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html",
    "href": "notebooks/01_fetchngs_human.html",
    "title": "01 - NGS collection [human]",
    "section": "",
    "text": "import pandas as pd"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#datasets",
    "href": "notebooks/01_fetchngs_human.html#datasets",
    "title": "01 - NGS collection [human]",
    "section": "0.1 Datasets",
    "text": "0.1 Datasets\n\n\n\nDataset\nStages\nTechnology\n\n\n\n\nMeistermann2021\nE0,E2,E2.5,E3.25,E3.5,E3.75,E4.5\nSMART-seq2\n\n\nPetropoulos2016\nE3,E4,E5,E6,E7\nSMART-Seq2\n\n\nYan2013\nMII-Oocyte, Zygote, 2C,4C,8C,morula,blastocyst\nSMART-seq\n\n\nYanagida\nE6,E7\nSMART-seq\n\n\nNakamura\nCynomolgus Monkey E6 onwards\nSC3-seq\n\n\nBlakeley\nE6/7\nSMARTer-seq\n\n\nHang\nE6,7,8,9,10,12,14\nSMART-seq2\n\n\nXue\n\nTang et al.method\n\n\n\n\n\n\nRoot Dataset\nDataset\nTechnology\nDownload\nNotes\n\n\n\n\nRadley et al., 2022\n\n\n\n\n\n\nX\nMeistermann et al, 2021\nSMART-SEQ2\nPRJEB30442\n\n\n\nX\nPetropoulos et al, 2016\nSMART-SEQ2\nE-MTAB-3929\nSCPORTAL\n\n\nX\nYan et al, 2013\nSMART-SEQ\nGSE36552\nSCPORTAL\n\n\nX\nYanagida et al, 2021\nSMART-SEQ2\nGSE171820\n\n\n\nX\nNakamura et al, 2017\nSMART-SEQ2\n\n\n\n\nBlakeley et al, 2015\n\nSMARTer Ultra Low RNA Kit\nGSE66507\n\n\n\nTysen et al, 2021\nSMARTSEQ2\nPortal\nGASTRULATION (CS7)\n\n\n\nHang et al, 2019\nSMART-SEQ2\nGSE136447\n\n\n\n\nXue\nTang et al.method\nGSE44183\n\n\n\n\n\n\nMeistermann 2021\nPetropoulos 2016\nXiang 2020\nYan 2013\nYanagida 2021\nXue 2013"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#meistermann-et-al.-2021-prjeb30442",
    "href": "notebooks/01_fetchngs_human.html#meistermann-et-al.-2021-prjeb30442",
    "title": "01 - NGS collection [human]",
    "section": "0.2 Meistermann et al., 2021 PRJEB30442",
    "text": "0.2 Meistermann et al., 2021 PRJEB30442\n\nMEISTERMANN_ENA_URL = \"https://www.ebi.ac.uk/ena/portal/api/filereport?accession=PRJEB30442&result=read_run&fields=study_accession,sample_accession,experiment_accession,run_accession,tax_id,scientific_name,fastq_ftp,submitted_ftp,sra_ftp,sample_alias&format=tsv&limit=0\"\nmeistermann_metadata = pd.read_table(MEISTERMANN_ENA_URL)\n\n\nmeistermann_sample_annotation = pd.read_csv(\"../data/external/human/Meistermann_et_al_2021/sampleAnnot.tsv\", index_col=0, sep=\"\\t\")\n\n\nmeistermann_sample_annotation = meistermann_sample_annotation[meistermann_sample_annotation['Dataset'] == 'ThisPaper']\n\n\nmeistermann_sample_annotation = meistermann_sample_annotation.merge(meistermann_metadata, left_on = 'Name', right_on = 'sample_alias')\n\n\nmeistermann_sample_annotation.run_accession.to_csv(\"../pipeline/fetchngs/human_PRJEB30442.txt\", index=None, header=None)\n\nnf-core_tower.sh \\\n    Meistermann_2021 \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/human_PRJEB30442.txt\nnf-core_tower.sh Meistermann_2021 nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.human.config \\\n    --input /scratch/Brickman/pipelines/Meistermann_2021/results/samplesheet/samplesheet.csv"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#petropoulos-et-al.-2016-e-mtab-3929",
    "href": "notebooks/01_fetchngs_human.html#petropoulos-et-al.-2016-e-mtab-3929",
    "title": "01 - NGS collection [human]",
    "section": "0.3 Petropoulos et al., 2016 E-MTAB-3929",
    "text": "0.3 Petropoulos et al., 2016 E-MTAB-3929\n\nPETROPOULOS_URL = \"https://www.ebi.ac.uk/ena/portal/api/filereport?accession=PRJEB11202&result=read_run&fields=study_accession,sample_accession,experiment_accession,run_accession,tax_id,scientific_name,fastq_ftp,submitted_ftp,sra_ftp,sample_alias&format=tsv&limit=0\"\npetropoulos_metadata = pd.read_table(PETROPOULOS_URL)\n\n\npetropoulos_metadata.sample_alias = petropoulos_metadata.sample_alias.str.extract(\"(E[0-9].*$)\")\n\n\npetropoulos_metadata_short = petropoulos_metadata[['run_accession', 'sample_alias']]\n\n\npetropoulos_sample_annotation = pd.read_csv(\"../data/external/human/Meistermann_et_al_2021/sampleAnnot.tsv\", index_col=0, sep=\"\\t\")\n\n\npetropoulos_sample_annotation = petropoulos_sample_annotation.loc[petropoulos_sample_annotation.Dataset == 'Petropoulos2016']\n\n\npetropoulos_sample_annotation = petropoulos_sample_annotation.merge(petropoulos_metadata_short, left_on = 'Name', right_on = 'sample_alias')\n\n\npetropoulos_sample_annotation.run_accession.to_csv(\"../pipeline/fetchngs/human_E-MTAB-3929.txt\", index=None, header=None)\n\nnf-core_tower.sh \\\n    Petropoulos_2016 \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/human_E-MTAB-3929.txt\nnf-core_tower.sh Petropoulos_2016 nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.human.config \\\n    --input /scratch/Brickman/pipelines/Petropoulos_2016/results/samplesheet/samplesheet.csv"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#xiang-et-al.-2020-gse136447",
    "href": "notebooks/01_fetchngs_human.html#xiang-et-al.-2020-gse136447",
    "title": "01 - NGS collection [human]",
    "section": "0.4 Xiang et al., 2020 [GSE136447]",
    "text": "0.4 Xiang et al., 2020 [GSE136447]\n\nxiang_metadata_1 = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE136nnn/GSE136447/matrix/GSE136447-GPL20795_series_matrix.txt.gz\", \n                              skiprows=29, nrows=1, index_col = 0).T\n\n\nxiang_metadata_2 = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE136nnn/GSE136447/matrix/GSE136447-GPL23227_series_matrix.txt.gz\", \n                              skiprows=29, nrows=1, index_col = 0).T\n\n\nxiang_metadata = pd.concat([xiang_metadata_1, xiang_metadata_2])\n\n\nxiang_metadata['Sample_name'] = xiang_metadata.index.to_list()\n\n\nxiang_metadata['Sample_name'] = xiang_metadata['Sample_name'].str.extract(\"_(.*$)\")\n\n\nxiang_metadata\n\n\n\n\n\n\n\n!Sample_title\n!Sample_geo_accession\nSample_name\n\n\n\n\nEmbryo_D6A1S1\nGSM4050122\nD6A1S1\n\n\nEmbryo_D6A1S2\nGSM4050123\nD6A1S2\n\n\nEmbryo_D6A1S3\nGSM4050124\nD6A1S3\n\n\nEmbryo_D6A1S4\nGSM4050125\nD6A1S4\n\n\nEmbryo_D6A1B1\nGSM4050126\nD6A1B1\n\n\n...\n...\n...\n\n\nEmbryo_D14A1S5\nGSM4050628\nD14A1S5\n\n\nEmbryo_D14A1S6\nGSM4050634\nD14A1S6\n\n\nEmbryo_D14A1S7\nGSM4050635\nD14A1S7\n\n\nEmbryo_D14A1S8\nGSM4050636\nD14A1S8\n\n\nEmbryo_D14A1S9\nGSM4050637\nD14A1S9\n\n\n\n\n555 rows  2 columns\n\n\n\n\nxiang_sample_annotation = pd.read_excel(\"../data/external/human/Xiang_et_al_2019/41586_2019_1875_MOESM10_ESM.xlsx\", skiprows=2, index_col=0)\n\n\nxiang_sample_annotation = xiang_sample_annotation.merge(xiang_metadata, left_on='Sample ID', right_on = 'Sample_name')\n\n\nxiang_sample_annotation.columns = ['Day', 'Embryo ID', 'Group', 'GEO_accession', 'Sample_name']\n\n\nxiang_sample_annotation.GEO_accession.to_csv(\"../pipeline/fetchngs/human_GSE136447.txt\", index=None, header=None)\n\nnf-core_tower.sh \\\n    Xiang_2020 \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/human_GSE136447.txt\nnf-core_tower.sh Xiang_2020_human nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.human.config \\\n    --input /scratch/Brickman/pipelines/Xiang_2020_human/results/samplesheet/samplesheet.csv"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#yan-et-al.-2013",
    "href": "notebooks/01_fetchngs_human.html#yan-et-al.-2013",
    "title": "01 - NGS collection [human]",
    "section": "0.5 Yan et al., 2013",
    "text": "0.5 Yan et al., 2013\n\nYAN_MATRIX_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE36nnn/GSE36552/matrix/GSE36552_series_matrix.txt.gz\"\n\n\nyam_metadata = pd.read_table(YAN_MATRIX_URL, skiprows=52, index_col = 0).T\n\n\nyam_annotations = metadata = pd.read_csv(\"../data/external/human/Meistermann_et_al_2021/sampleAnnot.tsv\", index_col=0, sep=\"\\t\")\nyam_annotations = yam_annotations[yam_annotations.Dataset == 'Yan2013'].copy()\n\n\nyam_metadata = yam_metadata[~yam_metadata.index.str.contains('hESC')].copy()\n\n\nyam_metadata['SampleNames'] = yam_metadata.index.values\n\n\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\"#\",\".\")\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\" -Cell\", \"\")\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\"Late blastocyst \", \"lateBlasto\")\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\"Morulae \", \"Morula\")\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\"Oocyte \", \"Oocyte\")\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\"Zygote \", \"Zygote\")\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\"2-cell embryo\", \"e2C\")\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\"4-cell embryo\", \"e4C\")\nyam_metadata['SampleNames'] = yam_metadata['SampleNames'].str.replace(\"8-cell embryo\", \"e8C\")\n\n\nyam_metadata = yam_metadata.loc[:,['!Sample_geo_accession','SampleNames']].copy()\n\n\nyam_metadata.columns = ['Geo_accession', 'SampleNames']\n\n\nyam_annotations = yam_annotations.merge(yam_metadata, left_index = True, right_on='SampleNames', how = 'right')\n\n\nyam_annotations.Geo_accession.to_csv(\"../pipeline/fetchngs/human_GSE36552.txt\", index=None, header=None)\n\nnf-core_tower.sh \\\n    Yan_2013_human \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/human_GSE36552.txt\nnf-core_tower.sh Yan_2013_human nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.human.config \\\n    --input /scratch/Brickman/pipelines/Yan_2013_human/results/samplesheet/samplesheet.csv"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#yanagida-et-al.-2021-gse171820",
    "href": "notebooks/01_fetchngs_human.html#yanagida-et-al.-2021-gse171820",
    "title": "01 - NGS collection [human]",
    "section": "0.6 Yanagida et al., 2021 [GSE171820]",
    "text": "0.6 Yanagida et al., 2021 [GSE171820]\n\nYANAGIDA_URL = 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE171nnn/GSE171820/matrix/GSE171820_series_matrix.txt.gz'\n\n\nyanagida_metadata = pd.read_table(YANAGIDA_URL, skiprows=30, index_col = 0).T\n\n\nyanagida_metadata = yanagida_metadata[yanagida_metadata['!Sample_source_name_ch1'] != 'Blastoid'].copy()\n\n\nyanagida_metadata['lineage'] = yanagida_metadata[['!Sample_characteristics_ch1']].agg(' '.join, axis=1).str.extract(\"lineage: (.*) polar_mural\")\nyanagida_metadata['day'] = yanagida_metadata[['!Sample_characteristics_ch1']].agg(' '.join, axis=1).str.extract(\"time point: Embryonic day ([0-9]{1})\")\nyanagida_metadata['side'] = yanagida_metadata[['!Sample_characteristics_ch1']].agg(' '.join, axis=1).str.extract(\"polar_mural: ([a-z]*)\")\n\n\nyanagida_metadata = yanagida_metadata[['lineage','day','side']].copy()\n\n\nyanagida_metadata['Geo_accession'] = yanagida_metadata.index.values\n\n\nyanagida_metadata.Geo_accession.to_csv(\"../pipeline/fetchngs/human_GSE171820.txt\", index=None, header=None)\n\nnf-core_tower.sh \\\n    Yanagida_2021_human \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/human_GSE171820.txt\nnf-core_tower.sh Yanagida_2021_human nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.human.config \\\n    --input /scratch/Brickman/pipelines/Yanagida_2021_human/results/samplesheet/samplesheet.csv"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#xue-et-al.-2013-gse44183",
    "href": "notebooks/01_fetchngs_human.html#xue-et-al.-2013-gse44183",
    "title": "01 - NGS collection [human]",
    "section": "0.7 Xue et al., 2013 [GSE44183]",
    "text": "0.7 Xue et al., 2013 [GSE44183]\n\nXUE_URL = 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE44nnn/GSE44183/matrix/GSE44183-GPL11154_series_matrix.txt.gz'\n\n\nxue_metadata = pd.read_table(XUE_URL, skiprows=36, index_col = 0).T\n\n\nxue_metadata = xue_metadata[xue_metadata['!Sample_source_name_ch1'].isin(['oocyte','pronucleus','zygote','2-cell blastomere','4-cell blastomere','8-cell blastomere', 'morula'])].copy()\nxue_metadata = xue_metadata[['!Sample_geo_accession','!Sample_source_name_ch1']].copy()\n\n\nreannotate_dict = {\n    'oocyte': 'Oocyte',\n    'pronucleus': 'Pronucleus',\n    'zygote': 'Zygote',\n    '2-cell blastomere': '2C',\n    '4-cell blastomere': '4C',\n    '8-cell blastomere': '8C'\n}\nxue_metadata.replace(reannotate_dict, inplace=True)\n\n\nxue_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/human_GSE44183.txt\", index=None, header=None)\n\nnf-core_tower.sh \\\n    Xue_2013_human \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/human_GSE44183.txt\nnf-core_tower.sh Xue_2013_human nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.human.config \\\n    --input /scratch/Brickman/pipelines/Meistermann_2021/results/samplesheet/samplesheet.csv"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#datasets-1",
    "href": "notebooks/01_fetchngs_human.html#datasets-1",
    "title": "01 - NGS collection [human]",
    "section": "1.1 Datasets",
    "text": "1.1 Datasets\n\n\n\nDataset\nStages\nTechnology\n\n\n\n\nMeistermann2021\nE0,E2,E2.5,E3.25,E3.5,E3.75,E4.5\nSMART-seq2\n\n\nPetropoulos2016\nE3,E4,E5,E6,E7\nSMART-Seq2\n\n\nYan2013\nMII-Oocyte, Zygote, 2C,4C,8C,morula,blastocyst\nSMART-seq\n\n\nYanagida\nE6,E7\nSMART-seq\n\n\nNakamura\nCynomolgus Monkey E6 onwards\nSC3-seq\n\n\nBlakeley\nE6/7\nSMARTer-seq\n\n\nHang\nE6,7,8,9,10,12,14\nSMART-seq2\n\n\nXue\n\nTang et al.method\n\n\n\n\n\n\nRoot Dataset\nDataset\nTechnology\nDownload\nNotes\n\n\n\n\nRadley et al., 2022\n\n\n\n\n\n\nX\nMeistermann et al, 2021\nSMART-SEQ2\nPRJEB30442\n\n\n\nX\nPetropoulos et al, 2016\nSMART-SEQ2\nE-MTAB-3929\nSCPORTAL\n\n\nX\nYan et al, 2013\nSMART-SEQ\nGSE36552\nSCPORTAL\n\n\nX\nYanagida et al, 2021\nSMART-SEQ2\nGSE171820\n\n\n\nX\nNakamura et al, 2017\nSMART-SEQ2\n\n\n\n\nBlakeley et al, 2015\n\nSMARTer Ultra Low RNA Kit\nGSE66507\n\n\n\nTysen et al, 2021\nSMARTSEQ2\nPortal\nGASTRULATION (CS7)\n\n\n\nHang et al, 2019\nSMART-SEQ2\nGSE136447\n\n\n\n\nXue\nTang et al.method\nGSE44183"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#initial-setup",
    "href": "notebooks/01_fetchngs_human.html#initial-setup",
    "title": "01 - NGS collection [human]",
    "section": "1.2 Initial setup",
    "text": "1.2 Initial setup\nFor the pipeline, need to normalise using TPM. This requires average gene lengths. The original iteration of the notebooks linked GENE SYMBOL to MEAN GENE LENGTH. This time, I will instead link ENSEMBL GENE CODE to MEAN GENE LENGTH.\npython3.10 ../data/external/human/gtftools.py -l ../data/external/human/Homo_sapiens.GRCh38.110.gene_length.tsv /scratch/Brickman/references/homo_sapiens/ensembl/GRCh38_110/Homo_sapiens.GRCh38.110.gtf\n\ngtf = pd.read_table(\"../data/external/human/Homo_sapiens.GRCh38.110.gene_length.tsv\", index_col=0)\n\n\ngene_lengths = gtf[['mean']].copy()\ngene_lengths.columns = ['length']\n\n\ndef normalize_smartseq(adata: sc.AnnData, gene_len: pd.DataFrame) -&gt; sc.AnnData:\n    print(\"SMART-SEQ: Normalization\")\n\n    common_genes = adata.var_names.intersection(gene_len.index)\n    print(f\"SMART-SEQ: Common genes {common_genes.shape[0]}\")\n\n    lengths = gene_len.loc[common_genes, \"length\"].values\n    normalized = sc.AnnData(adata[:, common_genes].X, obs=adata.obs, dtype=np.float32)\n    normalized.var_names = common_genes\n    normalized.X = normalized.X / lengths * np.median(lengths)\n    normalized.X = np.rint(normalized.X)\n\n    return normalized"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#meistermann-et-al.-2021",
    "href": "notebooks/01_fetchngs_human.html#meistermann-et-al.-2021",
    "title": "01 - NGS collection [human]",
    "section": "1.3 Meistermann et al., 2021",
    "text": "1.3 Meistermann et al., 2021\nFor annotation, I will be wiping the published annotations of the Meistermann dataset. Setting everything to Unknown. The annotations do not contain an ICM.\n\nmeistermann_h5ad = sc.read_h5ad(\"../data/external/human/meistermann_2021_reprocessed.h5ad\")\n\n\nMEISTERMANN_ENA_URL = \"https://www.ebi.ac.uk/ena/portal/api/filereport?accession=PRJEB30442&result=read_run&fields=study_accession,sample_accession,experiment_accession,run_accession,tax_id,scientific_name,fastq_ftp,submitted_ftp,sra_ftp,sample_alias&format=tsv&limit=0\"\nmeistermann_metadata = pd.read_table(MEISTERMANN_ENA_URL)\nmeistermann_sample_annotation = pd.read_csv(\"../data/external/human/Meistermann_et_al_2021/sampleAnnot.tsv\", index_col=0, sep=\"\\t\")\nmeistermann_sample_annotation = meistermann_sample_annotation[meistermann_sample_annotation['Dataset'] == 'ThisPaper']\nmeistermann_sample_annotation = meistermann_sample_annotation.merge(meistermann_metadata, left_on = 'Name', right_on = 'sample_alias')\n\n\nmeistermann_sample_annotation.columns\n\nIndex(['Embryo', 'Branches', 'EmbryoDay', 'Stage', 'BlastoDissectionSide',\n       'Dataset', 'Treatment', 'Stirparo.lineage', 'Author.lineage',\n       'Pseudotime', 'totalCounts', 'totalGenesExpr', 'clusterUmap',\n       'study_accession', 'sample_accession', 'experiment_accession',\n       'run_accession', 'tax_id', 'scientific_name', 'fastq_ftp',\n       'submitted_ftp', 'sra_ftp', 'sample_alias'],\n      dtype='object')\n\n\n\nmeistermann_sample_annotation.clusterUmap.unique()\n\narray(['B1.EPI', 'B1_B2', 'early_TE', 'EPI', 'medium_TE', 'late_TE',\n       'EPI.PrE', 'Morula', 'EightCells', 'EPI.PrE.TE'], dtype=object)\n\n\n\nmeistermann_sample_annotation.Branches.unique()\n\narray(['6.Epiblast', '3.Early blastocyst', '5.Early trophectoderm',\n       '4.Inner cell mass', '8.TE.NR2F2-', '9.TE.NR2F2+', '2.Morula',\n       '1.Pre-morula', '7.Primitive endoderm'], dtype=object)\n\n\n\nmeistermann_h5ad.obs.loc[:,['sample','run_accession']].merge(meistermann_sample_annotation, left_on='run_accession', right_on='run_accession').loc[:,['Stage','Dataset', 'clusterUmap','EmbryoDay']]\n\n\n\n\n\n\n\n\nStage\nDataset\nclusterUmap\nEmbryoDay\n\n\n\n\n0\nB2+\nThisPaper\nB1.EPI\n5.0\n\n\n1\nB2+\nThisPaper\nB1_B2\n5.0\n\n\n2\nB2+\nThisPaper\nB1.EPI\n5.0\n\n\n3\nB2+\nThisPaper\nB1.EPI\n5.0\n\n\n4\nB2+\nThisPaper\nB1_B2\n5.0\n\n\n...\n...\n...\n...\n...\n\n\n145\nB5\nThisPaper\nmedium_TE\n6.0\n\n\n146\nB5\nThisPaper\nmedium_TE\n6.0\n\n\n147\nB5\nThisPaper\nmedium_TE\n6.0\n\n\n148\nB5\nThisPaper\nmedium_TE\n6.0\n\n\n149\nB4\nThisPaper\nearly_TE\n6.0\n\n\n\n\n150 rows  4 columns\n\n\n\n\nmeistermann = meistermann_h5ad.copy()\n\n\nmeistermann.obs = meistermann_h5ad.obs.loc[:,['sample','run_accession']].reset_index().merge(meistermann_sample_annotation, left_on='run_accession', right_on='run_accession').set_index('index')\n\n\nmeistermann_reannotation = meistermann.obs[['EmbryoDay','clusterUmap']]\n\n\nmeistermann_reannotation.head()\n\n\n\n\n\n\n\n\nEmbryoDay\nclusterUmap\n\n\nindex\n\n\n\n\n\n\nERX3015937_ERX3015937\n5.0\nB1.EPI\n\n\nERX3015939_ERX3015939\n5.0\nB1_B2\n\n\nERX3015940_ERX3015940\n5.0\nB1.EPI\n\n\nERX3015941_ERX3015941\n5.0\nB1.EPI\n\n\nERX3015936_ERX3015936\n5.0\nB1_B2\n\n\n\n\n\n\n\n\nlineage_renaming = {\n    'early_TE': 'Trophectoderm',\n    'late_TE': 'Trophectoderm',\n    'medium_TE':'Trophectoderm',\n    'EPI':'Epiblast',\n    'PrE':'Primitive Endoderm',\n    'PrE.TE':'Unknown',\n    'B1.EPI':'Unknown',\n    'EPI.PrE': 'Unknown',\n    'EPI.PrE.TE':'Unknown',\n    'EPI.early_TE':'Unknown',\n    'B1_B2':'Blastocyst',\n    'EightCells': '8C',\n    'Morula': 'Morula',\n}\n\n\nmeistermann_reannotation = meistermann_reannotation.replace({\n    'clusterUmap':lineage_renaming\n})\n\n\nmeistermann_reannotation.columns = ['day', 'ct']\nmeistermann_reannotation['ct'] = 'Unknown'\nmeistermann_reannotation['experiment'] = 'Meistermann_2021'\nmeistermann_reannotation['technology'] = 'SMARTSeq2'\nmeistermann_reannotation.head()\n\n\n\n\n\n\n\n\nday\nct\nexperiment\ntechnology\n\n\nindex\n\n\n\n\n\n\n\n\nERX3015937_ERX3015937\n5.0\nUnknown\nMeistermann_2021\nSMARTSeq2\n\n\nERX3015939_ERX3015939\n5.0\nUnknown\nMeistermann_2021\nSMARTSeq2\n\n\nERX3015940_ERX3015940\n5.0\nUnknown\nMeistermann_2021\nSMARTSeq2\n\n\nERX3015941_ERX3015941\n5.0\nUnknown\nMeistermann_2021\nSMARTSeq2\n\n\nERX3015936_ERX3015936\n5.0\nUnknown\nMeistermann_2021\nSMARTSeq2\n\n\n\n\n\n\n\n\nmeistermann.obs = meistermann_reannotation\n\n\nnormalize_smartseq(meistermann, gene_lengths)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 62663\n\n\nAnnData object with n_obs  n_vars = 150  62663\n    obs: 'day', 'ct', 'experiment', 'technology'\n\n\n\nsc.pp.filter_cells(meistermann, min_counts=10)\nsc.pp.filter_cells(meistermann, min_genes=10)\nmeistermann.layers[\"counts\"] = meistermann.X.copy()\nsc.pp.normalize_total(meistermann, target_sum=10_000)\nsc.pp.log1p(meistermann)\nmeistermann.raw = meistermann"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#petropoulos-et-al.-2016",
    "href": "notebooks/01_fetchngs_human.html#petropoulos-et-al.-2016",
    "title": "01 - NGS collection [human]",
    "section": "1.4 Petropoulos et al., 2016",
    "text": "1.4 Petropoulos et al., 2016\n\npetropoulos_h5ad = sc.read_h5ad(\"../data/external/human/petropoulos_2016_reprocesses.h5ad\")\n\n\npetropoulos_h5ad\n\nAnnData object with n_obs  n_vars = 1496  62754\n    obs: 'sample', 'fastq_1', 'run_accession', 'experiment_accession', 'sample_accession', 'secondary_sample_accession', 'study_accession', 'secondary_study_accession', 'submission_accession', 'run_alias', 'experiment_alias', 'sample_alias', 'study_alias', 'library_layout', 'library_selection', 'library_source', 'library_strategy', 'library_name', 'instrument_model', 'instrument_platform', 'scientific_name', 'sample_title', 'experiment_title', 'study_title', 'sample_description', 'fastq_md5', 'fastq_ftp', 'fastq_galaxy', 'fastq_aspera'\n    var: 'gene_symbol'\n\n\n\nPETROPOULOS_URL = \"https://www.ebi.ac.uk/ena/portal/api/filereport?accession=PRJEB11202&result=read_run&fields=study_accession,sample_accession,experiment_accession,run_accession,tax_id,scientific_name,fastq_ftp,submitted_ftp,sra_ftp,sample_alias&format=tsv&limit=0\"\npetropoulos_metadata = pd.read_table(PETROPOULOS_URL)\npetropoulos_metadata.sample_alias = petropoulos_metadata.sample_alias.str.extract(\"(E[0-9].*$)\")\npetropoulos_metadata_short = petropoulos_metadata[['run_accession', 'sample_alias']]\npetropoulos_sample_annotation = pd.read_csv(\"../data/external/human/Meistermann_et_al_2021/sampleAnnot.tsv\", index_col=0, sep=\"\\t\")\npetropoulos_sample_annotation = petropoulos_sample_annotation.loc[petropoulos_sample_annotation.Dataset == 'Petropoulos2016']\npetropoulos_sample_annotation = petropoulos_sample_annotation.merge(petropoulos_metadata_short, left_on = 'Name', right_on = 'sample_alias')\n\n\npetropoulos = petropoulos_h5ad.copy()\npetropoulos.obs = petropoulos_h5ad.obs.loc[:,['sample','run_accession']].reset_index().merge(petropoulos_sample_annotation, left_on='run_accession', right_on='run_accession').set_index('index')\n\n\npetropoulos\n\nAnnData object with n_obs  n_vars = 1496  62754\n    obs: 'sample', 'run_accession', 'Embryo', 'Branches', 'EmbryoDay', 'Stage', 'BlastoDissectionSide', 'Dataset', 'Treatment', 'Stirparo.lineage', 'Author.lineage', 'Pseudotime', 'totalCounts', 'totalGenesExpr', 'clusterUmap', 'sample_alias'\n    var: 'gene_symbol'\n\n\n\npetropoulos_reannotation = petropoulos.obs\n\n\npd.crosstab(petropoulos_reannotation['Stirparo.lineage'], petropoulos_reannotation.Stage)\n\n\n\n\n\n\n\nStage\n8C\nB\nB2+\nM\nMC\n\n\nStirparo.lineage\n\n\n\n\n\n\n\n\n\nEPI\n0\n44\n0\n0\n0\n\n\nICM\n0\n65\n0\n0\n0\n\n\nTE\n0\n927\n0\n0\n0\n\n\nintermediate\n0\n66\n0\n0\n0\n\n\nprE\n0\n28\n0\n0\n0\n\n\nundefined\n78\n43\n24\n120\n47\n\n\n\n\n\n\n\n\npd.crosstab(petropoulos_reannotation.Branches, petropoulos_reannotation.EmbryoDay)\n\n\n\n\n\n\n\nEmbryoDay\n3.0\n4.0\n5.0\n6.0\n7.0\n\n\nBranches\n\n\n\n\n\n\n\n\n\n1.Pre-morula\n80\n8\n0\n0\n0\n\n\n2.Morula\n0\n150\n16\n0\n0\n\n\n3.Early blastocyst\n0\n29\n116\n1\n0\n\n\n4.Inner cell mass\n0\n0\n13\n6\n0\n\n\n5.Early trophectoderm\n0\n0\n97\n27\n2\n\n\n6.Epiblast\n0\n0\n114\n33\n16\n\n\n7.Primitive endoderm\n0\n0\n7\n45\n42\n\n\n8.TE.NR2F2-\n0\n0\n3\n226\n141\n\n\n9.TE.NR2F2+\n0\n0\n0\n71\n253\n\n\n\n\n\n\n\n\npd.crosstab(petropoulos_reannotation.clusterUmap, petropoulos_reannotation.Branches)\n\n\n\n\n\n\n\nBranches\n1.Pre-morula\n2.Morula\n3.Early blastocyst\n4.Inner cell mass\n5.Early trophectoderm\n6.Epiblast\n7.Primitive endoderm\n8.TE.NR2F2-\n9.TE.NR2F2+\n\n\nclusterUmap\n\n\n\n\n\n\n\n\n\n\n\n\n\nB1.EPI\n0\n0\n0\n1\n0\n3\n0\n0\n0\n\n\nB1_B2\n0\n25\n136\n2\n7\n1\n0\n0\n0\n\n\nEPI\n0\n0\n0\n0\n0\n104\n29\n0\n0\n\n\nEPI.PrE\n0\n0\n0\n0\n0\n19\n9\n0\n0\n\n\nEPI.PrE.TE\n0\n0\n0\n1\n2\n8\n19\n11\n3\n\n\nEPI.early_TE\n0\n0\n0\n0\n1\n14\n0\n0\n0\n\n\nEightCells\n83\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nMorula\n5\n141\n7\n0\n0\n0\n0\n0\n0\n\n\nPrE\n0\n0\n0\n0\n0\n9\n32\n4\n3\n\n\nPrE.TE\n0\n0\n0\n0\n0\n0\n1\n0\n15\n\n\nearly_TE\n0\n0\n3\n15\n98\n5\n0\n0\n0\n\n\nlate_TE\n0\n0\n0\n0\n0\n0\n3\n39\n290\n\n\nmedium_TE\n0\n0\n0\n0\n18\n0\n1\n316\n13\n\n\n\n\n\n\n\n\nclusterUmap_renaming = {\n    'early_TE': 'Trophectoderm',\n    'late_TE': 'Trophectoderm',\n    'medium_TE':'Trophectoderm',\n    'EPI':'Epiblast',\n    'PrE':'Primitive Endoderm',\n    'PrE.TE':'Unknown',\n    'B1.EPI':'Unknown',\n    'EPI.PrE': 'Unknown',\n    'EPI.PrE.TE':'Unknown',\n    'EPI.early_TE':'Unknown',\n    'B1_B2':'Blastocyst',\n    'EightCells': '8C',\n    'Morula': 'Morula',\n}\npetropoulos_reannotation = petropoulos_reannotation.replace({\n    'clusterUmap':clusterUmap_renaming\n})\n\n\nstirparoLineage_renaming = {\n    'EPI':'Epiblast',\n    'prE':'Primitive Endoderm',\n    'ICM':'Inner Cell Mass',\n    'TE': 'Trophectoderm',\n    'intermediate': 'Unknown',\n    'undefined': 'Unknown'\n}\npetropoulos_reannotation = petropoulos_reannotation.replace({\n    'Stirparo.lineage':stirparoLineage_renaming\n})\n\n\nnp.sum(petropoulos_reannotation['Stirparo.lineage'].isna())\n\n54\n\n\n\npetropoulos_reannotation.loc[petropoulos_reannotation['Stirparo.lineage'].isna(),['Stirparo.lineage']] = 'Unknown'\n\n\npetropoulos_reannotation = petropoulos_reannotation[['EmbryoDay','Dataset','Stirparo.lineage']].copy()\npetropoulos_reannotation.columns = ['day','experiment','ct']\npetropoulos_reannotation['experiment'] = 'Petropoulos_2016'\npetropoulos_reannotation['technology'] = 'SMARTSeq2'\npetropoulos_reannotation.head()\n\n\n\n\n\n\n\n\nday\nexperiment\nct\ntechnology\n\n\nindex\n\n\n\n\n\n\n\n\nERX1120888_ERX1120888\n3.0\nPetropoulos_2016\nUnknown\nSMARTSeq2\n\n\nERX1120887_ERX1120887\n3.0\nPetropoulos_2016\nUnknown\nSMARTSeq2\n\n\nERX1120886_ERX1120886\n3.0\nPetropoulos_2016\nUnknown\nSMARTSeq2\n\n\nERX1120885_ERX1120885\n3.0\nPetropoulos_2016\nUnknown\nSMARTSeq2\n\n\nERX1120890_ERX1120890\n3.0\nPetropoulos_2016\nUnknown\nSMARTSeq2\n\n\n\n\n\n\n\n\npetropoulos.obs = petropoulos_reannotation\n\n\nnormalize_smartseq(petropoulos, gene_lengths)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 62663\n\n\nAnnData object with n_obs  n_vars = 1496  62663\n    obs: 'day', 'experiment', 'ct', 'technology'\n\n\n\nsc.pp.filter_cells(petropoulos, min_counts=10)\nsc.pp.filter_cells(petropoulos, min_genes=10)\npetropoulos.layers[\"counts\"] = petropoulos.X.copy()\nsc.pp.normalize_total(petropoulos, target_sum=10_000)\nsc.pp.log1p(petropoulos)\npetropoulos.raw = petropoulos"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#xiang-2020",
    "href": "notebooks/01_fetchngs_human.html#xiang-2020",
    "title": "01 - NGS collection [human]",
    "section": "1.5 Xiang 2020",
    "text": "1.5 Xiang 2020\n\nxiang_h5ad = sc.read_h5ad(\"../data/external/human/xiang_2020_reprocessed.h5ad\")\n\n\nxiang_metadata_1 = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE136nnn/GSE136447/matrix/GSE136447-GPL20795_series_matrix.txt.gz\", \n                              skiprows=29, nrows=1, index_col = 0).T\nxiang_metadata_2 = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE136nnn/GSE136447/matrix/GSE136447-GPL23227_series_matrix.txt.gz\", \n                              skiprows=29, nrows=1, index_col = 0).T\nxiang_metadata = pd.concat([xiang_metadata_1, xiang_metadata_2])\nxiang_metadata['Sample_name'] = xiang_metadata.index.to_list()\nxiang_metadata['Sample_name'] = xiang_metadata['Sample_name'].str.extract(\"_(.*$)\")\nxiang_sample_annotation = pd.read_excel(\"../data/external/human/Xiang_et_al_2019/41586_2019_1875_MOESM10_ESM.xlsx\", skiprows=2, index_col=0)\nxiang_sample_annotation = xiang_sample_annotation.merge(xiang_metadata, left_on='Sample ID', right_on = 'Sample_name')\nxiang_sample_annotation.columns = ['Day', 'Embryo ID', 'Group', 'GEO_accession', 'Sample_name']\n\n\nxiang_sample_annotation\n\n\n\n\n\n\n\n\nDay\nEmbryo ID\nGroup\nGEO_accession\nSample_name\n\n\n\n\n0\nD6\nD6A1\nICM\nGSM4050122\nD6A1S1\n\n\n1\nD6\nD6A1\nEPI\nGSM4050123\nD6A1S2\n\n\n2\nD6\nD6A1\nICM\nGSM4050124\nD6A1S3\n\n\n3\nD6\nD6A1\nICM\nGSM4050125\nD6A1S4\n\n\n4\nD6\nD6A1\nICM\nGSM4050126\nD6A1B1\n\n\n...\n...\n...\n...\n...\n...\n\n\n550\nD14\nD14A3\nEPI\nGSM4050672\nD14A3S29\n\n\n551\nD14\nD14A3\nEVT\nGSM4050673\nD14A3S30\n\n\n552\nD14\nD14A3\nCTB\nGSM4050674\nD14A3S5\n\n\n553\nD14\nD14A3\nEVT\nGSM4050675\nD14A3S7\n\n\n554\nD14\nD14A3\nEVT\nGSM4050676\nD14A3S8\n\n\n\n\n555 rows  5 columns\n\n\n\n\nxiang = xiang_h5ad.copy()\n\n\nxiang.obs = xiang_h5ad.obs.loc[:,['sample','sample_alias']].reset_index().merge(xiang_sample_annotation, left_on='sample_alias', right_on='GEO_accession').set_index('index')\n\n\nxiang\n\nAnnData object with n_obs  n_vars = 555  62754\n    obs: 'sample', 'sample_alias', 'Day', 'Embryo ID', 'Group', 'GEO_accession', 'Sample_name'\n    var: 'gene_symbol'\n\n\n\nxiang_reannotation = xiang.obs\n\n\nday_renaming = {\n    'D10':10,\n    'D12':12,\n    'D14':14,\n    'D6':6,\n    'D7':7,\n    'D8':8,\n    'D9':9,\n}\n\ngroup_renaming = {\n    'CTB':'Trophectoderm',\n    'EPI':'Epiblast',\n    'EVT':'Trophectoderm',\n    'ICM':'Inner Cell Mass',\n    'PSA-EPI':'PostImplantation-Epiblast',\n    'PrE':'Primitive Endoderm',\n    'STB':'Trophectoderm'\n}\n\nxiang_reannotation = xiang_reannotation.replace({'Day':day_renaming, 'Group': group_renaming})\n\n\nxiang_reannotation = xiang_reannotation[['Day', 'Group']].copy()\nxiang_reannotation.columns = ['day', 'ct']\nxiang_reannotation['experiment'] = 'Xiang_2020'\nxiang_reannotation['technology'] = 'SMARTSeq2'\nxiang_reannotation.head()\n\n\n\n\n\n\n\n\nday\nct\nexperiment\ntechnology\n\n\nindex\n\n\n\n\n\n\n\n\nSRX6774526_SRX6774526\n12\nTrophectoderm\nXiang_2020\nSMARTSeq2\n\n\nSRX6774449_SRX6774449\n6\nEpiblast\nXiang_2020\nSMARTSeq2\n\n\nSRX6774468_SRX6774468\n6\nEpiblast\nXiang_2020\nSMARTSeq2\n\n\nSRX6774508_SRX6774508\n12\nTrophectoderm\nXiang_2020\nSMARTSeq2\n\n\nSRX6774478_SRX6774478\n10\nEpiblast\nXiang_2020\nSMARTSeq2\n\n\n\n\n\n\n\n\nxiang.obs = xiang_reannotation\n\n\nnormalize_smartseq(xiang, gene_lengths)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 62663\n\n\nAnnData object with n_obs  n_vars = 555  62663\n    obs: 'day', 'ct', 'experiment', 'technology'\n\n\n\nsc.pp.filter_cells(xiang, min_counts=10)\nsc.pp.filter_cells(xiang, min_genes=10)\nxiang.layers[\"counts\"] = xiang.X.copy()\nsc.pp.normalize_total(xiang, target_sum=10_000)\nsc.pp.log1p(xiang)\nxiang.raw = xiang"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#yan-2013",
    "href": "notebooks/01_fetchngs_human.html#yan-2013",
    "title": "01 - NGS collection [human]",
    "section": "1.6 Yan 2013",
    "text": "1.6 Yan 2013\n\nyan_h5ad = sc.read_h5ad(\"../data/external/human/yan_2013_reprocessed.h5ad\")\n\n\nYAN_MATRIX_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE36nnn/GSE36552/matrix/GSE36552_series_matrix.txt.gz\"\nyan_metadata = pd.read_table(YAN_MATRIX_URL, skiprows=52, index_col = 0).T\nyan_annotations = metadata = pd.read_csv(\"../data/external/human/Meistermann_et_al_2021/sampleAnnot.tsv\", index_col=0, sep=\"\\t\")\nyan_annotations = yan_annotations[yan_annotations.Dataset == 'Yan2013'].copy()\nyan_metadata = yan_metadata[~yan_metadata.index.str.contains('hESC')].copy()\nyan_metadata['SampleNames'] = yan_metadata.index.values\n\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\"#\",\".\")\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\" -Cell\", \"\")\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\"Late blastocyst \", \"lateBlasto\")\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\"Morulae \", \"Morula\")\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\"Oocyte \", \"Oocyte\")\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\"Zygote \", \"Zygote\")\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\"2-cell embryo\", \"e2C\")\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\"4-cell embryo\", \"e4C\")\nyan_metadata['SampleNames'] = yan_metadata['SampleNames'].str.replace(\"8-cell embryo\", \"e8C\")\n\nyan_metadata = yan_metadata.loc[:,['!Sample_geo_accession','SampleNames']].copy()\nyan_metadata.columns = ['Geo_accession', 'SampleNames']\nyan_annotations = yan_annotations.merge(yan_metadata, left_index = True, right_on='SampleNames', how = 'right')\n\n\nyan = yan_h5ad.copy()\n\n\nyan.obs = yan_h5ad.obs.loc[:,['sample','sample_alias']].reset_index().merge(yan_annotations, left_on='sample_alias', right_on='Geo_accession').set_index('index')\n\nThe Yan 2013 data is encoded by stage (Oocyte, Zygote, etc). To convert to Embryonic day, the samples were encoded as follows:\n\nZygote &gt; E0.75; Collected 17h post-IVF\ne2C &gt; E1.25; Collected 27h post-IVF\ne4C &gt; E2.0; Collected 48h post-IVF\ne8C &gt; E3.0\n\n\nyan_reannotation = yan.obs\n\n\nyan_reannotation.loc[yan_reannotation['SampleNames'].str.contains('Oocyte'),['EmbryoDay','clusterUmap', 'Stirparo.lineage']] = [0,'Oocyte','Oocyte']\nyan_reannotation.loc[yan_reannotation['SampleNames'].str.contains('Zygote'),['EmbryoDay','clusterUmap', 'Stirparo.lineage']] = [0.75, 'Zygote', 'Zygote']\nyan_reannotation.loc[yan_reannotation['SampleNames'].str.contains('e2C'),['EmbryoDay','clusterUmap', 'Stirparo.lineage']] = [1.25, '2C', '2C']\nyan_reannotation.loc[yan_reannotation['SampleNames'].str.contains('e4C'),['EmbryoDay','clusterUmap', 'Stirparo.lineage']] = [2.0, '4C', '4C']\nyan_reannotation.loc[yan_reannotation['SampleNames'].str.contains('e8C'),['EmbryoDay','clusterUmap', 'Stirparo.lineage']] = [3.0, '8C', '8C']\nyan_reannotation.loc[yan_reannotation['SampleNames'].str.contains('Morula'),['clusterUmap', 'Stirparo.lineage']] = ['Morula', 'Morula']\n\nclusterUmap_renaming = {\n    'early_TE': 'Trophectoderm',\n    'late_TE': 'Trophectoderm',\n    'medium_TE':'Trophectoderm',\n    'EPI':'Epiblast',\n    'PrE':'Primitive Endoderm',\n    'PrE.TE':'Unknown',\n    'B1.EPI':'Unknown',\n    'EPI.PrE': 'Unknown',\n    'EPI.PrE.TE':'Unknown',\n    'EPI.early_TE':'Unknown',\n    'B1_B2':'Blastocyst',\n    'EightCells': '8C',\n    'Morula': 'Morula',\n}\nyan_reannotation = yan_reannotation.replace({\n    'clusterUmap':clusterUmap_renaming\n})\n\nstirparoLineage_renaming = {\n    'EPI':'Epiblast',\n    'prE':'Primitive Endoderm',\n    'ICM':'Inner Cell Mass',\n    'TE': 'Trophectoderm',\n    'intermediate': 'Unknown',\n    'undefined': 'Unknown'\n}\nyan_reannotation = yan_reannotation.replace({\n    'Stirparo.lineage':stirparoLineage_renaming\n})\n\nyan_reannotation.loc[yan_reannotation['Stirparo.lineage'].isna(),['Stirparo.lineage']] = 'Unknown'\n\n\nyan_reannotation.head()\n\n\n\n\n\n\n\n\nsample\nsample_alias\nEmbryo\nBranches\nEmbryoDay\nStage\nBlastoDissectionSide\nDataset\nTreatment\nStirparo.lineage\nAuthor.lineage\nPseudotime\ntotalCounts\ntotalGenesExpr\nclusterUmap\nGeo_accession\nSampleNames\n\n\nindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRX144398_SRX144398\nSRX144398\nGSM922204\nlateBlasto.1\n4.Inner cell mass\n6.0\nB\nNaN\nYan2013\nNO\nTrophectoderm\nTE\n32.314831\n11403434.0\n12724.0\nTrophectoderm\nGSM922204\nlateBlasto.1.11\n\n\nSRX144343_SRX144343\nSRX144343\nGSM922149\nNaN\nNaN\n2.0\nNaN\nNaN\nNaN\nNaN\n4C\nNaN\nNaN\nNaN\nNaN\n4C\nGSM922149\ne4C.1.4\n\n\nSRX144359_SRX144359\nSRX144359\nGSM922165\n8C.2\n1.Pre-morula\n3.0\n8C\nNaN\nYan2013\nNO\n8C\nNaN\n2.626271\n18039226.0\n16018.0\n8C\nGSM922165\ne8C.2.4\n\n\nSRX144408_SRX144408\nSRX144408\nGSM922214\nlateBlasto.2\n4.Inner cell mass\n6.0\nB\nNaN\nYan2013\nNO\nTrophectoderm\nTE\n35.919631\n21209246.0\n12577.0\nUnknown\nGSM922214\nlateBlasto.2.9\n\n\nSRX144361_SRX144361\nSRX144361\nGSM922167\n8C.2\n1.Pre-morula\n3.0\n8C\nNaN\nYan2013\nNO\n8C\nNaN\n0.329333\n17166536.0\n17739.0\n8C\nGSM922167\ne8C.2.6\n\n\n\n\n\n\n\n\nyan_reannotation = yan_reannotation[['EmbryoDay', 'Stirparo.lineage']].copy()\nyan_reannotation.columns = ['day','ct']\nyan_reannotation['experiment'] = 'Yan_2013'\nyan_reannotation['technology'] = 'SMARTSeq'\nyan_reannotation.head()\n\n\n\n\n\n\n\n\nday\nct\nexperiment\ntechnology\n\n\nindex\n\n\n\n\n\n\n\n\nSRX144398_SRX144398\n6.0\nTrophectoderm\nYan_2013\nSMARTSeq\n\n\nSRX144343_SRX144343\n2.0\n4C\nYan_2013\nSMARTSeq\n\n\nSRX144359_SRX144359\n3.0\n8C\nYan_2013\nSMARTSeq\n\n\nSRX144408_SRX144408\n6.0\nTrophectoderm\nYan_2013\nSMARTSeq\n\n\nSRX144361_SRX144361\n3.0\n8C\nYan_2013\nSMARTSeq\n\n\n\n\n\n\n\n\nyan.obs = yan_reannotation\n\n\nnormalize_smartseq(yan, gene_lengths)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 62663\n\n\nAnnData object with n_obs  n_vars = 90  62663\n    obs: 'day', 'ct', 'experiment', 'technology'\n\n\n\nsc.pp.filter_cells(yan, min_counts=10)\nsc.pp.filter_cells(yan, min_genes=10)\nyan.layers[\"counts\"] = yan.X.copy()\nsc.pp.normalize_total(yan, target_sum=10_000)\nsc.pp.log1p(yan)\nyan.raw = yan"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#yanagida-2021",
    "href": "notebooks/01_fetchngs_human.html#yanagida-2021",
    "title": "01 - NGS collection [human]",
    "section": "1.7 Yanagida 2021",
    "text": "1.7 Yanagida 2021\n\nyanagida_h5ad = sc.read_h5ad(\"../data/external/human/yanagida_2021_reprocessed.h5ad\")\n\n\nYANAGIDA_URL = 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE171nnn/GSE171820/matrix/GSE171820_series_matrix.txt.gz'\nyanagida_metadata = pd.read_table(YANAGIDA_URL, skiprows=30, index_col = 0).T\nyanagida_metadata = yanagida_metadata[yanagida_metadata['!Sample_source_name_ch1'] != 'Blastoid'].copy()\nyanagida_metadata['lineage'] = yanagida_metadata[['!Sample_characteristics_ch1']].agg(' '.join, axis=1).str.extract(\"lineage: (.*) polar_mural\")\nyanagida_metadata['day'] = yanagida_metadata[['!Sample_characteristics_ch1']].agg(' '.join, axis=1).str.extract(\"time point: Embryonic day ([0-9]{1})\")\nyanagida_metadata['side'] = yanagida_metadata[['!Sample_characteristics_ch1']].agg(' '.join, axis=1).str.extract(\"polar_mural: ([a-z]*)\")\nyanagida_metadata = yanagida_metadata[['lineage','day','side']].copy()\nyanagida_metadata['Geo_accession'] = yanagida_metadata.index.values\n\n\nyanagida = yanagida_h5ad.copy()\n\n\nyanagida_metadata\n\n\n\n\n\n\n\n!Sample_geo_accession\nlineage\nday\nside\nGeo_accession\n\n\n\n\nGSM5234744\nTrophectoderm\n7\npolar\nGSM5234744\n\n\nGSM5234745\nTrophectoderm\n7\npolar\nGSM5234745\n\n\nGSM5234746\nTrophectoderm\n7\npolar\nGSM5234746\n\n\nGSM5234747\nEpiblast\n6\npolar\nGSM5234747\n\n\nGSM5234748\nEpiblast\n6\npolar\nGSM5234748\n\n\n...\n...\n...\n...\n...\n\n\nGSM5235116\nTrophectoderm\n6\npolar\nGSM5235116\n\n\nGSM5235117\nTrophectoderm\n6\npolar\nGSM5235117\n\n\nGSM5235118\nTrophectoderm\n6\npolar\nGSM5235118\n\n\nGSM5235119\nTrophectoderm\n6\nmural\nGSM5235119\n\n\nGSM5235128\nTrophectoderm\n6\nmural\nGSM5235128\n\n\n\n\n228 rows  4 columns\n\n\n\n\nyanagida.obs = yanagida_h5ad.obs.loc[:,['sample','sample_alias']].reset_index().merge(yanagida_metadata, left_on='sample_alias', right_on='Geo_accession').set_index('index')\n\n\nyanagida_reannotation = yanagida.obs[['lineage','day']]\n\n\nyanagida_reannotation\n\n\n\n\n\n\n\n\nlineage\nday\n\n\nindex\n\n\n\n\n\n\nSRX10567995_SRX10567995\nTrophectoderm\n6\n\n\nSRX10567984_SRX10567984\nTrophectoderm\n6\n\n\nSRX10568025_SRX10568025\nTrophectoderm\n6\n\n\nSRX10567983_SRX10567983\nTrophectoderm\n6\n\n\nSRX10567987_SRX10567987\nTrophectoderm\n7\n\n\n...\n...\n...\n\n\nSRX10568348_SRX10568348\nTrophectoderm\n6\n\n\nSRX10568337_SRX10568337\nTrophectoderm\n6\n\n\nSRX10568339_SRX10568339\nTrophectoderm\n6\n\n\nSRX10568338_SRX10568338\nTrophectoderm\n6\n\n\nSRX10568336_SRX10568336\nTrophectoderm\n6\n\n\n\n\n228 rows  2 columns\n\n\n\n\nyanagida_reannotation.lineage.unique()\n\narray(['Trophectoderm', 'Epiblast', 'Unknown', 'Early Trophectoderm',\n       'Inner Cell Mass', 'Inner Cell Mass-Trophectoderm Transition',\n       'Primitive Endoderm'], dtype=object)\n\n\n\nlineage_renaming = {\n    'Early Trophectoderm': 'Trophectoderm',\n    'Inner Cell Mass-Trophectoderm Transition': 'Unknown',\n}\nyanagida_reannotation = yanagida_reannotation.replace({'lineage':lineage_renaming})\n\n\nyanagida_reannotation = yanagida_reannotation[['day', 'lineage']]\nyanagida_reannotation.columns = ['day','ct']\nyanagida_reannotation['experiment'] = 'Yanagida_2021'\nyanagida_reannotation['technology'] = 'SMARTSeq2'\nyanagida_reannotation.head()\n\n\n\n\n\n\n\n\nday\nct\nexperiment\ntechnology\n\n\nindex\n\n\n\n\n\n\n\n\nSRX10567995_SRX10567995\n6\nTrophectoderm\nYanagida_2021\nSMARTSeq2\n\n\nSRX10567984_SRX10567984\n6\nTrophectoderm\nYanagida_2021\nSMARTSeq2\n\n\nSRX10568025_SRX10568025\n6\nTrophectoderm\nYanagida_2021\nSMARTSeq2\n\n\nSRX10567983_SRX10567983\n6\nTrophectoderm\nYanagida_2021\nSMARTSeq2\n\n\nSRX10567987_SRX10567987\n7\nTrophectoderm\nYanagida_2021\nSMARTSeq2\n\n\n\n\n\n\n\n\nyanagida.obs = yanagida_reannotation\n\n\nnormalize_smartseq(yanagida, gene_lengths)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 62663\n\n\nAnnData object with n_obs  n_vars = 228  62663\n    obs: 'day', 'ct', 'experiment', 'technology'\n\n\n\nsc.pp.filter_cells(yanagida, min_counts=10)\nsc.pp.filter_cells(yanagida, min_genes=10)\nyanagida.layers[\"counts\"] = yanagida.X.copy()\nsc.pp.normalize_total(yanagida, target_sum=10_000)\nsc.pp.log1p(yanagida)\nyanagida.raw = yanagida"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#xue-2013",
    "href": "notebooks/01_fetchngs_human.html#xue-2013",
    "title": "01 - NGS collection [human]",
    "section": "1.8 Xue 2013",
    "text": "1.8 Xue 2013\n\nxue_h5ad = sc.read_h5ad(\"../data/external/human/xue_2013_reprocessed.h5ad\")\n\n\nXUE_URL = 'https://ftp.ncbi.nlm.nih.gov/geo/series/GSE44nnn/GSE44183/matrix/GSE44183-GPL11154_series_matrix.txt.gz'\nxue_metadata = pd.read_table(XUE_URL, skiprows=36, index_col = 0).T\nxue_metadata = xue_metadata[xue_metadata['!Sample_source_name_ch1'].isin(['oocyte','pronucleus','zygote','2-cell blastomere','4-cell blastomere','8-cell blastomere', 'morula'])].copy()\nxue_metadata = xue_metadata[['!Sample_geo_accession','!Sample_source_name_ch1']].copy()\nreannotate_dict = {\n    'oocyte': 'Oocyte',\n    'pronucleus': 'Pronucleus',\n    'zygote': 'Zygote',\n    '2-cell blastomere': '2C',\n    '4-cell blastomere': '4C',\n    '8-cell blastomere': '8C',\n    'morula': 'Morula',\n}\nxue_metadata.replace(reannotate_dict, inplace=True)\n\n\nxue = xue_h5ad.copy()\n\n\nxue.obs = xue.obs.loc[:,['sample','sample_alias']].reset_index().merge(xue_metadata, left_on='sample_alias', right_on='!Sample_geo_accession').set_index('index')\n\nThis dataset contains an additional Pronuclei stage. According to Capmany, et al.(1996), the average time for pronuclei formation is 8h post-IVF. We therefore annotate these cells as {'EmbryonicDay': '0.33', 'Lineage': 'Pronucleus'}\n\nxue.obs\n\n\n\n\n\n\n\n\nsample\nsample_alias\n!Sample_geo_accession\n!Sample_source_name_ch1\n\n\nindex\n\n\n\n\n\n\n\n\nSRX300891_SRX300891\nSRX300891\nGSM1160130\nGSM1160130\n8C\n\n\nSRX300889_SRX300889\nSRX300889\nGSM1160128\nGSM1160128\n8C\n\n\nSRX300873_SRX300873\nSRX300873\nGSM1160112\nGSM1160112\nOocyte\n\n\nSRX300899_SRX300899\nSRX300899\nGSM1160138\nGSM1160138\nMorula\n\n\nSRX300883_SRX300883\nSRX300883\nGSM1160122\nGSM1160122\n2C\n\n\nSRX300895_SRX300895\nSRX300895\nGSM1160134\nGSM1160134\n8C\n\n\nSRX300892_SRX300892\nSRX300892\nGSM1160131\nGSM1160131\n8C\n\n\nSRX300901_SRX300901\nSRX300901\nGSM1160140\nGSM1160140\nMorula\n\n\nSRX300900_SRX300900\nSRX300900\nGSM1160139\nGSM1160139\nMorula\n\n\nSRX300885_SRX300885\nSRX300885\nGSM1160124\nGSM1160124\n4C\n\n\nSRX300875_SRX300875\nSRX300875\nGSM1160114\nGSM1160114\nOocyte\n\n\nSRX300897_SRX300897\nSRX300897\nGSM1160136\nGSM1160136\n8C\n\n\nSRX300879_SRX300879\nSRX300879\nGSM1160118\nGSM1160118\nZygote\n\n\nSRX300896_SRX300896\nSRX300896\nGSM1160135\nGSM1160135\n8C\n\n\nSRX300890_SRX300890\nSRX300890\nGSM1160129\nGSM1160129\n8C\n\n\nSRX300894_SRX300894\nSRX300894\nGSM1160133\nGSM1160133\n8C\n\n\nSRX300881_SRX300881\nSRX300881\nGSM1160120\nGSM1160120\n2C\n\n\nSRX300874_SRX300874\nSRX300874\nGSM1160113\nGSM1160113\nOocyte\n\n\nSRX300887_SRX300887\nSRX300887\nGSM1160126\nGSM1160126\n4C\n\n\nSRX300880_SRX300880\nSRX300880\nGSM1160119\nGSM1160119\nZygote\n\n\nSRX300893_SRX300893\nSRX300893\nGSM1160132\nGSM1160132\n8C\n\n\nSRX300878_SRX300878\nSRX300878\nGSM1160117\nGSM1160117\nPronucleus\n\n\nSRX300888_SRX300888\nSRX300888\nGSM1160127\nGSM1160127\n8C\n\n\nSRX300884_SRX300884\nSRX300884\nGSM1160123\nGSM1160123\n4C\n\n\nSRX300876_SRX300876\nSRX300876\nGSM1160115\nGSM1160115\nPronucleus\n\n\nSRX300882_SRX300882\nSRX300882\nGSM1160121\nGSM1160121\n2C\n\n\nSRX300886_SRX300886\nSRX300886\nGSM1160125\nGSM1160125\n4C\n\n\nSRX300877_SRX300877\nSRX300877\nGSM1160116\nGSM1160116\nPronucleus\n\n\n\n\n\n\n\n\nxue_reannotation = xue.obs[['!Sample_source_name_ch1', 'sample_alias']].copy()\nxue_reannotation.columns = ['Lineage', 'alias']\n\n\nxue_reannotation\n\n\n\n\n\n\n\n\nLineage\nalias\n\n\nindex\n\n\n\n\n\n\nSRX300891_SRX300891\n8C\nGSM1160130\n\n\nSRX300889_SRX300889\n8C\nGSM1160128\n\n\nSRX300873_SRX300873\nOocyte\nGSM1160112\n\n\nSRX300899_SRX300899\nMorula\nGSM1160138\n\n\nSRX300883_SRX300883\n2C\nGSM1160122\n\n\nSRX300895_SRX300895\n8C\nGSM1160134\n\n\nSRX300892_SRX300892\n8C\nGSM1160131\n\n\nSRX300901_SRX300901\nMorula\nGSM1160140\n\n\nSRX300900_SRX300900\nMorula\nGSM1160139\n\n\nSRX300885_SRX300885\n4C\nGSM1160124\n\n\nSRX300875_SRX300875\nOocyte\nGSM1160114\n\n\nSRX300897_SRX300897\n8C\nGSM1160136\n\n\nSRX300879_SRX300879\nZygote\nGSM1160118\n\n\nSRX300896_SRX300896\n8C\nGSM1160135\n\n\nSRX300890_SRX300890\n8C\nGSM1160129\n\n\nSRX300894_SRX300894\n8C\nGSM1160133\n\n\nSRX300881_SRX300881\n2C\nGSM1160120\n\n\nSRX300874_SRX300874\nOocyte\nGSM1160113\n\n\nSRX300887_SRX300887\n4C\nGSM1160126\n\n\nSRX300880_SRX300880\nZygote\nGSM1160119\n\n\nSRX300893_SRX300893\n8C\nGSM1160132\n\n\nSRX300878_SRX300878\nPronucleus\nGSM1160117\n\n\nSRX300888_SRX300888\n8C\nGSM1160127\n\n\nSRX300884_SRX300884\n4C\nGSM1160123\n\n\nSRX300876_SRX300876\nPronucleus\nGSM1160115\n\n\nSRX300882_SRX300882\n2C\nGSM1160121\n\n\nSRX300886_SRX300886\n4C\nGSM1160125\n\n\nSRX300877_SRX300877\nPronucleus\nGSM1160116\n\n\n\n\n\n\n\n\nembryonictime_annotation = {\n    'Oocyte': 0,\n    'Pronucleus': 0.33,\n    'Zygote': 0.75,\n    '2C': 1.25,\n    '4C': 2,\n    '8C':3,\n    'Morula':4,\n}\n\n\nxue_reannotation['EmbryonicDay'] = xue_reannotation['Lineage'].map(embryonictime_annotation)\n\n\nxue_reannotation = xue_reannotation[['EmbryonicDay', 'Lineage']]\nxue_reannotation.columns = ['day','ct']\nxue_reannotation['experiment'] = 'Xue_2013'\nxue_reannotation['technology'] = 'Tang2009'\nxue_reannotation.head()\n\n\n\n\n\n\n\n\nday\nct\nexperiment\ntechnology\n\n\nindex\n\n\n\n\n\n\n\n\nSRX300891_SRX300891\n3.00\n8C\nXue_2013\nTang2009\n\n\nSRX300889_SRX300889\n3.00\n8C\nXue_2013\nTang2009\n\n\nSRX300873_SRX300873\n0.00\nOocyte\nXue_2013\nTang2009\n\n\nSRX300899_SRX300899\n4.00\nMorula\nXue_2013\nTang2009\n\n\nSRX300883_SRX300883\n1.25\n2C\nXue_2013\nTang2009\n\n\n\n\n\n\n\n\nxue.obs = xue_reannotation\n\n\nnormalize_smartseq(xue, gene_lengths)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 62663\n\n\nAnnData object with n_obs  n_vars = 28  62663\n    obs: 'day', 'ct', 'experiment', 'technology'\n\n\n\nsc.pp.filter_cells(xue, min_counts=10)\nsc.pp.filter_cells(xue, min_genes=10)\nxue.layers[\"counts\"] = xue.X.copy()\nsc.pp.normalize_total(xue, target_sum=10_000)\nsc.pp.log1p(xue)\nxue.raw = xue"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#reannotation",
    "href": "notebooks/01_fetchngs_human.html#reannotation",
    "title": "01 - NGS collection [human]",
    "section": "2.1 Reannotation",
    "text": "2.1 Reannotation\n\n2.1.0.1 Concatenated cell type and embryonic day\n\nhuman_adata.obs['ct_fine'] = human_adata.obs.ct.astype(str) + '_' + human_adata.obs.day.astype(str)\n\n\nhuman_adata.obs.loc[human_adata.obs.ct == 'Unknown','ct_fine'] = 'Unknown'\n\n\nhuman_adata.obs\n\n\n\n\n\n\n\n\nday\nct\nexperiment\ntechnology\nn_counts\nn_genes\nct_fine\n\n\nindex\n\n\n\n\n\n\n\n\n\n\n\nERX3015937_ERX3015937\n5.00\nUnknown\nMeistermann_2021\nSMARTSeq2\n708313.0\n5761\nUnknown\n\n\nERX3015939_ERX3015939\n5.00\nUnknown\nMeistermann_2021\nSMARTSeq2\n402557.0\n5689\nUnknown\n\n\nERX3015940_ERX3015940\n5.00\nUnknown\nMeistermann_2021\nSMARTSeq2\n511338.0\n6039\nUnknown\n\n\nERX3015941_ERX3015941\n5.00\nUnknown\nMeistermann_2021\nSMARTSeq2\n994383.0\n8383\nUnknown\n\n\nERX3015936_ERX3015936\n5.00\nUnknown\nMeistermann_2021\nSMARTSeq2\n1389486.0\n7762\nUnknown\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nSRX300884_SRX300884\n2.00\n4C\nXue_2013\nTang2009\n13308292.0\n14096\n4C_2.0\n\n\nSRX300876_SRX300876\n0.33\nPronucleus\nXue_2013\nTang2009\n16438437.0\n16542\nPronucleus_0.33\n\n\nSRX300882_SRX300882\n1.25\n2C\nXue_2013\nTang2009\n11549318.0\n12071\n2C_1.25\n\n\nSRX300886_SRX300886\n2.00\n4C\nXue_2013\nTang2009\n10497600.0\n7149\n4C_2.0\n\n\nSRX300877_SRX300877\n0.33\nPronucleus\nXue_2013\nTang2009\n13025184.0\n17779\nPronucleus_0.33\n\n\n\n\n2547 rows  7 columns\n\n\n\n\n\n2.1.0.2 Remove Day 12 and Day 14 datasets\n\nhuman_adata = human_adata[human_adata.obs.day &lt; 12].copy()\n\n\n\n2.1.0.3 Set 4C and earlier stages as Prelineage\n\nhuman_adata.obs.loc[human_adata.obs.day &lt;= 2, 'ct_fine'] = 'Prelineage'\n\n\nhuman_adata.obs.ct_fine.value_counts()\n\nUnknown                    609\nTrophectoderm_7.0          462\nTrophectoderm_6.0          403\nTrophectoderm_5.0          246\nInner Cell Mass_5.0         87\nEpiblast_6.0                76\nTrophectoderm_10.0          60\nTrophectoderm_9.0           53\nEpiblast_7.0                46\nTrophectoderm_8.0           46\nPrelineage                  39\nInner Cell Mass_6.0         33\nPrimitive Endoderm_7.0      32\n8C_3.0                      30\nMorula_4.0                  19\nPrimitive Endoderm_6.0      19\nInner Cell Mass_7.0         18\nEpiblast_10.0               14\nEpiblast_8.0                11\nEpiblast_9.0                10\nPrimitive Endoderm_10.0      3\nPrimitive Endoderm_9.0       3\nPrimitive Endoderm_8.0       2\nInner Cell Mass_9.0          2\nName: ct_fine, dtype: int64\n\n\n\n\n2.1.0.4 Combine Epiblast E8, E9 and E10 into Late Epiblast\n\nhuman_adata.obs.loc[(human_adata.obs.day &gt;= 8) & (human_adata.obs.ct == 'Epiblast'),'ct_fine'] = 'Late epiblast'\n\n\n\n2.1.0.5 Combine PrE from all days into PrE\n\nhuman_adata.obs.loc[human_adata.obs.ct == 'Primitive Endoderm','ct_fine'] = 'Primitive Endoderm'\n\n\n\n2.1.0.6 Combine all ICM into one category\n\nhuman_adata.obs.loc[(human_adata.obs.ct == 'Inner Cell Mass'),'ct_fine'] = 'Inner Cell Mass'"
  },
  {
    "objectID": "notebooks/01_fetchngs_human.html#write-out-human-data",
    "href": "notebooks/01_fetchngs_human.html#write-out-human-data",
    "title": "01 - NGS collection [human]",
    "section": "2.2 Write out human data",
    "text": "2.2 Write out human data\n\nhuman_adata.obs.ct_fine.value_counts()\n\nUnknown               609\nTrophectoderm_7.0     462\nTrophectoderm_6.0     403\nTrophectoderm_5.0     246\nInner Cell Mass       140\nEpiblast_6.0           76\nTrophectoderm_10.0     60\nPrimitive Endoderm     59\nTrophectoderm_9.0      53\nEpiblast_7.0           46\nTrophectoderm_8.0      46\nPrelineage             39\nLate epiblast          35\n8C_3.0                 30\nMorula_4.0             19\nName: ct_fine, dtype: int64\n\n\n\nhuman_adata.write_h5ad('../data/processed/32_human_adata.h5ad')"
  },
  {
    "objectID": "notebooks/01_fetchngs_mouse.html",
    "href": "notebooks/01_fetchngs_mouse.html",
    "title": "01 - NGS collection [mouse]",
    "section": "",
    "text": "Timepoints were adjusted based on Saiz and Plusa et al., Reproduction 2013\nMouse: - Guo et al., 2010: qPCR on steroids, complicated, skipping - maybe for prediction, could be interesting) - Guo et al., 2014: Bisulfite-Seq (skipping) - ~~Ohnishi et al., 2014: Microarray (used in ccmnetplus for validation) *~~\n!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\nimport anndata\nimport pandas as pd\nimport scanpy as sc\nimport pandas as pd\nimport seaborn as sns\n\n\ndef load_experiment(filename: str, GEO: str, left_on: str = 'sample', right_on='SRX'):\n    adata = sc.read(filename)\n    metadata = pd.read_csv(f\"../pipeline/fetchngs/{GEO}_metadata.csv\")\n\n    # sometimes we have duplicates because the ID is not unique\n    adata.obs = pd.merge(adata.obs, metadata, left_on=left_on, right_on=right_on)\\\n                    .drop_duplicates(left_on)\\\n                    .set_index(left_on)\n\n    adata.obs['ct_orig'] = adata.obs['sample_title']\n\n    return adata\n%run ../scripts/helpers.py\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\ndef normalize_smartseq(adata: sc.AnnData, gene_len: pd.DataFrame) -&gt; sc.AnnData:\n    print(\"SMART-SEQ: Normalization\")\n\n    common_genes = adata.var_names.intersection(gene_len.index)\n    print(f\"SMART-SEQ: Common genes {common_genes.shape[0]}\")\n\n    lengths = gene_len.loc[common_genes, \"length\"].values\n    normalized = adata[:, common_genes].copy()\n    normalized.X = normalized.X / lengths * np.median(lengths)\n    normalized.X = np.rint(normalized.X)\n\n    return normalized\n# pip install gtftools\n# !gtftools \\\n#     -l ../data/external/Mus_musculus_GRCm38_102_gene_length.txt \\\n#     /scratch/Brickman/references/mus_musculus/ensembl/GRCm38_102/Mus_musculus.GRCm38.102.gtf\n\ngenes_length = pd.read_table(\"../data/external/Mus_musculus_GRCm38_102_gene_length.txt\").set_index('gene')\ngenes_length['length'] = genes_length['mean']\ngenes_length\n\n\n\n\n\n\n\n\nmean\nmedian\nlongest_isoform\nmerged\nlength\n\n\ngene\n\n\n\n\n\n\n\n\n\nENSMUSG00000102693\n1070\n1070\n1070\n1070\n1070\n\n\nENSMUSG00000064842\n110\n110\n110\n110\n110\n\n\nENSMUSG00000051951\n3592\n3634\n4153\n6094\n3592\n\n\nENSMUSG00000102851\n480\n480\n480\n480\n480\n\n\nENSMUSG00000103377\n2819\n2819\n2819\n2819\n2819\n\n\n...\n...\n...\n...\n...\n...\n\n\nENSMUSG00000117740\n331\n331\n331\n331\n331\n\n\nENSMUSG00000117782\n1570\n1570\n1570\n1570\n1570\n\n\nENSMUSG00000117951\n256\n256\n256\n256\n256\n\n\nENSMUSG00000095993\n168\n168\n168\n168\n168\n\n\nENSMUSG00000118197\n243\n243\n243\n243\n243\n\n\n\n\n55364 rows  5 columns"
  },
  {
    "objectID": "notebooks/01_fetchngs_mouse.html#datasets",
    "href": "notebooks/01_fetchngs_mouse.html#datasets",
    "title": "01 - NGS collection [mouse]",
    "section": "1 Datasets",
    "text": "1 Datasets\n\n\n\nDataset\nTechnology\nDownload\nNotes\n\n\n\n\nDeng et al., 2014\nSMART-seq 1/2\nGSE45719\nDone\n\n\nBiase et al., 2014\nSMART-seq\nGSE57249\nDone\n\n\nPosfai et al., 2017\nSMART-seq\nGSE84892\nDone\n\n\nGoolamn et al., 2016\nSMART-seq2\nE-MTAB-3321\nDone\n\n\nBoroviak et al., 2015\nSMART-seq2\nSup Table S1\nDone\n\n\nChen et al., 2016\nSMART-seq2\nGSE74155\nDone\n\n\nNowotschin et al., 2019\n10X v2\nPortal\nDone\n\n\nFan et al., 2015\nSUPeR-seq\nGSE53386\nDone\n\n\nBorensztein et al., 2017\nqRT-PCR\nGSE80810\nDone\n\n\nStirparo et al., 2020\nSMART-seq2\nGSE159030\nDone\n\n\nXue et al., 2013\nqRT-PCR\nGSE44183\nDone\n\n\nYanagida et al., 2022\nSMART-seq2\nGSE148462\nDone\n\n\nMohammed et al., 2017\nSMART-seq2\nGSE100597\nDone\n\n\n\n\n1.1 Deng et al., 2014 GSE45719\nnf-core_tower.sh \\\n    Deng_et_al_2014 \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE45719.txt\n\nnf-core_tower.sh Deng_et_al_ALIGNED nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --protocol smartseq \\\n    --aligner star \\\n    --fasta /scratch/Brickman/references/mus_musculus/ensembl/GRCm38_102/Mus_musculus.GRCm38.dna_sm.primary_assembly.fa \\\n    --gtf /scratch/Brickman/references/mus_musculus/ensembl/GRCm38_102/Mus_musculus.GRCm38.102.gtf \\\n    --star_index /scratch/Brickman/references/mus_musculus/ensembl/GRCm38_102/star_2.7.10a \\\n    --input /scratch/Brickman/pipelines/Deng_et_al_2014/results/samplesheet/samplesheet.csv\n\n1.1.1 Preparation\n\ndeng_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE45nnn/GSE45719/matrix/GSE45719_series_matrix.txt.gz\", \n                              skiprows=30, index_col=0).T\n\n\ndeng_metadata['ct'] = deng_metadata['!Sample_source_name_ch1'].values\ndeng_metadata['SRX'] = deng_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\ndeng_metadata = deng_metadata.reset_index()\n\n\nlegend = {\n    '16-cell stage blastomere': '16C', \n    '2-cell stage blastomere': '2C',\n    '4-cell stage blastomere': '4C',\n    '8-cell stage blastomere': '8C',\n    'Early 2-cell stage blastomere (31-32h post-fertilization)': '2C',\n    'Early blastocyst cell (86-88h post-fertilization)': 'Blastocyst',\n    'Late 2-cell stage blastomere (46-48h post-fertilization)': '2C',\n    'Late blastocyst cell (100-102h post-fertilization)': 'Blastocyst',\n    'Liver': 'Liver',\n    'Liver cell': 'Liver', \n    'Mid 2-cell stage blastomere (34-40h post-fertilization)': '2C',\n    'Mid blastocyst cell (92-94h post-fertilization)': 'Blastocyst',\n    'Zygote': 'Zygote',\n    'fibroblast (primary culture from tail)': 'Fibroblast'\n}\n\nfor old_name, new_name in legend.items():\n    deng_metadata.loc[deng_metadata.ct == old_name, 'ct'] = new_name\ndeng_metadata.ct = deng_metadata.ct.astype('category')\ndeng_metadata = deng_metadata.query('ct not in [\"Liver\", \"Blastocyst\", \"Fibroblast\"]').copy()\n\n\ndeng_metadata['index'].to_csv(\"../pipeline/fetchngs/GSE45719.txt\", index=None, header=None)\ndeng_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE45719_metadata.csv\")\n\n\n\n1.1.2 Load dataset\n\ndeng = load_experiment(\n    \"../data/external/aligned/mouse/Deng_et_al_ALIGNED/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE45719\"\n)\n\n\ndeng.obs['experiment'] = \"Deng et al., 2014\"\ndeng.obs['technology'] = 'SMART-seq'\ndeng.obs.loc[deng.obs.sample_alias.isin([f'GSM12780{i:02d}' for i in range(9, 45)]), 'technology'] = 'SMART-seq2'\ndeng.obs['batch'] = \"DENG_1\"\ndeng.obs.loc[deng.obs.technology == 'SMART-seq2', 'batch'] = \"DENG_2\"\ndeng.obs = deng.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\ndeng = normalize_smartseq(deng, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\n\n\n1.2 Biase et al., 2014 GSE57249\nnf-core_tower.sh \\\n    Biase_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE57249.txt\n\nnf-core_tower.sh Biase_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Biase_et_al/results/samplesheet/samplesheet.csv\n\n1.2.1 Preparation\n\nbiase_metadata = pd.concat([\n    pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE57nnn/GSE57249/matrix/GSE57249-GPL13112_series_matrix.txt.gz\",\n                  skiprows=33, index_col=0).T.reset_index().set_index('!Sample_geo_accession'),\n    pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE57nnn/GSE57249/matrix/GSE57249-GPL17021_series_matrix.txt.gz\",\n                  skiprows=33, index_col=0).T.reset_index().set_index('!Sample_geo_accession')\n])\n\n\nbiase_metadata['ct'] = biase_metadata['index'].values\nbiase_metadata['SRX'] = biase_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\nbiase_metadata = biase_metadata.reset_index()\n\n\nlegend = {\n    'Zygote': 'Zygote',\n    'Two-cell': '2C',\n    'Four-cell': '4C',\n    'Inner cell mass': 'E3.5-ICM',\n    'Trophectoderm': 'E3.5-TE'\n}\n\nfor old_name, new_name in legend.items():\n    biase_metadata.loc[biase_metadata.ct.str.startswith(old_name), 'ct'] = new_name\nbiase_metadata.ct = biase_metadata.ct.astype('category')\n\n\nbiase_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE57249.txt\", index=None, header=None)\nbiase_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE57249_metadata.csv\")\n\n\n\n1.2.2 Load dataset\n\nbiase = load_experiment(\n    \"../data/external/aligned/mouse/Biase_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE57249\")\n\n\nbiase.obs['batch'] = \"BIASE_1\"\nbiase.obs['experiment'] = \"Biase et al., 2014\"\nbiase.obs['technology'] = \"SMART-seq2\"\n\nbiase.obs = biase.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nbiase = normalize_smartseq(biase, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nbiase\n\nAnnData object with n_obs  n_vars = 56  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.3 Posfai et al., 2017 GSE84892\nnf-core_tower.sh \\\n    Posfai_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE84892.txt\n\nnf-core_tower.sh Posfai_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Posfai_et_al/results/samplesheet/samplesheet.csv\n\n1.3.1 Preparation\n\nposfai_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE84nnn/GSE84892/matrix/GSE84892_series_matrix.txt.gz\",\n                                skiprows=31, index_col=0).T\n\n\nposfai_metadata['SRX'] = posfai_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\nposfai_metadata = posfai_metadata.reset_index()\n\n\nlegend = {\n    '16': '16C-',\n    '32': 'E3.25-',\n    '64': 'E3.5-'\n}\n\n\nposfai_metadata['ct'] = 'UNKNOWN'\nfor old_name, new_name in legend.items():\n    posfai_metadata.loc[posfai_metadata.loc[:, '!Sample_characteristics_ch1'].iloc[:, 0].str.contains(old_name), 'ct'] = new_name\n\nposfai_metadata.ct = posfai_metadata.ct + posfai_metadata.loc[:, '!Sample_characteristics_ch1'].iloc[:, 2].str.replace('lineage: ', '')\nposfai_metadata = posfai_metadata.query('~ct.str.contains(\"CO\") or ct != \"UNKNOWN\"').copy()\nposfai_metadata.loc[posfai_metadata.ct.str.contains('16C'), 'ct'] = '16C'\n\n\nposfai_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE84892.txt\", index=None, header=None)\nposfai_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE84892_metadata.csv\")\n\n\n\n1.3.2 Load dataset\n\nposfai = sc.read(\"../data/external/aligned/mouse/Posfai_et_al/results/star/mtx_conversions/combined_matrix.h5ad\")\nposfai = posfai[~posfai.obs.duplicated()].copy()\nposfai_metadata = pd.read_csv(\"../pipeline/fetchngs/GSE84892_metadata.csv\")\n\nposfai.obs = pd.merge(posfai.obs, posfai_metadata, left_on=\"sample_title\", right_on=\"index\").set_index('sample_title')\n\nposfai = posfai[posfai.obs.ct != \"E3.25-CO\"].copy()\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n  utils.warn_names_duplicates(\"obs\")\n\n\n\nposfai.obs['batch'] = \"POSFAI_1\"\nposfai.obs['experiment'] = \"Posfai et al., 2017\"\nposfai.obs['technology'] = \"SMART-seq2\"\nposfai.obs['ct_orig'] = posfai.obs['!Sample_characteristics_ch1']\n\nposfai.obs = posfai.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nposfai = normalize_smartseq(posfai, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nposfai\n\nAnnData object with n_obs  n_vars = 261  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.4 Goolamn et al., 2016 E-MTAB-3321\nnf-core_tower.sh \\\n    Goolam_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/E-MTAB-3321.txt\n\nnf-core_tower.sh Goolam_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Goolam_et_al/results/samplesheet/samplesheet.csv\n\n1.4.1 Preparation\n\ngoolamn_metadata = pd.read_table(\"https://www.ebi.ac.uk/biostudies/files/E-MTAB-3321/E-MTAB-3321.sdrf.txt\")\n\n\ngoolamn_metadata['ct'] = goolamn_metadata['Characteristics[developmental stage]'].values\n\n\nlegend = {\n    'cleavage 2-cell' : '2C',\n    'cleavage 4-cell': '4C',\n    'cleavage 8-cell': '8C',\n    'cleavage 16-cell': '16C',\n    'cleavage 32-cell': '32C'\n}\n\nfor old_name, new_name in legend.items():\n    goolamn_metadata.loc[goolamn_metadata.ct == old_name, 'ct'] = new_name\ngoolamn_metadata.ct = goolamn_metadata.ct.astype('category')\n\ngoolamn_metadata = goolamn_metadata.query('ct != \"32C\"').copy()\n\n\ngoolamn_metadata['Comment[ENA_RUN]'].to_csv(\"../pipeline/fetchngs/E-MTAB-3321.txt\", index=None, header=None)\ngoolamn_metadata.set_index('Comment[ENA_RUN]').to_csv(\"../pipeline/fetchngs/E-MTAB-3321_metadata.csv\")\n\n\n\n1.4.2 Load dataset\n\ngoolam = load_experiment(\n    \"../data/external/aligned/mouse/Goolam_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"E-MTAB-3321\", left_on='run_accession', right_on='Comment[ENA_RUN]'\n)\n\n\ngoolam.obs['batch'] = [f\"GOOLAM_{batch}\" for batch in goolam.obs[\"Characteristics[batch]\"].values]\ngoolam.obs['experiment'] = \"Goolamn et al., 2016\"\ngoolam.obs['technology'] = \"SMART-seq2\"\n\ngoolam.obs = goolam.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\ngoolam = normalize_smartseq(goolam, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\ngoolam\n\nAnnData object with n_obs  n_vars = 118  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.5 Boroviak et al., 2015 [E-MTAB-2958] and [E-MTAB-2959]\nnf-core_tower.sh \\\n    Boroviak_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/E-MTAB-29589.txt\n\nnf-core_tower.sh Boroviak_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Boroviak_et_al/results/samplesheet/samplesheet.csv\n\n1.5.1 Preparation\n\nboroviak_metadata = pd.concat([\n    pd.read_table(\"https://ftp.ebi.ac.uk/biostudies/nfs/E-MTAB-/958/E-MTAB-2958/Files/E-MTAB-2958.sdrf.txt\"),\n    pd.read_table(\"https://ftp.ebi.ac.uk/biostudies/nfs/E-MTAB-/959/E-MTAB-2959/Files/E-MTAB-2959.sdrf.txt\")\n])\n\n\nboroviak_metadata['ct'] = boroviak_metadata['Extract Name'].values\n\n\nlegend = {\n    'E2.5_MOR': '8C',\n    'E3.5_ICM': 'E3.5-ICM',\n    'E4.5_PrE': 'E4.5-PrE',\n    'E4.5_EPI': 'E4.5-EPI',\n}\n\nfor old_name, new_name in legend.items():\n    boroviak_metadata.loc[boroviak_metadata.ct.str.startswith(old_name), 'ct'] = new_name\n\nboroviak_metadata = boroviak_metadata.query('ct in [\"8C\", \"E3.5-ICM\", \"E4.5-EPI\", \"E4.5-PrE\"]').copy()\nboroviak_metadata.ct = boroviak_metadata.ct.astype('category')\n\n\nboroviak_metadata['Comment[ENA_RUN]'].to_csv(\"../pipeline/fetchngs/E-MTAB-29589.txt\", index=None, header=None)\nboroviak_metadata.set_index('Comment[ENA_RUN]').to_csv(\"../pipeline/fetchngs/E-MTAB-29589_metadata.csv\")\n\n\n\n1.5.2 Load dataset\n\nboroviak = load_experiment(\n    \"../data/external/aligned/mouse/Boroviak_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"E-MTAB-29589\", left_on='run_accession', right_on='Comment[ENA_RUN]')\n\n\nboroviak.obs['batch'] = \"BOROVIAK_1\"\nboroviak.obs['experiment'] = \"Boroviak et al., 2015\"\nboroviak.obs['technology'] = \"SMART-seq2\"\n\nboroviak.obs = boroviak.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nboroviak = normalize_smartseq(boroviak, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nboroviak\n\nAnnData object with n_obs  n_vars = 12  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.6 Chen et al., 2016 GSE74155\nnf-core_tower.sh \\\n    Chen_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --force_sratools_download \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE74155.txt\n\nnf-core_tower.sh Chen_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Chen_et_al/results/samplesheet/samplesheet.csv\n\n1.6.1 Preparation\n\nchen_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE74nnn/GSE74155/matrix/GSE74155_series_matrix.txt.gz\",\n                              skiprows=30, index_col=0).T\n\n\nchen_metadata['ct'] = chen_metadata['!Sample_characteristics_ch1'].iloc[:, 1].values\nchen_metadata['SRX'] = chen_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\nchen_metadata = chen_metadata.reset_index()\n\n\nlegend = {\n    'cell type: E3.5 ICM': 'E3.5-ICM',\n    'cell type: E4.5 Epiblast': 'E4.5-EPI'\n}\n\nfor old_name, new_name in legend.items():\n    chen_metadata.loc[chen_metadata.ct.str.startswith(old_name), 'ct'] = new_name\n\nchen_metadata = chen_metadata.query('ct in [\"E3.5-ICM\", \"E4.5-EPI\"]').copy()\nchen_metadata.ct = chen_metadata.ct.astype('category')\n\n\nchen_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE74155.txt\", index=None, header=None)\nchen_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE74155_metadata.csv\")\n\n\n\n1.6.2 Load dataset\n\nchen = load_experiment(\n    \"../data/external/aligned/mouse/Chen_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE74155\", left_on='sample_alias', right_on='ID_REF')\n\n\nchen.obs['batch'] = \"CHEN_1\"\nchen.obs['experiment'] = \"Chen et al., 2016\"\nchen.obs['technology'] = \"SMART-seq2\"\n\nchen.obs = chen.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nchen = normalize_smartseq(chen, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nchen\n\nAnnData object with n_obs  n_vars = 46  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.7 Nowotschin et al., 2019 [GSE123046]\nnf-core_tower.sh \\\n    Nowotschin_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --force_sratools_download \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE123046.txt\n\nwget https://raw.githubusercontent.com/10XGenomics/cellranger/master/lib/python/cellranger/barcodes/737K-august-2016.txt ../pipeline/737K-august-2016.txt && gzip ../pipeline/737K-august-2016.txt\n\nnf-core_tower.sh Nowotschin_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/10X.config \\\n    --input /scratch/Brickman/pipelines/Nowotschin_et_al/results/samplesheet/samplesheet.csv\n\n1.7.1 Preparation\n\nnowotschin_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE123nnn/GSE123046/matrix/GSE123046_series_matrix.txt.gz\",\n                                    skiprows=41, index_col=0).T\n\n\nnowotschin_metadata['ct'] = nowotschin_metadata.index\nnowotschin_metadata['SRX'] = nowotschin_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\nnowotschin_metadata = nowotschin_metadata.reset_index()\n\n\nnowotschin_metadata = nowotschin_metadata[nowotschin_metadata.ct.str.startswith((\"E3\", \"E4\"))].copy()\n\n\nnowotschin_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE123046.txt\", index=None, header=None)\nnowotschin_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE123046_metadata.csv\")\n\n\n\n1.7.2 Load dataset\n\ndef nowotschin_get_metadata():\n    metadata = pd.read_csv(\"https://s3.amazonaws.com/dp-lab-data-public/mouse_endoderm/sc_endoderm_all_cells_metadata.csv\", index_col=0)\n    correction = pd.read_csv(\"../data/external/aligned/mouse/Nowotschin_et_al/e35_cell_types.csv\", index_col=0)\n\n    metadata.loc[correction.index, 'CellType'] = correction.CellType\n\n    return metadata\n\n\nnowotschin = sc.read(\"../data/external/aligned/mouse/Nowotschin_et_al/results/star/mtx_conversions/combined_matrix.h5ad\")\n\nlegend = {\n    'E4.5_Rep1': 'Lib1-1_E4.5',\n    'E4.5_Rep2': 'Lib1-2_E4.5',\n    'E3.5_Rep1': 'Lib1-3_E3.5',\n    'E3.5_Rep2': 'Lib1-4_E3.5',\n}\n\nnowotschin.obs['Library'] = 'UNKNOWN'\nfor old_name, new_name in legend.items():\n    nowotschin.obs.loc[nowotschin.obs['sample_title'] == old_name, 'Library'] = new_name\n\nnowotschin.obs['cell_id'] = nowotschin.obs['Library'] + \"_\" + nowotschin.obs_names.str.split('_', expand=True).droplevel(1)\nnowotschin.obs['timepoint'] = nowotschin.obs.sample_title.str.split('_', expand=True).values[:, 0]\nnowotschin.obs = nowotschin.obs.set_index('cell_id')\n\n\nnowotschin_metadata = nowotschin_get_metadata()\n\n\nnowotschin = nowotschin[nowotschin.obs_names.intersection(nowotschin_metadata.index)].copy()\nnowotschin_metadata = nowotschin_metadata.loc[nowotschin.obs_names].copy()\n\n\nnowotschin.obs['batch'] = \"NOWO_1\"\nnowotschin.obs.loc[nowotschin.obs['timepoint'].str.startswith('E4.5'), 'batch'] = \"NOWO_2\"\n# nowotschin.obs['batch'] = nowotschin.obs['Library'].replace({\n#     'Lib1-1_E4.5': 'NOWO_1', \n#     'Lib1-2_E4.5': 'NOWO_2',\n#     'Lib1-3_E3.5': 'NOWO_3',\n#     'Lib1-4_E3.5': 'NOWO_4', \n# })\nnowotschin.obs['experiment'] = \"Nowotschin et al., 2019\"\nnowotschin.obs['technology'] = \"10X 3' v2\"\nnowotschin.obs['ct'] = nowotschin_metadata[['Timepoint', 'CellType']].agg('-'.join, axis=1)\nnowotschin.obs['ct_orig'] = nowotschin_metadata['CellType']\n\nnowotschin.obs = nowotschin.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\n\n\n1.8 Fan et al., 2015 GSE53386\nnf-core_tower.sh \\\n    Fan_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --force_sratools_download \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE53386.txt\n\nnf-core_tower.sh Fan_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Fan_et_al/results/samplesheet/samplesheet.csv\n\n1.8.1 Preparation\n\nfan_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE53nnn/GSE53386/matrix/GSE53386-GPL13112_series_matrix.txt.gz\", \n                      skiprows=33, index_col=0).T\nfan_metadata['SRX'] = fan_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\n\n\nfan_metadata['ct'] = fan_metadata['!Sample_characteristics_ch1'].iloc[:, 0].values\nfan_metadata = fan_metadata.reset_index()\n\n\nlegend = {\n    'cell type: zygote': 'Zygote',\n    'cell type: 2-cell embryo': '2C',\n    'cell type: 4-cell embryo': '4C',\n    'cell type: 8-cell embryo': '8C', \n    'cell type: morula': '16C',\n}\n\n\nfor old_name, new_name in legend.items():\n    fan_metadata.loc[fan_metadata.ct == old_name, 'ct'] = new_name\n    \nfan_metadata = fan_metadata[fan_metadata.ct.isin(legend.values())].copy()\n\n\nfan_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE53386.txt\", index=None, header=None)\nfan_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE53386_metadata.csv\")\n\n\n\n1.8.2 Load dataset\n\nfan = load_experiment(\n    \"../data/external/aligned/mouse/Fan_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE53386\"\n)\n\n\nfan.obs['batch'] = \"FAN_1\"\nfan.obs['experiment'] = \"Fan et al., 2015\"\nfan.obs['technology'] = \"SUPeR-seq\"\n\nfan.obs = fan.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nfan = normalize_smartseq(fan, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nfan\n\nAnnData object with n_obs  n_vars = 27  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.9 Borensztein et al., 2017 GSE80810\nnf-core_tower.sh \\\n    Borensztein_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE80810.txt\n\nnf-core_tower.sh Borensztein_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Borensztein_et_al/results/samplesheet/samplesheet.csv\n\n1.9.1 Preparation\n\nborenszrtein_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE80nnn/GSE80810/matrix/GSE80810_series_matrix.txt.gz\",\n                                      skiprows=31, index_col=0).T\nborenszrtein_metadata['SRX'] = borenszrtein_metadata[['!Sample_relation']].iloc[:, :2].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\n\n\nborenszrtein_metadata['ct'] = borenszrtein_metadata['!Sample_characteristics_ch1'].iloc[:, 1].values\nborenszrtein_metadata = borenszrtein_metadata.reset_index()\n\n\nlegend = {\n    # 'developmental stage: Oocyte': 'Oocyte',\n    'developmental stage: 2-cell': '2C',\n    'developmental stage: 4-cell': '4C',\n    'developmental stage: 8-cell': '8C',\n    'developmental stage: 16-cell': '16C',\n    # 'developmental stage: 32-cell': 'UNKNOWN',\n    # 'developmental stage: 64-cell': 'UNKNOWN'\n}\n\nfor old_name, new_name in legend.items():\n    borenszrtein_metadata.loc[borenszrtein_metadata.ct == old_name, 'ct'] = new_name\n    \nborenszrtein_metadata = borenszrtein_metadata[borenszrtein_metadata.ct.isin(legend.values())].copy()\nborenszrtein_metadata = borenszrtein_metadata[borenszrtein_metadata['!Sample_characteristics_ch1'].iloc[:, 2].str.contains('wt/wt')].copy()\n\n\nborenszrtein_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE80810.txt\", index=None, header=None)\nborenszrtein_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE80810_metadata.csv\")\n\n\n\n1.9.2 Load dataset\n\nborensztein = load_experiment(\n    \"../data/external/aligned/mouse/Borensztein_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE80810\", left_on='sample_alias', right_on='ID_REF'\n)\n\n\nborensztein.obs['batch'] = \"BORENSZTEIN_1\"\nborensztein.obs['experiment'] = \"Borensztein et al., 2017\"\nborensztein.obs['technology'] = \"qRT-PCR\"\n\nborensztein.obs = borensztein.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nborensztein = normalize_smartseq(borensztein, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nborensztein\n\nAnnData object with n_obs  n_vars = 60  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.10 Stirparo et al., 2020 GSE159030\nnf-core_tower.sh \\\n    Stirparo_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --force_sratools_download \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE159030.txt\n\nnf-core_tower.sh Stirparo_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Stirparo_et_al/results/samplesheet/samplesheet.csv\n\n1.10.1 Preparation\n\nstirparo_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE159nnn/GSE159030/matrix/GSE159030_series_matrix.txt.gz\",\n                                  skiprows=27, index_col=0).T\nstirparo_metadata['SRX'] = stirparo_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\n\n\nstirparo_metadata['ct'] = stirparo_metadata['!Sample_source_name_ch1']\nstirparo_metadata = stirparo_metadata.reset_index()\n\n\nlegend = {\n    'Primitive Endoderm': 'PrE',\n    'Epiblast': 'EPI',\n}\n\nfor old_name, new_name in legend.items():\n    stirparo_metadata.loc[stirparo_metadata.ct == old_name, 'ct'] = new_name\n\nstirparo_metadata['ct'] = stirparo_metadata['!Sample_characteristics_ch1'].iloc[:, 1].str.replace('developmental stage: ', '').astype(str)\\\n                        + '-' + stirparo_metadata.ct\nstirparo_metadata = stirparo_metadata[stirparo_metadata['!Sample_characteristics_ch1'].iloc[:, 0] == 'genotype: Wild-Type'].copy()\n\n\nstirparo_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE159030.txt\", index=None, header=None)\nstirparo_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE159030_metadata.csv\")\n\n\n\n1.10.2 Load dataset\n\nstirparo = load_experiment(\n    \"../data/external/aligned/mouse/Stirparo_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE159030\", left_on='sample_alias', right_on='ID_REF'\n)\n\n\nstirparo.obs['batch'] = \"STIRPARO_1\"\nstirparo.obs['experiment'] = \"Stirparo et al., 2020\"\nstirparo.obs['technology'] = \"SMART-seq2\"\n\nstirparo.obs = stirparo.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nstirparo = normalize_smartseq(stirparo, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nstirparo\n\nAnnData object with n_obs  n_vars = 64  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.11 Xue et al., 2013 GSE44183\nnf-core_tower.sh \\\n    Xue_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE44183.txt\n\nnf-core_tower.sh Xue_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Xue_et_al/results/samplesheet/samplesheet.csv\n\n1.11.1 Preparation\n\nxue_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE44nnn/GSE44183/matrix/GSE44183-GPL13112_series_matrix.txt.gz\",\n                               skiprows=35, index_col=0).T\nxue_metadata['SRX'] = xue_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\n\n\nxue_metadata['ct'] = xue_metadata['!Sample_source_name_ch1']\nxue_metadata = xue_metadata.reset_index()\n\n\nlegend = {\n    # 'oocyte', : '',\n    # 'pronucleus': '',\n    '2-cell blastomere': '2C', \n    '4-cell blastomere': '4C',\n    '8-cell blastomere': '8C', \n    'morula': '16C'\n}\n\nfor old_name, new_name in legend.items():\n    xue_metadata.loc[xue_metadata.ct == old_name, 'ct'] = new_name\n\nxue_metadata = xue_metadata[xue_metadata.ct.isin(legend.values())].copy()\n\n\nxue_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE44183.txt\", index=None, header=None)\nxue_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE44183_metadata.csv\")\n\n\n\n1.11.2 Load dataset\n\nxue = load_experiment(\n    \"../data/external/aligned/mouse/Xue_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE44183\"\n)\n\n\nxue.obs['batch'] = \"XUE_1\"\nxue.obs['experiment'] = \"Xue et al., 2013\"\nxue.obs['technology'] = \"qRT-PCR\"\n\nxue.obs = xue.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nxue = normalize_smartseq(xue, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nxue\n\nAnnData object with n_obs  n_vars = 12  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'\n\n\n\n\n\n1.12 Yanagida et al., 2022 GSE148462\nnf-core_tower.sh \\\n    Yanagida_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --force_sratools_download \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE148462.txt\n\nnf-core_tower.sh Yanagida_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Yanagida_et_al/results/samplesheet/samplesheet.csv\n\n1.12.1 Preparation\n\nyanagida_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE148nnn/GSE148462/matrix/GSE148462_series_matrix.txt.gz\",\n                                  skiprows=29, index_col=0).T\nyanagida_metadata['SRX'] = yanagida_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\n\n\nyanagida_metadata['ct'] = 'E3.75-ICM'\n\n\nyanagida_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE148462.txt\", index=None, header=None)\nyanagida_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE148462_metadata.csv\")\n\n\n\n1.12.2 Load dataset\n\nyanagida = load_experiment(\n    \"../data/external/aligned/mouse/Yanagida_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE148462\", left_on='sample_alias', right_on='ID_REF'\n)\n\n\nyanagida.obs['batch'] = \"YANAGIDA_1\"\nyanagida.obs['experiment'] = \"Yanagida et al., 2022\"\nyanagida.obs['technology'] = \"SMART-seq2\"\n\nyanagida.obs = yanagida.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nyanagida = normalize_smartseq(yanagida, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nyanagida\n\nAnnData object with n_obs  n_vars = 48  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'"
  },
  {
    "objectID": "notebooks/01_fetchngs_mouse.html#mohammed-et-al.-2017-gse100597",
    "href": "notebooks/01_fetchngs_mouse.html#mohammed-et-al.-2017-gse100597",
    "title": "01 - NGS collection [mouse]",
    "section": "2 Mohammed et al., 2017 GSE100597",
    "text": "2 Mohammed et al., 2017 GSE100597\nnf-core_tower.sh \\\n    Mohammed_et_al \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE100597.txt\n\nnf-core_tower.sh Mohammed_et_al nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Mohammed_et_al/results/samplesheet/samplesheet.csv\n\n2.1 Preparation\n\nmohammed_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE100nnn/GSE100597/matrix/GSE100597_series_matrix.txt.gz\",\n                                  skiprows=27, index_col=0).T\nmohammed_metadata['SRX'] = mohammed_metadata[['!Sample_relation']].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\n\n\nmohammed_metadata = mohammed_metadata[mohammed_metadata['!Sample_source_name_ch1'].isin(['E3.5', 'E4.5'])]\nmohammed_metadata = mohammed_metadata[mohammed_metadata.index.str.endswith('single')].copy()\n\n\nmohammed_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE100597.txt\", index=None, header=None)\nmohammed_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE100597_metadata.csv\")\n\n\n\n2.2 Load data\n\nmohammed = load_experiment(\n    \"../data/external/aligned/mouse/Mohammed_et_al/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE100597\", left_on='sample_alias', right_on='ID_REF'\n)\n\n\nmohammed_metadata = pd.read_table(\"../data/external/aligned/mouse/Mohammed_et_al/Cell_clusters.txt\", index_col=0)\nmohammed_metadata.Lineage = mohammed_metadata.Lineage.str.replace('epiblast', 'EPI').str.replace('PE', 'PrE')\nmohammed.obs['ct'] = mohammed_metadata.loc[mohammed.obs.ct_orig, ['Stage', 'Lineage']].agg('-'.join, axis=1).values\nmohammed = mohammed[mohammed.obs.ct != 'E4.5-interm'].copy()\n\n\nmohammed.obs['batch'] = \"MOHAMMED_1\"\nmohammed.obs['experiment'] = \"Mohammed et al., 2017\"\nmohammed.obs['technology'] = \"SMART-seq2\"\n\nmohammed.obs = mohammed.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\n\n\nmohammed = normalize_smartseq(mohammed, genes_length)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nmohammed\n\nAnnData object with n_obs  n_vars = 153  55364\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig'\n    var: 'gene_symbol'"
  },
  {
    "objectID": "notebooks/01_fetchngs_mouse.html#integration",
    "href": "notebooks/01_fetchngs_mouse.html#integration",
    "title": "01 - NGS collection [mouse]",
    "section": "3 Integration",
    "text": "3 Integration\n\nimport urllib.request, json\n\ncc_url = \"https://github.com/brickmanlab/project-template/raw/master/%7B%7B%20cookiecutter.project_name%20%7D%7D/data/external/mouse_cell_cycle_genes.json\"\nwith urllib.request.urlopen(cc_url) as url:\n    cc_dict = json.load(url)\n    cc = sum(list(cc_dict.values()), [])\n\n\nadata = anndata.concat([deng, biase, posfai, goolam, boroviak, chen, nowotschin, fan, borensztein, stirparo, xue, yanagida, mohammed])\nadata.obs['stage'] = adata.obs.ct.str.replace('E3.25-|E3.5-|E3.75-|E4.5-', '', regex=True)\nadata.obs['timepoint'] = adata.obs.ct.str.split('-', expand=True).iloc[:, 0]\nadata.obs.ct = pd.Categorical(adata.obs.ct, \n                              categories=['Zygote', '2C', '4C', '8C', '16C', \n                                          'E3.25-ICM', 'E3.25-TE', \n                                          'E3.5-ICM', 'E3.5-TE', 'E3.5-EPI', 'E3.5-PrE', \n                                          'E3.75-ICM', \n                                          'E4.5-TE', 'E4.5-EPI', 'E4.5-PrE'],\n                              ordered=True)\nadata.obs_names_make_unique()\n\nadata.var['gene_ids'] = adata.var_names\nadata.var['gene_symbol'] = deng[:, adata.var_names].var['gene_symbol'].values\nadata.var.index = adata.var.gene_symbol.str.lower().values\nadata.var_names_make_unique()\n\n# remove ribosomal genes\nadata = adata[:, ~np.logical_or(adata.var_names.str.startswith(('rps','rpl')), adata.var_names == \"ct010467.1\")].copy()\n\n# remove cc genes\nadata = adata[:, ~adata.var_names.isin(cc)].copy()\n\nadata\n\nAnnData object with n_obs  n_vars = 2022  54940\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig', 'stage', 'timepoint'\n    var: 'gene_ids', 'gene_symbol'\n\n\n\nget_summary(adata)\n\nNumber of MITO genes: 0\nNumber of ERCC genes: 0\nNumber of RIBO genes: 0\n\n\n3.1 Number of cells per experiment\n\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/seaborn/categorical.py:82: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  plot_data = [np.asarray(s, float) for k, s in iter_data]\n\n\n\n\n\n3.2 Number of cells cell type\n\n\n\n\n\n3.3 QC plots"
  },
  {
    "objectID": "notebooks/01_fetchngs_mouse.html#final-adjustments",
    "href": "notebooks/01_fetchngs_mouse.html#final-adjustments",
    "title": "01 - NGS collection [mouse]",
    "section": "4 Final adjustments",
    "text": "4 Final adjustments\n\nadata\n\nAnnData object with n_obs  n_vars = 2022  54940\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig', 'stage', 'timepoint', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'\n    var: 'gene_ids', 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'\n\n\n\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0.4, multi_panel=True)\n\n\n\n\n\nsc.pp.filter_genes(adata, min_cells=10)\nsc.pp.filter_cells(adata, max_genes=20_000)\nsc.pp.filter_cells(adata, max_counts=26_000_000)\n\n# adata = adata[adata.obs.pct_counts_mt &lt; 30]\n\n\nsc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0.4, multi_panel=True)\n\nfig, ax = plt.subplots(figsize=(20, 5), sharey=True)\nsns.scatterplot(\n    x=\"total_counts\", y=\"n_genes_by_counts\", ax=ax, data=adata.obs, hue=\"ct\"\n)\n# plt.axvline(x=26_000_000, c='r', linestyle='--')\n\n\n\n\n&lt;Axes: xlabel='total_counts', ylabel='n_genes_by_counts'&gt;\n\n\n\n\n\n\nadata.layers[\"counts\"] = adata.X.copy()\n\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nadata.raw = adata\n\nadata\n\nAnnData object with n_obs  n_vars = 2004  34346\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig', 'stage', 'timepoint', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'n_genes', 'n_counts'\n    var: 'gene_ids', 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n    uns: 'log1p'\n    layers: 'counts'\n\n\n\nadata.write(\"../data/processed/01_mouse_reprocessed.h5ad\")\n\n\nsc.tl.pca(adata, svd_solver='arpack')\nsc.pl.pca(adata, color=['ct', 'batch', 'technology', 'experiment'], frameon=False, wspace=0.4, ncols=2)\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter("
  },
  {
    "objectID": "notebooks/02_human_integration.html",
    "href": "notebooks/02_human_integration.html",
    "title": "02 - human integration",
    "section": "",
    "text": "!which pip\n\n~/projects/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\nimport scvi\nimport pandas as pd\nimport scanpy as sc\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nfrom rich import print\nfrom scib_metrics.benchmark import Benchmarker\nfrom scvi.model.utils import mde\n\n\nimport warnings\nfrom lightning_fabric.plugins.environments.slurm import PossibleUserWarning\nwarnings.simplefilter(action='ignore', category=PossibleUserWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nscvi.settings.seed = 42\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n[rank: 0] Global seed set to 42\nsc.set_figure_params(figsize=(10, 6))\n\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n%config InlineBackend.figure_format='retina'\nplt.rcParams['svg.fonttype'] = 'none'\nadata = sc.read(\"../data/processed/32_human_adata.h5ad\")\nadata\n\nAnnData object with n_obs  n_vars = 2323  62754\n    obs: 'day', 'ct', 'experiment', 'technology', 'n_counts', 'n_genes', 'ct_fine'\n    layers: 'counts'\nadata.obs.experiment = adata.obs.experiment.str.replace('_', ' et al., ').astype('category')\nadata.obs['batch'] = adata.obs.experiment\n\nadata.obs['stage'] = adata.obs.ct.cat.rename_categories({\n    'Epiblast': 'EPI',\n    'Inner Cell Mass': 'ICM',\n    'Primitive Endoderm': 'PrE',\n    'Trophectoderm': 'TE'\n}).cat.reorder_categories(['Oocyte', 'Pronucleus', 'Zygote', '2C', '4C', '8C', 'Morula', 'TE', 'ICM', 'EPI', 'PrE', 'Unknown'])\n\nadata.obs['timepoint'] = adata.obs.ct.astype(str)\ntimepoint_mask = adata.obs.ct.isin(['Unknown', 'Trophectoderm', 'Inner Cell Mass', 'Primitive Endoderm', 'Epiblast'])\nadata.obs.loc[timepoint_mask, 'timepoint'] = 'E' + adata.obs.loc[timepoint_mask, 'day'].astype(str)\nadata.obs.ct = adata.obs.ct.astype('category')\nadata.obs['ct_orig'] = adata.obs.ct\nadata.obs.ct = adata.obs.ct_fine\nENSG_to_SYMBOL = pd.read_csv('../data/external/human/Homo_sapiens.GRCh38.110.ENSG_to_SYMBOL.tsv', delimiter=\" \", header=None)\nENSG_to_SYMBOL.columns = ['ensembl','symbol']\nENSG_to_SYMBOL_noName = pd.read_csv('../data/external/human/Homo_sapiens.GRCh38.110.ENSG_to_SYMBOL_noName.tsv', delimiter=\" \", header=None)\nnameless_df = pd.DataFrame(\n    data = {\n        'ensembl' : list(set(ENSG_to_SYMBOL_noName[0].tolist()) - set(ENSG_to_SYMBOL.ensembl.tolist())),\n        'symbol' : list(set(ENSG_to_SYMBOL_noName[0].tolist()) - set(ENSG_to_SYMBOL.ensembl.tolist())),\n    })\nENSG_to_SYMBOL = pd.concat([ENSG_to_SYMBOL, nameless_df])\nENSG_to_SYMBOL.set_index('ensembl', inplace=True)\nadata.var['symbol'] = ENSG_to_SYMBOL.loc[adata.var_names, 'symbol']\n# remove mitochondrial genes\nadata = adata[:, adata.var[~adata.var.symbol.str.startswith('MT-')].index].copy()\n\n# remove ribosomal genes\nadata = adata[:, adata.var[~adata.var.symbol.str.startswith(('RPS', 'RPL'))].index].copy()\n# sc.pl.highest_expr_genes(adata, n_top=20)\n# adata.uns['log1p'][\"base\"] = None\nsc.pp.highly_variable_genes(\n    adata,\n    flavor=\"cell_ranger\",\n    n_top_genes=3_000,\n    batch_key=\"batch\",\n    subset=True,\n)\nadata.shape\n\n(2323, 3000)\n# sc.pp.highly_variable_genes(\n#     adata,\n#     flavor=\"seurat_v3\",\n#     n_top_genes=3_000,\n#     layer=\"counts\",\n#     batch_key=\"batch\",\n#     subset=True,\n# )\n# adata.shape"
  },
  {
    "objectID": "notebooks/02_human_integration.html#scvi",
    "href": "notebooks/02_human_integration.html#scvi",
    "title": "02 - human integration",
    "section": "1 1. SCVI",
    "text": "1 1. SCVI\n\nimport jax\njax.devices()\n\n[gpu(id=0), gpu(id=1), gpu(id=2), gpu(id=3)]\n\n\n\nscvi.model.SCVI.setup_anndata(\n    adata, \n    layer=\"counts\", \n    batch_key=\"batch\",\n)\n\nvae = scvi.model.SCVI(adata, n_layers=2, gene_likelihood='nb')\nvae\n\nSCVI Model with the following params: \nn_hidden: 128, n_latent: 10, n_layers: 2, dropout_rate: 0.1, dispersion: gene, gene_likelihood: nb, \nlatent_distribution: normal\nTraining status: Not Trained\nModel's adata is minified?: False\n\n\n\n\n\n\n\nvae.train(use_gpu=1, max_epochs=400, early_stopping=True)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n`Trainer.fit` stopped: `max_epochs=400` reached.\n\n\nEpoch 400/400: 100%|| 400/400 [00:58&lt;00:00,  6.87it/s, v_num=1, train_loss_step=6.95e+3, train_loss_epoch=6.45e+3]Epoch 400/400: 100%|| 400/400 [00:58&lt;00:00,  6.83it/s, v_num=1, train_loss_step=6.95e+3, train_loss_epoch=6.45e+3]\n\n\n\npd.concat([vae.history['elbo_train'], vae.history['elbo_validation']], axis=1).plot.line(marker='o')\n\n&lt;Axes: xlabel='epoch'&gt;\n\n\n\n\n\n\n# fig, ax = plt.subplots(1, 12, figsize=[25, 4])\n# for idx, key in enumerate(vae.history.keys()):\n#     vae.history[key].plot(title=key, ax=ax[idx])\n\n\nadata.obsm[\"X_scVI\"] = vae.get_latent_representation(adata)\nadata.obsm[\"X_mde_scVI\"] = mde(adata.obsm[\"X_scVI\"])\n\nadata.layers['scVI_normalized'] = vae.get_normalized_expression(return_numpy=True)\n\n\nvae.save(\"../results/02_human_integration/scvi\", overwrite=True, save_anndata=True)"
  },
  {
    "objectID": "notebooks/02_human_integration.html#scanvi",
    "href": "notebooks/02_human_integration.html#scanvi",
    "title": "02 - human integration",
    "section": "2 2. SCANVI",
    "text": "2 2. SCANVI\n\nlvae = scvi.model.SCANVI.from_scvi_model(\n    vae,\n    adata=adata,\n    labels_key=\"ct\",\n    unlabeled_category=\"Unknown\",\n)\nlvae\n\nScanVI Model with the following params: \nunlabeled_category: Unknown, n_hidden: 128, n_latent: 10, n_layers: 2, dropout_rate: 0.1, dispersion: gene, \ngene_likelihood: nb\nTraining status: Not Trained\nModel's adata is minified?: False\n\n\n\n\n\n\n\nmax_epochs_scanvi = int(np.min([10, np.max([2, round(200 / 3.0)])]))\nprint(max_epochs_scanvi)\n\nlvae.train(max_epochs=15)\n\n10\n\n\n\nINFO     Training for 15 epochs.                                                                                   \nEpoch 15/15: 100%|| 15/15 [00:05&lt;00:00,  2.91it/s, v_num=1, train_loss_step=6.7e+3, train_loss_epoch=6.53e+3]Epoch 15/15: 100%|| 15/15 [00:05&lt;00:00,  2.74it/s, v_num=1, train_loss_step=6.7e+3, train_loss_epoch=6.53e+3]\n\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n`Trainer.fit` stopped: `max_epochs=15` reached.\n\n\n\n# fig, ax = plt.subplots(3, 3, figsize=[20, 14])\n# for idx, key in enumerate(lvae.history.keys()):\n#     lvae.history[key].plot(title=key, ax=ax[idx // 3 , idx % 3])\n\n\nadata.obsm[\"X_scANVI\"] = lvae.get_latent_representation(adata)\nadata.obsm[\"X_mde_scANVI\"] = mde(adata.obsm[\"X_scANVI\"])\n\nadata.layers['scANVI_normalized'] = lvae.get_normalized_expression(return_numpy=True)\n\n\nlvae.save(\"../results/02_human_integration/scanvi\", overwrite=True, save_anndata=True)"
  },
  {
    "objectID": "notebooks/02_human_integration.html#scgen",
    "href": "notebooks/02_human_integration.html#scgen",
    "title": "02 - human integration",
    "section": "3 3. scGEN",
    "text": "3 3. scGEN\n\nimport scgen\n\n\nscgen.SCGEN.setup_anndata(adata, batch_key=\"batch\", labels_key=\"ct\")\n\n\nmscgen = scgen.SCGEN(adata)\n\n\nmscgen.train(\n    max_epochs=100,\n    batch_size=32,\n    early_stopping=True,\n    early_stopping_patience=20,\n)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n\n\nEpoch 29/100:  29%|                 | 29/100 [00:13&lt;00:33,  2.10it/s, v_num=1, train_loss_step=50.1, train_loss_epoch=45]\nMonitored metric elbo_validation did not improve in the last 20 records. Best score: 698.829. Signaling Trainer to stop.\n\n\n\npd.concat([mscgen.history['elbo_train'], mscgen.history['elbo_validation']], axis=1).plot.line(marker='o')\n\n&lt;Axes: xlabel='epoch'&gt;\n\n\n\n\n\n\nadata.obsm[\"X_scgen\"] = mscgen.batch_removal().obsm['corrected_latent']\nadata.obsm[\"X_mde_scgen\"] = mde(adata.obsm[\"X_scgen\"])\n\nadata.layers['scgen_decoded_expr'] = mscgen.get_decoded_expression()\n\nINFO     Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n\n\n\nmscgen.save(\"../results/02_human_integration/scgen\", overwrite=True, save_anndata=True)"
  },
  {
    "objectID": "notebooks/02_human_integration.html#stats",
    "href": "notebooks/02_human_integration.html#stats",
    "title": "02 - human integration",
    "section": "4 4. Stats",
    "text": "4 4. Stats\n\nbm = Benchmarker(\n    adata,\n    batch_key=\"batch\",\n    label_key=\"ct\",\n    embedding_obsm_keys=[\"X_pca\", \"X_scVI\", \"X_scANVI\", \"X_scgen\"],\n    n_jobs=-1,\n)\nbm.benchmark()\nbm.plot_results_table(min_max_scale=False, save_dir='../results/02_human_integration/')\n\nComputing neighbors:   0%|                                                                                | 0/4 [00:00&lt;?, ?it/s]/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  @numba.jit()\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  @numba.jit()\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  @numba.jit()\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  @numba.jit()\n2023-12-05 19:57:29.572687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nComputing neighbors: 100%|| 4/4 [00:49&lt;00:00, 12.37s/it]\nEmbeddings:   0%|                                                                                         | 0/4 [00:00&lt;?, ?it/s]\nMetrics:   0%|                                                                                           | 0/10 [00:00&lt;?, ?it/s]\nMetrics:   0%|                                                        | 0/10 [00:00&lt;?, ?it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                           | 1/10 [00:02&lt;00:20,  2.30s/it, Bio conservation: isolated_labels]\nMetrics:  10%|                              | 1/10 [00:02&lt;00:20,  2.30s/it, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                           | 2/10 [00:05&lt;00:21,  2.64s/it, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                     | 2/10 [00:05&lt;00:21,  2.64s/it, Bio conservation: silhouette_label]\nMetrics:  30%|                                 | 3/10 [00:05&lt;00:12,  1.76s/it, Bio conservation: silhouette_label]\nMetrics:  30%|                                     | 3/10 [00:05&lt;00:12,  1.76s/it, Bio conservation: clisi_knn]\nMetrics:  40%|                                | 4/10 [00:07&lt;00:10,  1.67s/it, Bio conservation: clisi_knn]\nMetrics:  40%|                            | 4/10 [00:07&lt;00:10,  1.67s/it, Batch correction: silhouette_batch]\nMetrics:  50%|                       | 5/10 [00:20&lt;00:28,  5.77s/it, Batch correction: silhouette_batch]\nMetrics:  50%|                           | 5/10 [00:20&lt;00:28,  5.77s/it, Batch correction: ilisi_knn]\nMetrics:  60%|                     | 6/10 [00:20&lt;00:15,  3.91s/it, Batch correction: ilisi_knn]\nMetrics:  60%|                   | 6/10 [00:20&lt;00:15,  3.91s/it, Batch correction: kbet_per_label]\nMetrics:  70%|              | 7/10 [00:29&lt;00:16,  5.43s/it, Batch correction: kbet_per_label]\nMetrics:  70%|             | 7/10 [00:29&lt;00:16,  5.43s/it, Batch correction: graph_connectivity]\nMetrics:  80%|         | 8/10 [00:29&lt;00:10,  5.43s/it, Batch correction: pcr_comparison]\nEmbeddings:  25%|                                                            | 1/4 [00:30&lt;01:31, 30.54s/it]\nMetrics:   0%|                                                                                           | 0/10 [00:00&lt;?, ?it/s]\n                                                                                                                                \nMetrics:   0%|                                                        | 0/10 [00:00&lt;?, ?it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                           | 1/10 [00:00&lt;00:01,  4.56it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                              | 1/10 [00:00&lt;00:01,  4.56it/s, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                           | 2/10 [00:02&lt;00:11,  1.46s/it, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                     | 2/10 [00:02&lt;00:11,  1.46s/it, Bio conservation: silhouette_label]\nMetrics:  30%|                                     | 3/10 [00:02&lt;00:10,  1.46s/it, Bio conservation: clisi_knn]\nMetrics:  40%|                            | 4/10 [00:02&lt;00:08,  1.46s/it, Batch correction: silhouette_batch]\nMetrics:  50%|                       | 5/10 [00:03&lt;00:03,  1.45it/s, Batch correction: silhouette_batch]\nMetrics:  50%|                           | 5/10 [00:03&lt;00:03,  1.45it/s, Batch correction: ilisi_knn]\nMetrics:  60%|                   | 6/10 [00:03&lt;00:02,  1.45it/s, Batch correction: kbet_per_label]\nMetrics:  70%|              | 7/10 [00:05&lt;00:02,  1.25it/s, Batch correction: kbet_per_label]\nMetrics:  70%|             | 7/10 [00:05&lt;00:02,  1.25it/s, Batch correction: graph_connectivity]\nMetrics:  80%|         | 8/10 [00:05&lt;00:01,  1.25it/s, Batch correction: pcr_comparison]\nEmbeddings:  50%|                                        | 2/4 [00:36&lt;00:32, 16.34s/it]\nMetrics:   0%|                                                                                           | 0/10 [00:00&lt;?, ?it/s]\n                                                                                                                                \nMetrics:   0%|                                                        | 0/10 [00:00&lt;?, ?it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                              | 1/10 [00:00&lt;00:00, 17.03it/s, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                           | 2/10 [00:01&lt;00:05,  1.38it/s, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                     | 2/10 [00:01&lt;00:05,  1.38it/s, Bio conservation: silhouette_label]\nMetrics:  30%|                                     | 3/10 [00:01&lt;00:05,  1.38it/s, Bio conservation: clisi_knn]\nMetrics:  40%|                            | 4/10 [00:01&lt;00:04,  1.38it/s, Batch correction: silhouette_batch]\nMetrics:  50%|                       | 5/10 [00:01&lt;00:01,  3.86it/s, Batch correction: silhouette_batch]\nMetrics:  50%|                           | 5/10 [00:01&lt;00:01,  3.86it/s, Batch correction: ilisi_knn]\nMetrics:  60%|                   | 6/10 [00:01&lt;00:01,  3.86it/s, Batch correction: kbet_per_label]\nMetrics:  70%|              | 7/10 [00:03&lt;00:01,  1.87it/s, Batch correction: kbet_per_label]\nMetrics:  70%|             | 7/10 [00:03&lt;00:01,  1.87it/s, Batch correction: graph_connectivity]\nEmbeddings:  75%|                    | 3/4 [00:40&lt;00:10, 10.49s/it]\nMetrics:   0%|                                                                                           | 0/10 [00:00&lt;?, ?it/s]\n                                                                                                                                \nMetrics:   0%|                                                        | 0/10 [00:00&lt;?, ?it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                           | 1/10 [00:00&lt;00:02,  4.01it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                              | 1/10 [00:00&lt;00:02,  4.01it/s, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                           | 2/10 [00:02&lt;00:11,  1.45s/it, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                     | 2/10 [00:02&lt;00:11,  1.45s/it, Bio conservation: silhouette_label]\nMetrics:  30%|                                     | 3/10 [00:02&lt;00:10,  1.45s/it, Bio conservation: clisi_knn]\nMetrics:  40%|                            | 4/10 [00:02&lt;00:08,  1.45s/it, Batch correction: silhouette_batch]\nMetrics:  50%|                       | 5/10 [00:03&lt;00:03,  1.40it/s, Batch correction: silhouette_batch]\nMetrics:  50%|                           | 5/10 [00:03&lt;00:03,  1.40it/s, Batch correction: ilisi_knn]\nMetrics:  60%|                   | 6/10 [00:03&lt;00:02,  1.40it/s, Batch correction: kbet_per_label]\nMetrics:  70%|              | 7/10 [00:04&lt;00:01,  1.54it/s, Batch correction: kbet_per_label]\nMetrics:  70%|             | 7/10 [00:04&lt;00:01,  1.54it/s, Batch correction: graph_connectivity]\nMetrics:  80%|         | 8/10 [00:04&lt;00:01,  1.54it/s, Batch correction: pcr_comparison]\nEmbeddings: 100%|| 4/4 [00:46&lt;00:00, 11.55s/it]\n\n                                                                                                                                \n\n\nINFO     Late epiblast consists of a single batch or is too small. Skip.                                           \nINFO     Trophectoderm_10.0 consists of a single batch or is too small. Skip.                                      \nINFO     Trophectoderm_8.0 consists of a single batch or is too small. Skip.                                       \nINFO     Trophectoderm_9.0 consists of a single batch or is too small. Skip.                                       \nINFO     Late epiblast consists of a single batch or is too small. Skip.                                           \nINFO     Trophectoderm_10.0 consists of a single batch or is too small. Skip.                                      \nINFO     Trophectoderm_8.0 consists of a single batch or is too small. Skip.                                       \nINFO     Trophectoderm_9.0 consists of a single batch or is too small. Skip.                                       \nINFO     Late epiblast consists of a single batch or is too small. Skip.                                           \nINFO     Trophectoderm_10.0 consists of a single batch or is too small. Skip.                                      \nINFO     Trophectoderm_8.0 consists of a single batch or is too small. Skip.                                       \nINFO     Trophectoderm_9.0 consists of a single batch or is too small. Skip.                                       \nINFO     Late epiblast consists of a single batch or is too small. Skip.                                           \nINFO     Trophectoderm_10.0 consists of a single batch or is too small. Skip.                                      \nINFO     Trophectoderm_8.0 consists of a single batch or is too small. Skip.                                       \nINFO     Trophectoderm_9.0 consists of a single batch or is too small. Skip.                                       \n\n\n\n\n\n&lt;plottable.table.Table at 0x7f5f707142e0&gt;\n\n\n\nsc.pl.pca(adata, color=['ct', 'stage'])\nsc.pl.embedding(adata, color=['ct', 'stage'], basis='X_mde_scVI')\nsc.pl.embedding(adata, color=['ct', 'stage'], basis='X_mde_scANVI')\nsc.pl.embedding(adata, color=['ct', 'stage'], basis='X_mde_scgen')"
  },
  {
    "objectID": "notebooks/02_human_tunning.html",
    "href": "notebooks/02_human_tunning.html",
    "title": "02 - human tunning",
    "section": "",
    "text": "This notebook contains multiple methods on how we trained the model. We summarize below which params were helpful in generating better integration.\n!which pip\n\n~/projects/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\nimport scvi\nimport scanpy as sc\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nfrom rich import print\nfrom scib_metrics.benchmark import Benchmarker\nfrom scvi.model.utils import mde\n\n\nimport warnings\nfrom lightning_fabric.plugins.environments.slurm import PossibleUserWarning\nwarnings.simplefilter(action='ignore', category=PossibleUserWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nscvi.settings.seed = 42\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n[rank: 0] Global seed set to 42\nsc.set_figure_params(figsize=(10, 6))\n\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n%config InlineBackend.figure_format='retina'\n\nplt.rcParams['svg.fonttype'] = 'none'\nadata = sc.read(\"../data/processed/32_human_adata.h5ad\")\nadata\n\nAnnData object with n_obs  n_vars = 2323  62754\n    obs: 'day', 'ct', 'experiment', 'technology', 'n_counts', 'n_genes', 'ct_fine'\n    layers: 'counts'\nadata.obs.experiment.unique().tolist()\n\n['Meistermann_2021',\n 'Petropoulos_2016',\n 'Xiang_2020',\n 'Yan_2013',\n 'Yanagida_2021',\n 'Xue_2013']\nsc.pp.highly_variable_genes(\n    adata,\n    flavor=\"seurat_v3\",\n    n_top_genes=3_000,\n    layer=\"counts\",\n    batch_key=\"experiment\",\n    subset=True,\n)"
  },
  {
    "objectID": "notebooks/02_human_tunning.html#pimp-my-model-ray-tunner",
    "href": "notebooks/02_human_tunning.html#pimp-my-model-ray-tunner",
    "title": "02 - human tunning",
    "section": "1 3. Pimp my model: ray tunner",
    "text": "1 3. Pimp my model: ray tunner\n\nimport ray\nimport jax\nimport os\n\nfrom ray import tune\nfrom scvi import autotune\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n\n\njax.devices()\n\n[gpu(id=0), gpu(id=1)]\n\n\n\nref_tuner = sc.AnnData(adata.layers[\"counts\"])\nref_tuner.obs = adata.obs[[\"technology\", \"experiment\"]].copy()\n\nmodel_cls = scvi.model.SCVI\nmodel_cls.setup_anndata(ref_tuner, \n                        batch_key=\"experiment\")\n\nscvi_tuner = autotune.ModelTuner(model_cls)\n\n\nscvi_tuner.info()\n\nModelTuner registry for SCVI\n\n\n\n                  Tunable hyperparameters                  \n\n      Hyperparameter       Default value     Source    \n\n         n_hidden               128           VAE      \n         n_latent               10            VAE      \n         n_layers                1            VAE      \n       dropout_rate             0.1           VAE      \n        dispersion             gene           VAE      \n     gene_likelihood           zinb           VAE      \n   latent_distribution        normal          VAE      \n    encode_covariates          False          VAE      \n deeply_inject_covariates      True           VAE      \n      use_batch_norm           both           VAE      \n      use_layer_norm           none           VAE      \n        optimizer              Adam       TrainingPlan \n            lr                 0.001      TrainingPlan \n       weight_decay            1e-06      TrainingPlan \n           eps                 0.01       TrainingPlan \n    n_steps_kl_warmup          None       TrainingPlan \n    n_epochs_kl_warmup          400       TrainingPlan \n   reduce_lr_on_plateau        False      TrainingPlan \n        lr_factor               0.6       TrainingPlan \n       lr_patience              30        TrainingPlan \n       lr_threshold             0.0       TrainingPlan \n          lr_min                 0        TrainingPlan \n      max_kl_weight             1.0       TrainingPlan \n      min_kl_weight             0.0       TrainingPlan \n\n\n\n\n       Available metrics        \n\n     Metric          Mode    \n\n validation_loss     min     \n\n\n\n\n                         Default search space                         \n\n Hyperparameter  Sample function   Arguments   Keyword arguments \n\n    n_hidden         choice       [[64, 128]]         {}         \n\n\n\n\n\nsearch_space = {\n    \"gene_likelihood\": tune.choice([\"nb\", \"zinb\"]),\n    \"dispersion\": tune.choice([\"gene\", \"gene-batch\"]),\n    \"n_hidden\": tune.choice([128, 144, 256]),\n    \"n_layers\": tune.choice([2, 3, 4, 5]),\n    \"lr\": tune.loguniform(1e-4, 0.6),\n}\n\n\nray.init(\n    log_to_driver=False,\n    num_cpus=10,\n    num_gpus=2,\n)\n\n2023-12-07 12:27:30,713 INFO worker.py:1636 -- Started a local Ray instance.\n\n\n\n    \n        Ray\n        \n            \n                \n            \n        \n        \n\n\n\nPython version:\n3.10.11\n\n\nRay version:\n2.5.1\n\n\n\n\n    \n\n\n\n\nresults = scvi_tuner.fit(\n    ref_tuner,\n    metric=\"validation_loss\",\n    search_space=search_space,\n    num_samples=50,\n    max_epochs=100,\n)\n\n\n  \n    \n      Tune Status\n      \n\n\n\nCurrent time:\n2023-12-07 12:46:54\n\n\nRunning for:\n00:19:16.27\n\n\nMemory:\n469.6/4031.0 GiB\n\n\n\n\n\n\n\n1.1 System Info\nUsing AsyncHyperBand: num_stopped=19\nBracket: Iter 64.000: -9342.2001953125 | Iter 32.000: -9850.13427734375 | Iter 16.000: -10166.60205078125 | Iter 8.000: -10333.1259765625 | Iter 4.000: -11369.15234375 | Iter 2.000: -13270.201171875 | Iter 1.000: -17707.0654296875\nLogical resource usage: 1.0/10 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:RTX)\n\n\n\n\n\n1.2 Messages\nNumber of errored trials: 31\n\n\n\n\nTrial name\n# failures\nerror file\n\n\n\n\n_trainable_f3b1a06f\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_f3b1a06f_7_dispersion=gene-batch,gene_likelihood=zinb,lr=0.4930,n_hidden=128,n_layers=4_2023-12-07_12-32-46/error.txt\n\n\n_trainable_7ca2ed73\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_7ca2ed73_9_dispersion=gene,gene_likelihood=nb,lr=0.4233,n_hidden=256,n_layers=5_2023-12-07_12-36-10/error.txt\n\n\n_trainable_eec818de\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_eec818de_16_dispersion=gene,gene_likelihood=nb,lr=0.2143,n_hidden=256,n_layers=4_2023-12-07_12-38-30/error.txt\n\n\n_trainable_d90facee\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_d90facee_19_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1319,n_hidden=256,n_layers=2_2023-12-07_12-40-05/error.txt\n\n\n_trainable_f12e443a\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_f12e443a_21_dispersion=gene-batch,gene_likelihood=nb,lr=0.3660,n_hidden=144,n_layers=3_2023-12-07_12-41-01/error.txt\n\n\n_trainable_bcd5fd32\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_bcd5fd32_22_dispersion=gene,gene_likelihood=nb,lr=0.2291,n_hidden=144,n_layers=2_2023-12-07_12-41-15/error.txt\n\n\n_trainable_b8440d6d\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_b8440d6d_23_dispersion=gene-batch,gene_likelihood=nb,lr=0.1749,n_hidden=144,n_layers=2_2023-12-07_12-42-23/error.txt\n\n\n_trainable_e9fe5792\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_e9fe5792_27_dispersion=gene,gene_likelihood=zinb,lr=0.1686,n_hidden=128,n_layers=3_2023-12-07_12-42-56/error.txt\n\n\n_trainable_0d91ae4a\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_0d91ae4a_28_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0855,n_hidden=256,n_layers=4_2023-12-07_12-43-01/error.txt\n\n\n_trainable_96bc8875\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_96bc8875_29_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3820,n_hidden=128,n_layers=3_2023-12-07_12-43-23/error.txt\n\n\n_trainable_f490d69c\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_f490d69c_30_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1207,n_hidden=256,n_layers=4_2023-12-07_12-43-33/error.txt\n\n\n_trainable_73dff5ab\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_73dff5ab_31_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3882,n_hidden=128,n_layers=3_2023-12-07_12-43-42/error.txt\n\n\n_trainable_445f139a\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_445f139a_32_dispersion=gene,gene_likelihood=zinb,lr=0.1255,n_hidden=256,n_layers=4_2023-12-07_12-43-52/error.txt\n\n\n_trainable_409c3774\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_409c3774_33_dispersion=gene-batch,gene_likelihood=zinb,lr=0.4378,n_hidden=128,n_layers=3_2023-12-07_12-44-01/error.txt\n\n\n_trainable_b03bca9b\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_b03bca9b_34_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0874,n_hidden=256,n_layers=4_2023-12-07_12-44-10/error.txt\n\n\n_trainable_2c90d960\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_2c90d960_35_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3791,n_hidden=128,n_layers=3_2023-12-07_12-44-19/error.txt\n\n\n_trainable_5fdc457e\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_5fdc457e_36_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0968,n_hidden=256,n_layers=4_2023-12-07_12-44-28/error.txt\n\n\n_trainable_9b2eb7fc\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_9b2eb7fc_37_dispersion=gene-batch,gene_likelihood=zinb,lr=0.5606,n_hidden=128,n_layers=3_2023-12-07_12-44-38/error.txt\n\n\n_trainable_f3b20f38\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_f3b20f38_38_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0796,n_hidden=256,n_layers=4_2023-12-07_12-44-48/error.txt\n\n\n_trainable_4e50382e\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_4e50382e_39_dispersion=gene-batch,gene_likelihood=zinb,lr=0.2660,n_hidden=128,n_layers=3_2023-12-07_12-44-57/error.txt\n\n\n_trainable_0b8ff26b\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_0b8ff26b_40_dispersion=gene,gene_likelihood=zinb,lr=0.0690,n_hidden=256,n_layers=4_2023-12-07_12-45-06/error.txt\n\n\n_trainable_b5cc9a84\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_b5cc9a84_41_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3677,n_hidden=128,n_layers=3_2023-12-07_12-45-16/error.txt\n\n\n_trainable_94926e6b\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_94926e6b_42_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0885,n_hidden=256,n_layers=4_2023-12-07_12-45-25/error.txt\n\n\n_trainable_d51b9768\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_d51b9768_43_dispersion=gene-batch,gene_likelihood=zinb,lr=0.4548,n_hidden=128,n_layers=2_2023-12-07_12-45-35/error.txt\n\n\n_trainable_6184ccd3\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_6184ccd3_44_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1118,n_hidden=256,n_layers=4_2023-12-07_12-45-45/error.txt\n\n\n_trainable_3bd44daf\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_3bd44daf_45_dispersion=gene,gene_likelihood=zinb,lr=0.3045,n_hidden=128,n_layers=3_2023-12-07_12-45-55/error.txt\n\n\n_trainable_50e7b732\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_50e7b732_46_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1431,n_hidden=256,n_layers=4_2023-12-07_12-46-04/error.txt\n\n\n_trainable_5a7c99e4\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_5a7c99e4_47_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3950,n_hidden=128,n_layers=3_2023-12-07_12-46-14/error.txt\n\n\n_trainable_e1a7a955\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_e1a7a955_48_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0784,n_hidden=256,n_layers=4_2023-12-07_12-46-23/error.txt\n\n\n_trainable_868afbe8\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_868afbe8_49_dispersion=gene,gene_likelihood=zinb,lr=0.4845,n_hidden=128,n_layers=3_2023-12-07_12-46-32/error.txt\n\n\n_trainable_2db3e93e\n1\n/maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_2db3e93e_50_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1057,n_hidden=256,n_layers=4_2023-12-07_12-46-42/error.txt\n\n\n\n\n\n\n\n\n1.3 Trial Status\n\n\n\nTrial name\nstatus\nloc\ngene_likelihood\ndispersion\nn_hidden\nn_layers\nlr\nvalidation_loss\n\n\n\n\n_trainable_78d3bc3d\nTERMINATED\n10.84.5.120:3533767\nzinb\ngene-batch\n128\n2\n0.0365808\n11194.1\n\n\n_trainable_c1b116e0\nTERMINATED\n10.84.5.120:3534500\nzinb\ngene\n256\n5\n0.00183116\n10236.2\n\n\n_trainable_7bb06efc\nTERMINATED\n10.84.5.120:3533767\nzinb\ngene\n144\n2\n0.00159217\n10415.3\n\n\n_trainable_a636a222\nTERMINATED\n10.84.5.120:3533767\nnb\ngene\n256\n3\n0.000100827\n24027.9\n\n\n_trainable_28417f3c\nTERMINATED\n10.84.5.120:3533767\nzinb\ngene-batch\n128\n2\n0.000106731\n14757.4\n\n\n_trainable_128c3ced\nTERMINATED\n10.84.5.120:3533767\nnb\ngene\n144\n4\n0.0210739\n13192.6\n\n\n_trainable_88017ea7\nTERMINATED\n10.84.5.120:3534500\nzinb\ngene-batch\n128\n4\n0.0243514\n10226.9\n\n\n_trainable_7d239652\nTERMINATED\n10.84.5.120:3562315\nnb\ngene-batch\n128\n5\n0.00167404\n23036.1\n\n\n_trainable_44e62c77\nTERMINATED\n10.84.5.120:3562315\nzinb\ngene\n128\n4\n0.00910985\n9.12925e+07\n\n\n_trainable_bf57f58a\nTERMINATED\n10.84.5.120:3562315\nzinb\ngene\n144\n2\n0.00269743\n9358.84\n\n\n_trainable_b2b14e20\nTERMINATED\n10.84.5.120:3563526\nzinb\ngene\n144\n3\n0.000574114\n14023.4\n\n\n_trainable_9385462d\nTERMINATED\n10.84.5.120:3563526\nnb\ngene-batch\n144\n2\n0.000251087\n22836\n\n\n_trainable_28fbe85a\nTERMINATED\n10.84.5.120:3563526\nzinb\ngene-batch\n128\n4\n0.00103395\n13270.2\n\n\n_trainable_c37af702\nTERMINATED\n10.84.5.120:3567942\nzinb\ngene-batch\n144\n5\n0.0148429\n6.75583e+06\n\n\n_trainable_4e89fe81\nTERMINATED\n10.84.5.120:3567942\nnb\ngene\n144\n2\n0.0107417\n1.85768e+07\n\n\n_trainable_3235ef47\nTERMINATED\n10.84.5.120:3571980\nnb\ngene-batch\n144\n5\n0.00592304\n20656.7\n\n\n_trainable_920c5342\nTERMINATED\n10.84.5.120:3580420\nnb\ngene\n144\n4\n0.01458\n5.86773e+30\n\n\n_trainable_d9d9c50f\nTERMINATED\n10.84.5.120:3580420\nzinb\ngene-batch\n144\n4\n0.00589932\n100343\n\n\n_trainable_8094b046\nTERMINATED\n10.84.5.120:3580420\nnb\ngene\n128\n2\n0.00140256\n21310.5\n\n\n_trainable_f3b1a06f\nERROR\n10.84.5.120:3533767\nzinb\ngene-batch\n128\n4\n0.492984\n\n\n\n_trainable_7ca2ed73\nERROR\n10.84.5.120:3534500\nnb\ngene\n256\n5\n0.423289\n\n\n\n_trainable_eec818de\nERROR\n10.84.5.120:3563526\nnb\ngene\n256\n4\n0.214329\n\n\n\n_trainable_d90facee\nERROR\n10.84.5.120:3567942\nzinb\ngene-batch\n256\n2\n0.131873\n\n\n\n_trainable_f12e443a\nERROR\n10.84.5.120:3571980\nnb\ngene-batch\n144\n3\n0.365967\n\n\n\n_trainable_bcd5fd32\nERROR\n10.84.5.120:3562315\nnb\ngene\n144\n2\n0.229075\n\n\n\n_trainable_b8440d6d\nERROR\n10.84.5.120:3579542\nnb\ngene-batch\n144\n2\n0.174888\n\n\n\n_trainable_e9fe5792\nERROR\n10.84.5.120:3580420\nzinb\ngene\n128\n3\n0.168562\n\n\n\n_trainable_0d91ae4a\nERROR\n10.84.5.120:3582476\nzinb\ngene-batch\n256\n4\n0.0855489\n\n\n\n_trainable_96bc8875\nERROR\n10.84.5.120:3584135\nzinb\ngene-batch\n128\n3\n0.381998\n\n\n\n_trainable_f490d69c\nERROR\n10.84.5.120:3584403\nzinb\ngene-batch\n256\n4\n0.120705\n\n\n\n_trainable_73dff5ab\nERROR\n10.84.5.120:3584657\nzinb\ngene-batch\n128\n3\n0.388218\n\n\n\n_trainable_445f139a\nERROR\n10.84.5.120:3586141\nzinb\ngene\n256\n4\n0.125464\n\n\n\n_trainable_409c3774\nERROR\n10.84.5.120:3586416\nzinb\ngene-batch\n128\n3\n0.437846\n\n\n\n_trainable_b03bca9b\nERROR\n10.84.5.120:3586698\nzinb\ngene-batch\n256\n4\n0.0874067\n\n\n\n_trainable_2c90d960\nERROR\n10.84.5.120:3587753\nzinb\ngene-batch\n128\n3\n0.379138\n\n\n\n_trainable_5fdc457e\nERROR\n10.84.5.120:3588396\nzinb\ngene-batch\n256\n4\n0.0967505\n\n\n\n_trainable_9b2eb7fc\nERROR\n10.84.5.120:3588644\nzinb\ngene-batch\n128\n3\n0.560638\n\n\n\n_trainable_f3b20f38\nERROR\n10.84.5.120:3589750\nzinb\ngene-batch\n256\n4\n0.0796038\n\n\n\n_trainable_4e50382e\nERROR\n10.84.5.120:3590401\nzinb\ngene-batch\n128\n3\n0.265968\n\n\n\n_trainable_0b8ff26b\nERROR\n10.84.5.120:3590703\nzinb\ngene\n256\n4\n0.0689615\n\n\n\n_trainable_b5cc9a84\nERROR\n10.84.5.120:3591788\nzinb\ngene-batch\n128\n3\n0.367703\n\n\n\n_trainable_94926e6b\nERROR\n10.84.5.120:3592431\nzinb\ngene-batch\n256\n4\n0.0885429\n\n\n\n_trainable_d51b9768\nERROR\n10.84.5.120:3592687\nzinb\ngene-batch\n128\n2\n0.454769\n\n\n\n_trainable_6184ccd3\nERROR\n10.84.5.120:3593005\nzinb\ngene-batch\n256\n4\n0.111828\n\n\n\n_trainable_3bd44daf\nERROR\n10.84.5.120:3594445\nzinb\ngene\n128\n3\n0.304513\n\n\n\n_trainable_50e7b732\nERROR\n10.84.5.120:3594737\nzinb\ngene-batch\n256\n4\n0.14314\n\n\n\n_trainable_5a7c99e4\nERROR\n10.84.5.120:3595061\nzinb\ngene-batch\n128\n3\n0.395037\n\n\n\n_trainable_e1a7a955\nERROR\n10.84.5.120:3596494\nzinb\ngene-batch\n256\n4\n0.078421\n\n\n\n_trainable_868afbe8\nERROR\n10.84.5.120:3596744\nzinb\ngene\n128\n3\n0.484486\n\n\n\n_trainable_2db3e93e\nERROR\n10.84.5.120:3597015\nzinb\ngene-batch\n256\n4\n0.105745\n\n\n\n\n\n\n  \n\n\n\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1559: RuntimeWarning: All-NaN slice encountered\n  r, k = function_base._ureduce(a,\n2023-12-07 12:33:20,350 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_f3b1a06f\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3533767, ip=10.84.5.120, actor_id=931a50e60d09eec32f47c4b801000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:37:14,553 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_7ca2ed73\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3534500, ip=10.84.5.120, actor_id=7dba3ac8be6db7e4f191317f01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:38:48,178 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_eec818de\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3563526, ip=10.84.5.120, actor_id=e3c2bfaf1ba3402aa66931fe01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:40:13,599 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_d90facee\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3567942, ip=10.84.5.120, actor_id=a0af97a46c5f3b71ed2d5d0901000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:41:17,118 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_f12e443a\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3571980, ip=10.84.5.120, actor_id=5d31c645fe01d93a033ab16201000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:42:24,432 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_bcd5fd32\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3562315, ip=10.84.5.120, actor_id=025924cfdf52bf58bc61bcc501000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:42:38,601 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_b8440d6d\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3579542, ip=10.84.5.120, actor_id=d52b1a4674cf5211a35b220b01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:43:04,718 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_e9fe5792\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3580420, ip=10.84.5.120, actor_id=ac5ec889bcf9738b52adcb3301000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:43:25,515 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_0d91ae4a\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3582476, ip=10.84.5.120, actor_id=3cb3d4c36c2b36294b67dd5d01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:43:35,178 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_96bc8875\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3584135, ip=10.84.5.120, actor_id=f9bd48d236d43db8f6a8fa4b01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:43:44,312 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_f490d69c\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3584403, ip=10.84.5.120, actor_id=5d3a9b6a0c4350847bf0897d01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:43:54,005 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_73dff5ab\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3584657, ip=10.84.5.120, actor_id=d8f15f010e4bca6031438b5d01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:44:03,061 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_445f139a\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3586141, ip=10.84.5.120, actor_id=fe3e64dc09326a99df1df8aa01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:44:12,058 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_409c3774\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3586416, ip=10.84.5.120, actor_id=1033c2965773573235c58d3c01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:44:21,747 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_b03bca9b\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3586698, ip=10.84.5.120, actor_id=9868484fba2be8ba05fe2ceb01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:44:30,419 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_2c90d960\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3587753, ip=10.84.5.120, actor_id=4fe2ee44cc83ab4ad4fc3fc601000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:44:40,764 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_5fdc457e\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3588396, ip=10.84.5.120, actor_id=ab6a66223879470dfbbd02f501000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:44:49,807 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_9b2eb7fc\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3588644, ip=10.84.5.120, actor_id=e65abe3399a5f6c232198e1601000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:44:59,597 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_f3b20f38\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3589750, ip=10.84.5.120, actor_id=4208197b5733a8fe85e3fbe601000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:45:08,542 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_4e50382e\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3590401, ip=10.84.5.120, actor_id=18219a0034099ab920900d9c01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:45:18,817 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_0b8ff26b\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3590703, ip=10.84.5.120, actor_id=1f0c1a91be57bf97119c1ce301000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:45:27,854 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_b5cc9a84\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3591788, ip=10.84.5.120, actor_id=321149c37ebb59bf450462cc01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:45:37,637 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_94926e6b\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3592431, ip=10.84.5.120, actor_id=563946fedd590cbc67cef29901000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:45:47,466 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_d51b9768\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3592687, ip=10.84.5.120, actor_id=c71d2be6f00784e46aaeeddf01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:45:57,298 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_6184ccd3\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3593005, ip=10.84.5.120, actor_id=ba42abb9d3bdc8f36a19e7eb01000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:46:06,923 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_3bd44daf\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3594445, ip=10.84.5.120, actor_id=e30245cccc14cd972ecdd07501000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:46:16,173 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_50e7b732\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3594737, ip=10.84.5.120, actor_id=3686f38befddeafa70e2c81001000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:46:25,304 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_5a7c99e4\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3595061, ip=10.84.5.120, actor_id=e07943311f97889261fbeb0701000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:46:35,584 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_e1a7a955\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3596494, ip=10.84.5.120, actor_id=33282de6ca06ddcb469f81b601000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:46:44,275 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_868afbe8\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3596744, ip=10.84.5.120, actor_id=7c7d89d36e304eca004dbec001000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:46:53,988 ERROR tune_controller.py:873 -- Trial task failed for trial _trainable_2db3e93e\nTraceback (most recent call last):\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n    result = ray.get(future)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/_private/worker.py\", line 2540, in get\n    raise value.as_instanceof_cause()\nray.exceptions.RayTaskError(ValueError): ray::ImplicitFunc.train() (pid=3597015, ip=10.84.5.120, actor_id=f63e4863590b747e280d995401000000, repr=_trainable)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 332, in _inner\n    return inner(config, checkpoint_dir=None)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 324, in inner\n    return trainable(config, **fn_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/autotune/_manager.py\", line 400, in _trainable\n    model.train(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/model/base/_training_mixin.py\", line 88, in train\n    return runner()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainrunner.py\", line 99, in __call__\n    self.trainer.fit(self.training_plan, self.data_splitter)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainer.py\", line 186, in fit\n    super().fit(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n    call._call_and_handle_interrupt(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n    results = self._run_stage()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n    self.fit_loop.run()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n    self.advance()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n    self.advance(data_fetcher)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n    call._call_lightning_module_hook(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n    optimizer.step(closure=optimizer_closure)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n    return optimizer.step(closure=closure, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n    out = func(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 33, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/optim/adam.py\", line 121, in step\n    loss = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n    closure_result = closure()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n    self._result = self.closure(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n    step_output = self._step_fn()\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 307, in _training_step\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 367, in training_step\n    return self.model.training_step(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 342, in training_step\n    _, _, scvi_loss = self.forward(batch, loss_kwargs=self.loss_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/train/_trainingplans.py\", line 278, in forward\n    return self.module(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 199, in forward\n    return _generic_forward(\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 743, in _generic_forward\n    inference_outputs = module.inference(**inference_inputs, **inference_kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_base_module.py\", line 303, in inference\n    return self._regular_inference(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/base/_decorators.py\", line 32, in auto_transfer_args\n    return fn(self, *args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/module/_vae.py\", line 336, in _regular_inference\n    qz, z = self.z_encoder(encoder_input, batch_index, *categorical_input)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/nn/_base_components.py\", line 289, in forward\n    dist = Normal(q_m, q_v.sqrt())\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/normal.py\", line 56, in __init__\n    super().__init__(batch_shape, validate_args=validate_args)\n  File \"/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/torch/distributions/distribution.py\", line 62, in __init__\n    raise ValueError(\nValueError: Expected parameter loc (Tensor of shape (128, 10)) of distribution Normal(loc: torch.Size([128, 10]), scale: torch.Size([128, 10])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan],\n        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;AddmmBackward0&gt;)\n2023-12-07 12:46:54,041 ERROR tune.py:1107 -- Trials did not complete: [_trainable_f3b1a06f, _trainable_7ca2ed73, _trainable_eec818de, _trainable_d90facee, _trainable_f12e443a, _trainable_bcd5fd32, _trainable_b8440d6d, _trainable_e9fe5792, _trainable_0d91ae4a, _trainable_96bc8875, _trainable_f490d69c, _trainable_73dff5ab, _trainable_445f139a, _trainable_409c3774, _trainable_b03bca9b, _trainable_2c90d960, _trainable_5fdc457e, _trainable_9b2eb7fc, _trainable_f3b20f38, _trainable_4e50382e, _trainable_0b8ff26b, _trainable_b5cc9a84, _trainable_94926e6b, _trainable_d51b9768, _trainable_6184ccd3, _trainable_3bd44daf, _trainable_50e7b732, _trainable_5a7c99e4, _trainable_e1a7a955, _trainable_868afbe8, _trainable_2db3e93e]\n2023-12-07 12:46:54,043 INFO tune.py:1111 -- Total run time: 1156.54 seconds (1156.25 seconds for the tuning loop).\n2023-12-07 12:46:54,113 WARNING experiment_analysis.py:910 -- Failed to read the results for 31 trials:\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_f3b1a06f_7_dispersion=gene-batch,gene_likelihood=zinb,lr=0.4930,n_hidden=128,n_layers=4_2023-12-07_12-32-46\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_7ca2ed73_9_dispersion=gene,gene_likelihood=nb,lr=0.4233,n_hidden=256,n_layers=5_2023-12-07_12-36-10\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_eec818de_16_dispersion=gene,gene_likelihood=nb,lr=0.2143,n_hidden=256,n_layers=4_2023-12-07_12-38-30\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_d90facee_19_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1319,n_hidden=256,n_layers=2_2023-12-07_12-40-05\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_f12e443a_21_dispersion=gene-batch,gene_likelihood=nb,lr=0.3660,n_hidden=144,n_layers=3_2023-12-07_12-41-01\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_bcd5fd32_22_dispersion=gene,gene_likelihood=nb,lr=0.2291,n_hidden=144,n_layers=2_2023-12-07_12-41-15\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_b8440d6d_23_dispersion=gene-batch,gene_likelihood=nb,lr=0.1749,n_hidden=144,n_layers=2_2023-12-07_12-42-23\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_e9fe5792_27_dispersion=gene,gene_likelihood=zinb,lr=0.1686,n_hidden=128,n_layers=3_2023-12-07_12-42-56\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_0d91ae4a_28_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0855,n_hidden=256,n_layers=4_2023-12-07_12-43-01\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_96bc8875_29_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3820,n_hidden=128,n_layers=3_2023-12-07_12-43-23\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_f490d69c_30_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1207,n_hidden=256,n_layers=4_2023-12-07_12-43-33\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_73dff5ab_31_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3882,n_hidden=128,n_layers=3_2023-12-07_12-43-42\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_445f139a_32_dispersion=gene,gene_likelihood=zinb,lr=0.1255,n_hidden=256,n_layers=4_2023-12-07_12-43-52\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_409c3774_33_dispersion=gene-batch,gene_likelihood=zinb,lr=0.4378,n_hidden=128,n_layers=3_2023-12-07_12-44-01\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_b03bca9b_34_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0874,n_hidden=256,n_layers=4_2023-12-07_12-44-10\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_2c90d960_35_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3791,n_hidden=128,n_layers=3_2023-12-07_12-44-19\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_5fdc457e_36_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0968,n_hidden=256,n_layers=4_2023-12-07_12-44-28\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_9b2eb7fc_37_dispersion=gene-batch,gene_likelihood=zinb,lr=0.5606,n_hidden=128,n_layers=3_2023-12-07_12-44-38\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_f3b20f38_38_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0796,n_hidden=256,n_layers=4_2023-12-07_12-44-48\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_4e50382e_39_dispersion=gene-batch,gene_likelihood=zinb,lr=0.2660,n_hidden=128,n_layers=3_2023-12-07_12-44-57\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_0b8ff26b_40_dispersion=gene,gene_likelihood=zinb,lr=0.0690,n_hidden=256,n_layers=4_2023-12-07_12-45-06\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_b5cc9a84_41_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3677,n_hidden=128,n_layers=3_2023-12-07_12-45-16\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_94926e6b_42_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0885,n_hidden=256,n_layers=4_2023-12-07_12-45-25\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_d51b9768_43_dispersion=gene-batch,gene_likelihood=zinb,lr=0.4548,n_hidden=128,n_layers=2_2023-12-07_12-45-35\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_6184ccd3_44_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1118,n_hidden=256,n_layers=4_2023-12-07_12-45-45\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_3bd44daf_45_dispersion=gene,gene_likelihood=zinb,lr=0.3045,n_hidden=128,n_layers=3_2023-12-07_12-45-55\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_50e7b732_46_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1431,n_hidden=256,n_layers=4_2023-12-07_12-46-04\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_5a7c99e4_47_dispersion=gene-batch,gene_likelihood=zinb,lr=0.3950,n_hidden=128,n_layers=3_2023-12-07_12-46-14\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_e1a7a955_48_dispersion=gene-batch,gene_likelihood=zinb,lr=0.0784,n_hidden=256,n_layers=4_2023-12-07_12-46-23\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_868afbe8_49_dispersion=gene,gene_likelihood=zinb,lr=0.4845,n_hidden=128,n_layers=3_2023-12-07_12-46-32\n- /maps/projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/notebooks/ray/tune_scvi_2023-12-07-12:27:37/_trainable_2db3e93e_50_dispersion=gene-batch,gene_likelihood=zinb,lr=0.1057,n_hidden=256,n_layers=4_2023-12-07_12-46-42\n\n\n\nprint(results.model_kwargs)\nprint(results.train_kwargs)\nprint(results.metric)\n\n{'gene_likelihood': 'zinb', 'dispersion': 'gene', 'n_hidden': 144, 'n_layers': 2}\n\n\n\n{'plan_kwargs': {'lr': 0.0026974298754178687}}\n\n\n\n{'metric': 'validation_loss', 'mode': 'min', 'value': 9358.837890625}\n\n\n\n\nimport pandas as pd\n\n\ntraining = pd.DataFrame([\n    [x.metrics['validation_loss']] + x.path.split(',')[1:]\n    for x in results.results if 'validation_loss' in x.metrics\n]).sort_values(by=0)\n\ntraining.to_csv(\"../results/02_human_integration/tunning.csv\")\ndisplay(training.head(10))\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\n9\n9358.837891\ngene_likelihood=zinb\nlr=0.0027\nn_hidden=144\nn_layers=2_2023-12-07_12-37-28\n\n\n6\n10226.864258\ngene_likelihood=zinb\nlr=0.0244\nn_hidden=128\nn_layers=4_2023-12-07_12-33-17\n\n\n1\n10236.216797\ngene_likelihood=zinb\nlr=0.0018\nn_hidden=256\nn_layers=5_2023-12-07_12-27-47\n\n\n2\n10415.340820\ngene_likelihood=zinb\nlr=0.0016\nn_hidden=144\nn_layers=2_2023-12-07_12-30-03\n\n\n0\n11194.058594\ngene_likelihood=zinb\nlr=0.0366\nn_hidden=128\nn_layers=2_2023-12-07_12-27-37\n\n\n5\n13192.603516\ngene_likelihood=nb\nlr=0.0211\nn_hidden=144\nn_layers=4_2023-12-07_12-32-37\n\n\n12\n13270.201172\ngene_likelihood=zinb\nlr=0.0010\nn_hidden=128\nn_layers=4_2023-12-07_12-38-25\n\n\n10\n14023.433594\ngene_likelihood=zinb\nlr=0.0006\nn_hidden=144\nn_layers=3_2023-12-07_12-37-32\n\n\n4\n14757.439453\ngene_likelihood=zinb\nlr=0.0001\nn_hidden=128\nn_layers=2_2023-12-07_12-32-30\n\n\n15\n20656.691406\ngene_likelihood=nb\nlr=0.0059\nn_hidden=144\nn_layers=5_2023-12-07_12-40-10"
  },
  {
    "objectID": "notebooks/02_mouse_integration.html",
    "href": "notebooks/02_mouse_integration.html",
    "title": "02 - mouse integration",
    "section": "",
    "text": "!which pip\n\n~/projects/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\nimport scvi\nimport pandas as pd\nimport scanpy as sc\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nfrom rich import print\nfrom scib_metrics.benchmark import Benchmarker\nfrom scvi.model.utils import mde\n\n\nimport warnings\nfrom lightning_fabric.plugins.environments.slurm import PossibleUserWarning\nwarnings.simplefilter(action='ignore', category=PossibleUserWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nscvi.settings.seed = 42\n\n[rank: 0] Global seed set to 42\nsc.set_figure_params(figsize=(10, 6))\n\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n%config InlineBackend.figure_format='retina'\nadata = sc.read(\"../data/processed/01_mouse_reprocessed.h5ad\")\nadata\n\nAnnData object with n_obs  n_vars = 2004  34346\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig', 'stage', 'timepoint', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'n_genes', 'n_counts'\n    var: 'gene_ids', 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n    uns: 'log1p'\n    layers: 'counts'\n# sc.pp.highly_variable_genes(\n#     adata,\n#     flavor=\"seurat_v3\",\n#     n_top_genes=3_000,\n#     layer=\"counts\",\n#     batch_key=\"batch\",\n#     subset=True,\n# )\nadata.uns['log1p'][\"base\"] = None\nsc.pp.highly_variable_genes(\n    adata,\n    flavor=\"cell_ranger\",\n    n_top_genes=3_000,\n    # batch_key=\"batch\",\n    batch_key=\"experiment\",\n    subset=True,\n)\nadata.shape\n\n(2004, 3000)"
  },
  {
    "objectID": "notebooks/02_mouse_integration.html#scvi",
    "href": "notebooks/02_mouse_integration.html#scvi",
    "title": "02 - mouse integration",
    "section": "1 1. SCVI",
    "text": "1 1. SCVI\n\nimport jax\njax.devices()\n\n[gpu(id=0), gpu(id=1), gpu(id=2), gpu(id=3)]\n\n\n\nadata.obs['batch_og'] = adata.obs['batch']\nadata.obs['batch'] = adata.obs.experiment.cat.codes.astype(str) + \"_\" + adata.obs.batch.cat.codes.astype(str)\n# adata.obs['batch_og'] = adata.obs['batch']\n# adata.obs['batch'] = adata.obs.experiment.cat.codes.astype(str) + \"_\" + adata.obs.technology.cat.codes.astype(str)\n# adata.obs['batch'] = adata.obs.batch.astype(str) + \"_\" + adata.obs.technology.cat.codes.astype(str)\n# adata.obs['batch'] = adata.obs.technology.astype(str) + \"_\" + adata.obs.batch.str.split('_', expand=True).iloc[:, 1].astype(str)\n\n\nscvi.model.SCVI.setup_anndata(\n    adata, \n    layer=\"counts\", \n    batch_key=\"batch\",\n    # batch_key=\"experiment|technology\",\n    # categorical_covariate_keys=[\"technology\"]\n)\n\n\nvae = scvi.model.SCVI(adata, n_layers=2, gene_likelihood='nb')\n\n# old settings\n# vae = scvi.model.SCVI(adata, dropout_rate=0.01, n_layers=3, n_latent=10, gene_likelihood='nb') # 0.58\n# other\n# vae = scvi.model.SCVI(adata, dropout_rate=0.005, n_layers=2, n_latent=20, gene_likelihood='nb')\n# vae = scvi.model.SCVI(adata, gene_likelihood='nb', dropout_rate=0.01, n_layers=3) # 0.57\n# from tunning\n# vae = scvi.model.SCVI(adata, dropout_rate=0.002, n_layers=3, gene_likelihood='zinb')\n# vae = scvi.model.SCVI(adata, dropout_rate=0.005, n_layers=2, gene_likelihood='zinb')\nvae\n\nSCVI Model with the following params: \nn_hidden: 128, n_latent: 10, n_layers: 2, dropout_rate: 0.1, dispersion: gene, gene_likelihood: nb, \nlatent_distribution: normal\nTraining status: Not Trained\nModel's adata is minified?: False\n\n\n\n\n\n\n\nvae.train(use_gpu=1, max_epochs=400, early_stopping=True)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n\n\nEpoch 386/400:  96%|        | 386/400 [00:51&lt;00:01,  7.46it/s, v_num=1, train_loss_step=4.71e+3, train_loss_epoch=4.95e+3]\nMonitored metric elbo_validation did not improve in the last 45 records. Best score: 5377.381. Signaling Trainer to stop.\n\n\n\npd.concat([vae.history['elbo_train'], vae.history['elbo_validation']], axis=1).plot.line(marker='o')\n\n&lt;Axes: xlabel='epoch'&gt;\n\n\n\n\n\n\n# fig, ax = plt.subplots(1, 12, figsize=[25, 4])\n# for idx, key in enumerate(vae.history.keys()):\n#     vae.history[key].plot(title=key, ax=ax[idx])\n\n\nadata.obsm[\"X_scVI\"] = vae.get_latent_representation(adata)\nadata.obsm[\"X_mde_scVI\"] = mde(adata.obsm[\"X_scVI\"])\n\nadata.layers['scVI_normalized'] = vae.get_normalized_expression(return_numpy=True)\n\n\nvae.save(\"../results/02_mouse_integration/scvi\", overwrite=True, save_anndata=True)"
  },
  {
    "objectID": "notebooks/02_mouse_integration.html#scanvi",
    "href": "notebooks/02_mouse_integration.html#scanvi",
    "title": "02 - mouse integration",
    "section": "2 2. SCANVI",
    "text": "2 2. SCANVI\n\nlvae = scvi.model.SCANVI.from_scvi_model(\n    vae,\n    adata=adata,\n    labels_key=\"ct\",\n    unlabeled_category=\"Unknown\",\n)\nlvae\n\nScanVI Model with the following params: \nunlabeled_category: Unknown, n_hidden: 128, n_latent: 10, n_layers: 2, dropout_rate: 0.1, dispersion: gene, \ngene_likelihood: nb\nTraining status: Not Trained\nModel's adata is minified?: False\n\n\n\n\n\n\n\nmax_epochs_scanvi = int(np.min([10, np.max([2, round(200 / 3.0)])]))\nprint(max_epochs_scanvi)\n\nlvae.train(max_epochs=15)\n\n10\n\n\n\nINFO     Training for 15 epochs.                                                                                   \nEpoch 15/15: 100%|| 15/15 [00:04&lt;00:00,  3.30it/s, v_num=1, train_loss_step=4.93e+3, train_loss_epoch=5.19e+3]Epoch 15/15: 100%|| 15/15 [00:04&lt;00:00,  3.06it/s, v_num=1, train_loss_step=4.93e+3, train_loss_epoch=5.19e+3]\n\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n`Trainer.fit` stopped: `max_epochs=15` reached.\n\n\n\n# fig, ax = plt.subplots(3, 3, figsize=[20, 14])\n# for idx, key in enumerate(lvae.history.keys()):\n#     lvae.history[key].plot(title=key, ax=ax[idx // 3 , idx % 3])\n\n\nadata.obsm[\"X_scANVI\"] = lvae.get_latent_representation(adata)\nadata.obsm[\"X_mde_scANVI\"] = mde(adata.obsm[\"X_scANVI\"])\n\nadata.layers['scANVI_normalized'] = lvae.get_normalized_expression(return_numpy=True)\n\n\nlvae.save(\"../results/02_mouse_integration/scanvi\", overwrite=True, save_anndata=True)"
  },
  {
    "objectID": "notebooks/02_mouse_integration.html#scgen",
    "href": "notebooks/02_mouse_integration.html#scgen",
    "title": "02 - mouse integration",
    "section": "3 3. scGEN",
    "text": "3 3. scGEN\n\nimport scgen\n\n\nscgen.SCGEN.setup_anndata(adata, batch_key=\"batch\", labels_key=\"ct\")\n\n\nmscgen = scgen.SCGEN(adata)\n\n\nmscgen.train(\n    max_epochs=100,\n    batch_size=32,\n    early_stopping=True,\n    early_stopping_patience=20,\n)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n\n\nEpoch 26/100:  26%|                                                                                                                                                                                               | 26/100 [00:10&lt;00:30,  2.40it/s, v_num=1, train_loss_step=482, train_loss_epoch=372]\nMonitored metric elbo_validation did not improve in the last 20 records. Best score: 1392.700. Signaling Trainer to stop.\n\n\n\npd.concat([mscgen.history['elbo_train'], mscgen.history['elbo_validation']], axis=1).plot.line(marker='o')\n\n&lt;Axes: xlabel='epoch'&gt;\n\n\n\n\n\n\nadata.obsm[\"X_scgen\"] = mscgen.batch_removal().obsm['corrected_latent']\nadata.obsm[\"X_mde_scgen\"] = mde(adata.obsm[\"X_scgen\"])\n\nadata.layers['scgen_decoded_expr'] = mscgen.get_decoded_expression()\n\nINFO     Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n\n\n\nmscgen.save(\"../results/02_mouse_integration/scgen\", overwrite=True, save_anndata=True)"
  },
  {
    "objectID": "notebooks/02_mouse_integration.html#stats",
    "href": "notebooks/02_mouse_integration.html#stats",
    "title": "02 - mouse integration",
    "section": "4 4. Stats",
    "text": "4 4. Stats\n\nbm = Benchmarker(\n    adata,\n    batch_key=\"batch\",\n    label_key=\"ct\",\n    embedding_obsm_keys=[\"X_pca\", \"X_scVI\", \"X_scANVI\", \"X_scgen\"],\n    n_jobs=-1,\n)\nbm.benchmark()\nbm.plot_results_table(min_max_scale=False, save_dir='../results/02_mouse_integration/')\n\nComputing neighbors:   0%|                                                                                                                                                                                                                                                                                                                          | 0/4 [00:00&lt;?, ?it/s]/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  @numba.jit()\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  @numba.jit()\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  @numba.jit()\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  @numba.jit()\n2023-09-23 16:36:34.725996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nComputing neighbors: 100%|| 4/4 [00:51&lt;00:00, 12.85s/it]\nEmbeddings:   0%|                                                                                                                                                                                                                                                                                                                                   | 0/4 [00:00&lt;?, ?it/s]\nMetrics:   0%|                                                                                                                                                                                                                                                                                                                                     | 0/10 [00:00&lt;?, ?it/s]\nMetrics:   0%|                                                                                                                                                                                                                                                                                                  | 0/10 [00:00&lt;?, ?it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                                                                                                                                                                                                                                             | 1/10 [00:02&lt;00:23,  2.65s/it, Bio conservation: isolated_labels]\nMetrics:  10%|                                                                                                                                                                                                                                                 | 1/10 [00:02&lt;00:23,  2.65s/it, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                                                                                                                                                                                                      | 2/10 [00:04&lt;00:19,  2.40s/it, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                                                                                                                                                                                                                | 2/10 [00:04&lt;00:19,  2.40s/it, Bio conservation: silhouette_label]\nMetrics:  30%|                                                                                                                                                                                                    | 3/10 [00:05&lt;00:11,  1.64s/it, Bio conservation: silhouette_label]\nMetrics:  30%|                                                                                                                                                                                                         | 3/10 [00:05&lt;00:11,  1.64s/it, Bio conservation: clisi_knn]\nMetrics:  40%|                                                                                                                                                                            | 4/10 [00:07&lt;00:09,  1.62s/it, Bio conservation: clisi_knn]\nMetrics:  40%|                                                                                                                                                                        | 4/10 [00:07&lt;00:09,  1.62s/it, Batch correction: silhouette_batch]\nMetrics:  50%|                                                                                                                                            | 5/10 [00:18&lt;00:25,  5.04s/it, Batch correction: silhouette_batch]\nMetrics:  50%|                                                                                                                                                | 5/10 [00:18&lt;00:25,  5.04s/it, Batch correction: ilisi_knn]\nMetrics:  60%|                                                                                                                   | 6/10 [00:18&lt;00:13,  3.42s/it, Batch correction: ilisi_knn]\nMetrics:  60%|                                                                                                                 | 6/10 [00:18&lt;00:13,  3.42s/it, Batch correction: kbet_per_label]\nMetrics:  70%|                                                                                     | 7/10 [00:26&lt;00:14,  4.87s/it, Batch correction: kbet_per_label]\nMetrics:  70%|                                                                                   | 7/10 [00:26&lt;00:14,  4.87s/it, Batch correction: graph_connectivity]\nMetrics:  80%|                                                        | 8/10 [00:26&lt;00:09,  4.87s/it, Batch correction: pcr_comparison]\nEmbeddings:  25%|                                                                                                                                                                                                                                            | 1/4 [00:27&lt;01:23, 27.68s/it]\nMetrics:   0%|                                                                                                                                                                                                                                                                                                                                     | 0/10 [00:00&lt;?, ?it/s]\n                                                                                                                                                                                                                                                                                                                                                                          \nMetrics:   0%|                                                                                                                                                                                                                                                                                                  | 0/10 [00:00&lt;?, ?it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                                                                                                                                                                                                                                             | 1/10 [00:00&lt;00:02,  4.19it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                                                                                                                                                                                                                                 | 1/10 [00:00&lt;00:02,  4.19it/s, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                                                                                                                                                                                                      | 2/10 [00:01&lt;00:08,  1.09s/it, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                                                                                                                                                                                                                | 2/10 [00:01&lt;00:08,  1.09s/it, Bio conservation: silhouette_label]\nMetrics:  30%|                                                                                                                                                                                                         | 3/10 [00:01&lt;00:07,  1.09s/it, Bio conservation: clisi_knn]\nMetrics:  40%|                                                                                                                                                                        | 4/10 [00:01&lt;00:06,  1.09s/it, Batch correction: silhouette_batch]\nMetrics:  50%|                                                                                                                                            | 5/10 [00:02&lt;00:02,  1.95it/s, Batch correction: silhouette_batch]\nMetrics:  50%|                                                                                                                                                | 5/10 [00:02&lt;00:02,  1.95it/s, Batch correction: ilisi_knn]\nMetrics:  60%|                                                                                                                 | 6/10 [00:02&lt;00:02,  1.95it/s, Batch correction: kbet_per_label]\nMetrics:  70%|                                                                                     | 7/10 [00:04&lt;00:01,  1.60it/s, Batch correction: kbet_per_label]\nMetrics:  70%|                                                                                   | 7/10 [00:04&lt;00:01,  1.60it/s, Batch correction: graph_connectivity]\nMetrics:  80%|                                                        | 8/10 [00:04&lt;00:01,  1.60it/s, Batch correction: pcr_comparison]\nEmbeddings:  50%|                                                                                                                                                             | 2/4 [00:32&lt;00:28, 14.42s/it]\nMetrics:   0%|                                                                                                                                                                                                                                                                                                                                     | 0/10 [00:00&lt;?, ?it/s]\n                                                                                                                                                                                                                                                                                                                                                                          \nMetrics:   0%|                                                                                                                                                                                                                                                                                                  | 0/10 [00:00&lt;?, ?it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                                                                                                                                                                                                                                 | 1/10 [00:00&lt;00:00, 15.25it/s, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                                                                                                                                                                                                      | 2/10 [00:01&lt;00:04,  1.86it/s, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                                                                                                                                                                                                                | 2/10 [00:01&lt;00:04,  1.86it/s, Bio conservation: silhouette_label]\nMetrics:  30%|                                                                                                                                                                                                         | 3/10 [00:01&lt;00:03,  1.86it/s, Bio conservation: clisi_knn]\nMetrics:  40%|                                                                                                                                                                        | 4/10 [00:01&lt;00:03,  1.86it/s, Batch correction: silhouette_batch]\nMetrics:  50%|                                                                                                                                            | 5/10 [00:01&lt;00:00,  5.11it/s, Batch correction: silhouette_batch]\nMetrics:  50%|                                                                                                                                                | 5/10 [00:01&lt;00:00,  5.11it/s, Batch correction: ilisi_knn]\nMetrics:  60%|                                                                                                                 | 6/10 [00:01&lt;00:00,  5.11it/s, Batch correction: kbet_per_label]\nMetrics:  70%|                                                                                     | 7/10 [00:01&lt;00:00,  5.48it/s, Batch correction: kbet_per_label]\nMetrics:  70%|                                                                                   | 7/10 [00:01&lt;00:00,  5.48it/s, Batch correction: graph_connectivity]\nEmbeddings:  75%|                                                                              | 3/4 [00:34&lt;00:08,  8.54s/it]\nMetrics:   0%|                                                                                                                                                                                                                                                                                                                                     | 0/10 [00:00&lt;?, ?it/s]\n                                                                                                                                                                                                                                                                                                                                                                          \nMetrics:   0%|                                                                                                                                                                                                                                                                                                  | 0/10 [00:00&lt;?, ?it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                                                                                                                                                                                                                                             | 1/10 [00:00&lt;00:02,  3.93it/s, Bio conservation: isolated_labels]\nMetrics:  10%|                                                                                                                                                                                                                                                 | 1/10 [00:00&lt;00:02,  3.93it/s, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                                                                                                                                                                                                      | 2/10 [00:01&lt;00:08,  1.07s/it, Bio conservation: nmi_ari_cluster_labels_kmeans]\nMetrics:  20%|                                                                                                                                                                                                                                | 2/10 [00:01&lt;00:08,  1.07s/it, Bio conservation: silhouette_label]\nMetrics:  30%|                                                                                                                                                                                                         | 3/10 [00:01&lt;00:07,  1.07s/it, Bio conservation: clisi_knn]\nMetrics:  40%|                                                                                                                                                                        | 4/10 [00:01&lt;00:06,  1.07s/it, Batch correction: silhouette_batch]\nMetrics:  50%|                                                                                                                                            | 5/10 [00:02&lt;00:02,  1.86it/s, Batch correction: silhouette_batch]\nMetrics:  50%|                                                                                                                                                | 5/10 [00:02&lt;00:02,  1.86it/s, Batch correction: ilisi_knn]\nMetrics:  60%|                                                                                                                 | 6/10 [00:02&lt;00:02,  1.86it/s, Batch correction: kbet_per_label]\nMetrics:  70%|                                                                                     | 7/10 [00:03&lt;00:01,  2.57it/s, Batch correction: kbet_per_label]\nMetrics:  70%|                                                                                   | 7/10 [00:03&lt;00:01,  2.57it/s, Batch correction: graph_connectivity]\nMetrics:  80%|                                                        | 8/10 [00:03&lt;00:00,  2.57it/s, Batch correction: pcr_comparison]\nEmbeddings: 100%|| 4/4 [00:38&lt;00:00,  9.60s/it]\n\n                                                                                                                                                                                                                                                                                                                                                                          \n\n\nINFO     E3.25-ICM consists of a single batch or is too small. Skip.                                               \nINFO     E3.25-TE consists of a single batch or is too small. Skip.                                                \nINFO     E3.5-EPI consists of a single batch or is too small. Skip.                                                \nINFO     E3.5-PrE consists of a single batch or is too small. Skip.                                                \nINFO     E3.75-ICM consists of a single batch or is too small. Skip.                                               \nINFO     E4.5-TE consists of a single batch or is too small. Skip.                                                 \nINFO     E3.25-ICM consists of a single batch or is too small. Skip.                                               \nINFO     E3.25-TE consists of a single batch or is too small. Skip.                                                \nINFO     E3.5-EPI consists of a single batch or is too small. Skip.                                                \nINFO     E3.5-PrE consists of a single batch or is too small. Skip.                                                \nINFO     E3.75-ICM consists of a single batch or is too small. Skip.                                               \nINFO     E4.5-TE consists of a single batch or is too small. Skip.                                                 \nINFO     E3.25-ICM consists of a single batch or is too small. Skip.                                               \nINFO     E3.25-TE consists of a single batch or is too small. Skip.                                                \nINFO     E3.5-EPI consists of a single batch or is too small. Skip.                                                \nINFO     E3.5-PrE consists of a single batch or is too small. Skip.                                                \nINFO     E3.75-ICM consists of a single batch or is too small. Skip.                                               \nINFO     E4.5-TE consists of a single batch or is too small. Skip.                                                 \nINFO     E3.25-ICM consists of a single batch or is too small. Skip.                                               \nINFO     E3.25-TE consists of a single batch or is too small. Skip.                                                \nINFO     E3.5-EPI consists of a single batch or is too small. Skip.                                                \nINFO     E3.5-PrE consists of a single batch or is too small. Skip.                                                \nINFO     E3.75-ICM consists of a single batch or is too small. Skip.                                               \nINFO     E4.5-TE consists of a single batch or is too small. Skip.                                                 \n\n\n\n\n\n&lt;plottable.table.Table at 0x7f7064eda8f0&gt;\n\n\n\nsc.pl.pca(adata, color=['ct', 'stage'])\nsc.pl.embedding(adata, color=['ct', 'stage'], basis='X_mde_scVI')\nsc.pl.embedding(adata, color=['ct', 'stage'], basis='X_mde_scANVI')\nsc.pl.embedding(adata, color=['ct', 'stage'], basis='X_mde_scgen')"
  },
  {
    "objectID": "notebooks/02_mouse_tunning.html",
    "href": "notebooks/02_mouse_tunning.html",
    "title": "02 - mouse tunning",
    "section": "",
    "text": "This notebook contains multiple methods on how we trained the model. We summarize below which params were helpful in generating better integration.\n!which pip\nimport scvi\nimport scanpy as sc\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nfrom rich import print\nfrom scib_metrics.benchmark import Benchmarker\nfrom scvi.model.utils import mde\n\n\nimport warnings\nfrom lightning_fabric.plugins.environments.slurm import PossibleUserWarning\nwarnings.simplefilter(action='ignore', category=PossibleUserWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nscvi.settings.seed = 42\nsc.set_figure_params(figsize=(10, 6))\n\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n%config InlineBackend.figure_format='retina'\nadata = sc.read(\"../data/processed/01_mouse_reprocessed.h5ad\")\nadata\nadata.obs.experiment.unique().tolist()\nsc.pp.highly_variable_genes(\n    adata,\n    flavor=\"seurat_v3\",\n    n_top_genes=3_000,\n    layer=\"counts\",\n    batch_key=\"batch\",\n    subset=True,\n)"
  },
  {
    "objectID": "notebooks/02_mouse_tunning.html#pimp-my-model-brute-force",
    "href": "notebooks/02_mouse_tunning.html#pimp-my-model-brute-force",
    "title": "02 - mouse tunning",
    "section": "1 2. Pimp my model: brute-force",
    "text": "1 2. Pimp my model: brute-force\nIn this method we brute-force params. At each iteration we generate PAGA graph which we use to check if the integration connects the correct cell types.\n\nimport itertools\nimport pandas as pd\n\n\nref_df = pd.DataFrame(0, index=adata.obs.ct.cat.categories, columns=adata.obs.ct.cat.categories)\nref_df.loc['Zygote', '2C'] = 1\nref_df.loc['2C', '4C'] = 1\nref_df.loc['4C', '8C'] = 1\nref_df.loc['16C', 'E3.25-ICM'] = 1\nref_df.loc['E3.25-ICM', 'E3.5-ICM'] = 1\n# df.loc['E3.5-ICM', 'E3.5-PrE'] = 1\n# df.loc['E3.5-ICM', 'E3.5-EPI'] = 1\n# df.loc['E3.5-ICM', 'E3.5-TE'] = 1\n\nref_df.loc['E3.5-EPI', 'E4.5-EPI'] = 1\nref_df.loc['E3.5-PrE', 'E4.5-PrE'] = 1\nref_df.loc['E3.5-TE', 'E4.5-TE'] = 1\n\n\nscvi.model.SCVI.setup_anndata(adata, layer=\"counts\", batch_key=\"batch\")\n\n\nparams = [[\"nb\", \"zinb\"], [\"gene\", \"gene-batch\"], [32, 64, 128], list(range(2,6))]\n\n\ntracked_params = []\n\nfor items in list(itertools.product(*params)):\n    gene_likelihood, dispersion, n_layers, n_hidden = items\n    \n    # SCVI\n    vae = scvi.model.SCVI(\n        adata, \n        n_layers=n_layers, \n        n_hidden=n_hidden, \n        dispersion=dispersion, \n        gene_likelihood=gene_likelihood\n    )\n    vae.train(use_gpu=1, max_epochs=400, early_stopping=True)\n    \n    # SCANVI\n    lvae = scvi.model.SCANVI.from_scvi_model(\n        vae,\n        adata=adata,\n        labels_key=\"ct\",\n        unlabeled_category=\"Unknown\",\n    )\n    lvae.train(max_epochs=10)\n    adata.obsm[\"X_scANVI\"] = lvae.get_latent_representation(adata)\n\n    try:\n        sc.pp.neighbors(adata, use_rep='X_scANVI')\n        sc.tl.diffmap(adata)\n        sc.tl.paga(adata, groups='ct')\n        sc.pl.paga(adata, color=['ct'], frameon=False, fontoutline=True)\n        sc.tl.draw_graph(adata, init_pos='paga', n_jobs=10)\n        df = pd.DataFrame(\n            adata.uns['paga']['connectivities'].A, \n            index=adata.obs.ct.cat.categories, \n            columns=adata.obs.ct.cat.categories\n        )\n        # maximize the connectivity, even though the interaction\n        # is around 0.5\n        df = df.round()\n\n        n_ref = np.sum(ref_df.values * ref_df.values)\n        \n        tracked_params.append(list(items) + [n_ref] + [\"success\"])\n    except TypeError as e:\n        # TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]\n        # This error comes from PAGA, usually the integration was a fail\n        tracked_params.append(list(items) + [0] + [\"failed\"])\n\n\nopt_params = pd.DataFrame(tracked_params, \n                          columns=['gene_likelihood', 'dispersion', 'n_layers', 'n_hidden', 'paga', 'run']) \\\n            .query('run == \"success\"') \\\n            # .query('n_layers &gt;= 64')\nopt_params.to_csv(\"../results/02_mouse_integration/opt_params.csv\")\nopt_params"
  },
  {
    "objectID": "notebooks/02_mouse_tunning.html#pimp-my-model-ray-tunner",
    "href": "notebooks/02_mouse_tunning.html#pimp-my-model-ray-tunner",
    "title": "02 - mouse tunning",
    "section": "2 3. Pimp my model: ray tunner",
    "text": "2 3. Pimp my model: ray tunner\n\nimport ray\nimport jax\nimport os\n\nfrom ray import tune\nfrom scvi import autotune\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n\n\njax.devices()\n\n\nref_tuner = sc.AnnData(adata.layers[\"counts\"])\nref_tuner.obs = adata.obs[[\"total_counts\", \"technology\", \"batch\"]].copy()\n\nmodel_cls = scvi.model.SCVI\nmodel_cls.setup_anndata(ref_tuner, \n                        batch_key=\"batch\")\n\nscvi_tuner = autotune.ModelTuner(model_cls)\n\n\nscvi_tuner.info()\n\n\nsearch_space = {\n    \"gene_likelihood\": tune.choice([\"nb\", \"zinb\"]),\n    \"dispersion\": tune.choice([\"gene\", \"gene-batch\"]),\n    \"n_hidden\": tune.choice([128, 144, 256]),\n    \"n_layers\": tune.choice([2, 3, 4, 5]),\n    \"lr\": tune.loguniform(1e-4, 0.6),\n}\n\n\nray.init(\n    log_to_driver=False,\n    num_cpus=10,\n    num_gpus=2,\n)\n\n\nresults = scvi_tuner.fit(\n    ref_tuner,\n    metric=\"validation_loss\",\n    search_space=search_space,\n    num_samples=50,\n    max_epochs=100,\n)\n\n\nprint(results.model_kwargs)\nprint(results.train_kwargs)\nprint(results.metric)\n\n\nimport pandas as pd\n\n\ntraining = pd.DataFrame([\n    [x.metrics['validation_loss']] + x.path.split(',')[1:]\n    for x in results.results if 'validation_loss' in x.metrics\n]).sort_values(by=0)\n\ntraining.to_csv(\"../results/02_mouse_integration/tunning.csv\")\ndisplay(training.head(10))"
  },
  {
    "objectID": "notebooks/03_human_analysis.html",
    "href": "notebooks/03_human_analysis.html",
    "title": "03 - human analysis",
    "section": "",
    "text": "!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport scvi\nimport scanpy as sc\nimport scanpy.external as sce\nimport scFates as scf\nimport matplotlib.pyplot as plt\n\nimport warnings\nfrom numba.core.errors import NumbaDeprecationWarning\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n# adata = sc.read(\"../results/human_integration/version_1/scvi/adata.h5ad\")\nadata = sc.read(\"../results/02_human_integration/scvi/adata.h5ad\")\nadata\n\nAnnData object with n_obs  n_vars = 2323  3000\n    obs: 'day', 'ct', 'experiment', 'technology', 'n_counts', 'n_genes', 'ct_fine', 'batch', 'stage', 'timepoint', 'ct_orig', '_scvi_batch', '_scvi_labels'\n    var: 'symbol', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n    uns: '_scvi_manager_uuid', '_scvi_uuid', 'hvg'\n    obsm: 'X_mde_scVI', 'X_scVI'\n    layers: 'counts', 'scVI_normalized'\n# adata.obs.experiment = adata.obs.experiment.str.replace('_', ' et al., ').astype('category')\n# adata.obs['batch'] = adata.obs._scvi_batch\n\n# adata.obs['stage'] = adata.obs.ct.cat.rename_categories({\n#     'Epiblast': 'EPI',\n#     'Inner Cell Mass': 'ICM',\n#     'Primitive Endoderm': 'PrE',\n#     'Trophectoderm': 'TE'\n# }).cat.reorder_categories(['Oocyte', 'Pronucleus', 'Zygote', '2C', '4C', '8C', 'Morula', 'TE', 'ICM', 'EPI', 'PrE', 'Unknown'])\n\n# adata.obs['timepoint'] = adata.obs.ct.astype(str)\n# timepoint_mask = adata.obs.ct.isin(['Unknown', 'Trophectoderm', 'Inner Cell Mass', 'Primitive Endoderm', 'Epiblast'])\n# adata.obs.loc[timepoint_mask, 'timepoint'] = 'E' + adata.obs.loc[timepoint_mask, 'day'].astype(str)\n# adata.obs.ct = adata.obs.ct.astype('category')\n# adata.obs['ct_orig'] = adata.obs.ct\n# adata.obs.ct = adata.obs.ct_fine\n# ENSG_to_SYMBOL = pd.read_csv('../data/external/human/Homo_sapiens.GRCh38.110.ENSG_to_SYMBOL.tsv', delimiter=\" \", header=None)\n# ENSG_to_SYMBOL.columns = ['ensembl','symbol']\n# ENSG_to_SYMBOL_noName = pd.read_csv('../data/external/human/Homo_sapiens.GRCh38.110.ENSG_to_SYMBOL_noName.tsv', delimiter=\" \", header=None)\n# nameless_df = pd.DataFrame(\n#     data = {\n#         'ensembl' : list(set(ENSG_to_SYMBOL_noName[0].tolist()) - set(ENSG_to_SYMBOL.ensembl.tolist())),\n#         'symbol' : list(set(ENSG_to_SYMBOL_noName[0].tolist()) - set(ENSG_to_SYMBOL.ensembl.tolist())),\n#     })\n# ENSG_to_SYMBOL = pd.concat([ENSG_to_SYMBOL, nameless_df])\n# ENSG_to_SYMBOL.set_index('ensembl', inplace=True)\n# adata.var['symbol'] = ENSG_to_SYMBOL.loc[adata.var_names, 'symbol']"
  },
  {
    "objectID": "notebooks/03_human_analysis.html#scvi",
    "href": "notebooks/03_human_analysis.html#scvi",
    "title": "03 - human analysis",
    "section": "1 1. SCVI",
    "text": "1 1. SCVI\n\nUSE_REP = 'X_scVI'\n\n\n# Ideally find 15 clusters\n\nsc.pp.neighbors(adata, use_rep=USE_REP)\nsc.tl.leiden(adata, resolution=0.8)\n\n2023-12-05 20:08:39.657755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\nfig, ax = plt.subplots(1, 2, figsize=[25, 5])\nadata.obs.groupby(['ct', 'leiden']).size().unstack().plot(kind='bar', stacked=True, ax=ax[0]).legend(loc='right')\nadata.obs.groupby(['leiden', 'ct']).size().unstack().plot(kind='bar', stacked=True, ax=ax[1]).legend(loc='right')\n\n&lt;matplotlib.legend.Legend at 0x7fb8c7661750&gt;\n\n\n\n\n\n\n1.1 1.0. PCA\n\nsc.tl.pca(adata)\nsc.pl.pca(adata, color=['stage', 'ct'], frameon=False, ncols=2)\n\n\n\n\n\n\n1.2 1.1. UMAP\n\nsc.tl.umap(adata)\nsc.pl.umap(adata, color=['stage', 'ct'], frameon=False, ncols=2)\n\n\n\n\n\n\n1.3 1.2. Phate\n\nsce.tl.phate(adata, n_jobs=8)\nsce.pl.phate(adata, color=['stage', 'ct'], frameon=False, ncols=2)\n\n\n\n\n\n\n1.4 1.3. t-SNE\n\nsc.tl.tsne(adata, n_jobs=8, perplexity=300)\nsc.pl.tsne(adata, color=['stage', 'ct'], frameon=False, ncols=2)\n\n\n\n\n\n\n1.5 1.4. Force Directed Graph\n\nsc.tl.draw_graph(adata, n_jobs=8, random_state=9)\nsc.pl.draw_graph(adata, color=['experiment', 'stage', 'ct'], frameon=False, ncols=3, wspace=0.4)\n\n\n\n\n\n\n1.6 1.5. DC\n\n# Bug: https://github.com/scverse/scanpy/issues/2254\nsc.tl.diffmap(adata)\n\nadata.obsm[\"X_diffmap_\"] = adata.obsm[\"X_diffmap\"][:, 1:] \nsc.pl.embedding(adata, \"diffmap_\", color=['stage', 'ct'], frameon=False, ncols=2)"
  },
  {
    "objectID": "notebooks/03_human_analysis.html#pseudotime",
    "href": "notebooks/03_human_analysis.html#pseudotime",
    "title": "03 - human analysis",
    "section": "2 2. Pseudotime",
    "text": "2 2. Pseudotime\n\nadata\n\nAnnData object with n_obs  n_vars = 2323  3000\n    obs: 'day', 'ct', 'experiment', 'technology', 'n_counts', 'n_genes', 'ct_fine', 'batch', 'stage', 'timepoint', 'ct_orig', '_scvi_batch', '_scvi_labels', 'leiden'\n    var: 'symbol', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n    uns: '_scvi_manager_uuid', '_scvi_uuid', 'hvg', 'neighbors', 'leiden', 'pca', 'stage_colors', 'ct_colors', 'umap', 'tsne', 'draw_graph', 'experiment_colors', 'diffmap_evals'\n    obsm: 'X_mde_scVI', 'X_scVI', 'X_pca', 'X_umap', 'X_phate', 'X_tsne', 'X_draw_graph_fa', 'X_diffmap', 'X_diffmap_'\n    varm: 'PCs'\n    layers: 'counts', 'scVI_normalized'\n    obsp: 'distances', 'connectivities'\n\n\n\n2.1 2.1. DPT package\n\nsc.pp.neighbors(adata, use_rep=USE_REP)\nsc.tl.diffmap(adata)\n\nsc.tl.paga(adata, groups='ct')\nsc.pl.paga(adata, color=['ct'], frameon=False, fontoutline=True)\nsc.tl.draw_graph(adata, init_pos='paga', n_jobs=10)\n\n\n\n\n\nwith plt.rc_context({\"figure.figsize\": (6, 6), \"figure.dpi\": (300)}):\n    sc.pl.paga(adata, color=['ct'], frameon=False, fontoutline=True)\n\n\n\n\n\nadata.uns['iroot'] = np.flatnonzero(adata.obs['ct']  == 'Prelineage')[0]\n# adata.uns['iroot'] = np.where(adata.obs_names == 'SRX144343_SRX144343')[0][0]\nsc.tl.dpt(adata)\n\n\nsc.pl.draw_graph(adata, color=['dpt_pseudotime', 'ct'], frameon=False, ncols=2, cmap='tab20')\nsc.pl.draw_graph(adata, color=['experiment', 'ct'], frameon=False, ncols=2, cmap='tab20')\n\n\n\n\n\n\n\n\n\n2.2 2.2. scFATEs\n\nsc.pp.neighbors(adata, use_rep=USE_REP)\nsc.tl.draw_graph(adata, n_jobs=10, random_state=9)\n\n\nsc.pl.draw_graph(adata, color=['dpt_pseudotime', 'ct'], frameon=False, ncols=2, cmap='tab20')\nsc.pl.draw_graph(adata, color=['stage', 'timepoint'], frameon=False, ncols=2, cmap='tab20')\n\n\n\n\n\n\n\n\nsig = scf.tl.explore_sigma(adata,\n                         # Nodes=20,\n                         Nodes=60,\n                         use_rep=\"X_draw_graph_fa\",\n                         sigmas=[1000,500,400,300,200,100,50,10,1],\n                         seed=42,plot=True)\n\n\n\n\n\nscf.tl.tree(adata,\n            # Nodes=30,\n            Nodes=60,\n            use_rep=\"X_draw_graph_fa\",\n            method=\"ppt\",\n            ppt_nsteps=10,\n            ppt_sigma=sig,\n            ppt_lambda=100,\n            seed=42)\n\ninferring a principal tree --&gt; parameters used \n    60 principal points, sigma = 500, lambda = 100, metric = euclidean\n    fitting: 100%|| 10/10 [00:00&lt;00:00, 248.42it/s]\n    not converged (error: 0.1919399979722125)\n    finished (0:00:00) --&gt; added \n    .uns['ppt'], dictionnary containing inferred tree.\n    .obsm['X_R'] soft assignment of cells to principal points.\n    .uns['graph']['B'] adjacency matrix of the principal points.\n    .uns['graph']['F'] coordinates of principal points in representation space.\n\n\n\nscf.pl.graph(adata)\n\n\n\n\n\nscf.tl.root(adata, 21)\n\nnode 21 selected as a root --&gt; added\n    .uns['graph']['root'] selected root.\n    .uns['graph']['pp_info'] for each PP, its distance vs root and segment assignment.\n    .uns['graph']['pp_seg'] segments network information.\n\n\n\nscf.tl.pseudotime(adata,n_jobs=10,n_map=10,seed=42)\n\nprojecting cells onto the principal graph\n    mappings: 100%|| 10/10 [00:54&lt;00:00,  5.43s/it]\n    finished (0:00:57) --&gt; added\n    .obs['edge'] assigned edge.\n    .obs['t'] pseudotime value.\n    .obs['seg'] segment of the tree assigned.\n    .obs['milestones'] milestone assigned.\n    .uns['pseudotime_list'] list of cell projection from all mappings.\n\n\n\nscf.pl.trajectory(adata)\n\n\n\n\n\nsc.pl.draw_graph(adata, color=['stage', 'seg', 'dpt_pseudotime', 't'], frameon=False, ncols=2, cmap='tab20')\n\n\n\n\n\nscf.tl.dendrogram(adata, n_jobs=8)\nwith plt.rc_context({\"figure.figsize\": (6, 6)}):\n    scf.pl.dendrogram(adata,color=\"seg\")\n    scf.pl.dendrogram(adata,color=\"ct\",legend_loc=\"on data\",color_milestones=True,legend_fontoutline=True)\n\nGenerating dendrogram of tree\n    segment : 100%|| 9/9 [00:02&lt;00:00,  3.83it/s]\n    finished (0:00:02) --&gt; added \n    .obsm['X_dendro'], new embedding generated.\n    .uns['dendro_segments'] tree segments used for plotting.\n\n\n\n\n\n\n\n\n\n\n2.3 2.3. Palantir\nNOTE: doesnt work, skipping\n\n# import logging\n# logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n\n# sc.pp.neighbors(adata, use_rep=\"X_scANVI\")\n# sce.tl.palantir(adata, use_adjacency_matrix=True, distances_key=\"distances\")\n# sc.tl.tsne(adata, n_pcs=2, use_rep='X_palantir_multiscale', perplexity=30)\n\n# sc.pl.embedding(adata, basis='X_palantir_multiscale', color=['ct', 'stage'], frameon=False, ncols=2)"
  },
  {
    "objectID": "notebooks/03_human_analysis.html#differentially-expressed-genes",
    "href": "notebooks/03_human_analysis.html#differentially-expressed-genes",
    "title": "03 - human analysis",
    "section": "3 3. Differentially expressed genes",
    "text": "3 3. Differentially expressed genes\n\ndef filter_markers(df: pd.DataFrame, n_genes: int = 5, upper: bool = False):\n    # significant only\n    df = df[\n        (df[\"is_de_fdr_0.05\"])\n        & (df[\"bayes_factor\"] &gt; 3)\n        & (df[\"non_zeros_proportion1\"] &gt; 0.1)\n        & (df[\"lfc_median\"] &gt; 0)\n    ]\n    comparisons = df.comparison.unique()\n\n    deg_df = {}\n    for comparison in comparisons:\n        cluster = comparison.split(\" \")[0]\n        markers = (\n            df.query(\"comparison == @comparison\")\n            .sort_values(by=\"lfc_median\", ascending=False)\n            .head(n_genes)\n        )\n        deg_df[cluster] = (\n            markers.index.str.upper().tolist() if upper else markers.index.tolist()\n        )\n\n    return deg_df\n\n\nvae = scvi.model.SCVI.load(\"../results/02_human_integration/scvi/\")\n\nINFO     File ../results/02_human_integration/scvi/model.pt already downloaded                                     \n\n\n\nm_ct = vae.differential_expression(groupby=\"ct\")\nm_ct_filt = filter_markers(m_ct, n_genes=10)\n\nDE...: 100%|| 15/15 [00:16&lt;00:00,  1.07s/it]\n\n\n\npd.DataFrame.from_dict(m_ct_filt, orient='index').transpose()\n\n\n\n\n\n\n\n\n8C_3.0\nEpiblast_6.0\nEpiblast_7.0\nInner\nLate\nMorula_4.0\nPrelineage\nPrimitive\nTrophectoderm_5.0\nTrophectoderm_6.0\nTrophectoderm_7.0\nTrophectoderm_8.0\nTrophectoderm_9.0\nTrophectoderm_10.0\nUnknown\n\n\n\n\n0\nENSG00000258223\nENSG00000143768\nENSG00000143768\nENSG00000010438\nENSG00000162344\nENSG00000285891\nENSG00000254659\nENSG00000259974\nENSG00000286361\nENSG00000127074\nENSG00000249861\nENSG00000077274\nENSG00000077274\nENSG00000166396\nENSG00000196289\n\n\n1\nENSG00000285891\nENSG00000283567\nENSG00000283567\nENSG00000180644\nENSG00000136999\nENSG00000274764\nENSG00000285010\nENSG00000162998\nENSG00000287442\nENSG00000109205\nENSG00000203857\nENSG00000166396\nENSG00000166396\nENSG00000077274\nENSG00000258223\n\n\n2\nENSG00000243073\nENSG00000146250\nENSG00000189184\nENSG00000166523\nENSG00000283567\nENSG00000178928\nENSG00000288545\nENSG00000167434\nENSG00000164089\nENSG00000137440\nENSG00000203783\nENSG00000254622\nENSG00000172927\nENSG00000172927\nENSG00000124557\n\n\n3\nENSG00000254659\nENSG00000283405\nENSG00000146250\nENSG00000164530\nENSG00000198576\nENSG00000257951\nENSG00000146678\nENSG00000171557\nENSG00000204478\nENSG00000145681\nENSG00000124731\nENSG00000112195\nENSG00000254622\nENSG00000112195\nENSG00000287442\n\n\n4\nENSG00000274764\nENSG00000102854\nENSG00000178860\nENSG00000136869\nENSG00000145423\nENSG00000258873\nENSG00000149507\nENSG00000125798\nENSG00000095596\nENSG00000198734\nENSG00000184502\nENSG00000136695\nENSG00000167767\nENSG00000254622\nENSG00000204479\n\n\n5\nENSG00000213921\nENSG00000181234\nENSG00000102854\nENSG00000289643\nENSG00000178860\nENSG00000204501\nENSG00000253585\nENSG00000229214\nENSG00000010438\nENSG00000104921\nENSG00000096088\nENSG00000167767\nENSG00000136695\nENSG00000142623\nENSG00000259009\n\n\n6\nENSG00000272382\nENSG00000189184\nENSG00000243232\nENSG00000179934\nENSG00000106341\nENSG00000287512\nENSG00000237469\nENSG00000125848\nENSG00000198883\nENSG00000121769\nENSG00000135346\nENSG00000099250\nENSG00000112195\nENSG00000125084\nENSG00000251360\n\n\n7\nENSG00000226185\nENSG00000166523\nENSG00000174807\nENSG00000125845\nENSG00000174807\nENSG00000258223\nENSG00000205126\nENSG00000164736\nENSG00000124557\nENSG00000188176\nENSG00000082074\nENSG00000203857\nENSG00000158786\nENSG00000221826\nENSG00000272382\n\n\n8\nENSG00000277058\nENSG00000118785\nENSG00000133083\nENSG00000167755\nENSG00000067840\nENSG00000239810\nENSG00000132514\nENSG00000243978\nENSG00000251360\nENSG00000165092\nENSG00000135046\nENSG00000158786\nENSG00000203857\nENSG00000274286\nENSG00000257951\n\n\n9\nENSG00000204501\nENSG00000134817\nENSG00000118785\nENSG00000133937\nENSG00000133083\nENSG00000277058\nENSG00000172680\nENSG00000146374\nENSG00000121933\nENSG00000163347\nENSG00000189052\nENSG00000203783\nENSG00000139209\nENSG00000185112\nENSG00000254659\n\n\n\n\n\n\n\n\nsc.pl.dotplot(adata, m_ct_filt, groupby='ct', dendrogram=False, standard_scale='var')\nsc.pl.matrixplot(adata, m_ct_filt, groupby='ct', dendrogram=False, standard_scale='var')\n\n\n\n\n\n\n\n\n3.1 4. Markers\n\nsc.tl.embedding_density(adata, basis='draw_graph_fa', groupby='ct')\nsc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_ct')\n\n\n\n\n\n# lineage_markers = pd.read_excel(\"../data/external/mouse_lineage_markers.xlsx\", sheet_name=\"Sheet1\").fillna('')\n# lineage_markers\n\n\n# for stage, genes in lineage_markers.to_dict('list').items():\n#     common_genes = adata.var_names.intersection([str.lower(g) for g in genes if g != ''])\n#     sc.pl.draw_graph(adata, color=['stage', *common_genes], title=[stage, *common_genes],\n#                      groups=stage, legend_loc=None, frameon=False, ncols=len(common_genes) + 1)"
  },
  {
    "objectID": "notebooks/03_human_analysis.html#save-model",
    "href": "notebooks/03_human_analysis.html#save-model",
    "title": "03 - human analysis",
    "section": "4 Save model",
    "text": "4 Save model\n\nadata.write(\"../results/03_human.processed.h5ad\")"
  },
  {
    "objectID": "notebooks/03_human_analysis.html#other",
    "href": "notebooks/03_human_analysis.html#other",
    "title": "03 - human analysis",
    "section": "5 4. OTHER",
    "text": "5 4. OTHER\n\n5.1 2. scGEN\nscGen returns imputed counts only. In this case we are not able to run DEGs because we need to have normalized counts. The predict function also wont work because we dont have any perturbation in the dataset.\n\nimport scgen\n\n\nmscgen = scgen.SCGEN.load(\"../results/02_mouse_integration/scgen/\")\n\n\ncorrected_adata = mscgen.batch_removal()\ncorrected_adata\n\n\nsc.pp.neighbors(corrected_adata, use_rep='corrected_latent')\nsc.tl.draw_graph(corrected_adata)\n\n\nsc.pl.draw_graph(corrected_adata, color=['ct', 'Stage'], wspace=0.4, frameon=False)\n\n\nsc.tl.umap(corrected_adata)\nsc.pl.umap(corrected_adata, color=['batch', 'Stage'], wspace=0.4, frameon=False)\n\n\n\n5.2 3. Integration stats\n\nfrom rich import print\nfrom scib_metrics.benchmark import Benchmarker\n\n\nbm = Benchmarker(\n    adata,\n    batch_key=\"batch\",\n    label_key=\"ct\",\n    embedding_obsm_keys=[\"X_pca\", \"X_scVI\", \"X_scANVI\", \"X_scgen\"],\n    n_jobs=-1,\n)\nbm.benchmark()\n\n\nbm.plot_results_table(min_max_scale=False)\n\n\nfrom pysankey import sankey\n\n\n%run ../scripts/helpers.py\n\n\nsc.tl.dendrogram(adata, groupby=\"leiden\", key_added=\"dendrogram_leiden\")\nsc.tl.dendrogram(adata, groupby=\"ct\", key_added=\"dendrogram_ct\")\n\n\nwith plt.rc_context({\"figure.figsize\": [20, 20]}):\n    sc.pl.correlation_matrix(adata, groupby=\"ct\", show_correlation_numbers=True)\n\n\n_ = sc.pl.dendrogram(adata, groupby=\"ct\", orientation='top')\n\n\n\n5.3 3.1. Prediction\n\ndef get_predictions(lvae: scvi.model.SCANVI, threshold: float = 0.85):\n    df = pd.DataFrame(zip(predictions.idxmax(axis=1), predictions.max(axis=1)), columns=['predicted', 'score'])\n    df['predicted_filt'] = 'Unknown'\n    df.loc[df.score &gt;= threshold, 'predicted_filt'] = df.loc[df.score &gt;= threshold, 'predicted']\n    df['uncertainty'] = np.maximum(1 - df.score, 0)\n\n    return df\n\n\nlvae = scvi.model.SCANVI.load(\"../results/02-mouse/\")\nadata.obs[[\"predicted\", \"score\", \"predicted_filt\", \"uncertainty\"]] = get_predictions(lvae).values\n\n\nsc.pl.draw_graph(adata, color=['ct', 'predicted', 'uncertainty'], frameon=False, ncols=3)\n\n\ndf = adata.obs.groupby([\"ct\", \"predicted\"]).size().unstack(fill_value=0)\nnorm_df = df / df.sum(axis=0)\n\nplt.figure(figsize=(8, 8))\n_ = plt.pcolor(norm_df)\n_ = plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns, rotation=90)\n_ = plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n_ = plt.colorbar()\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Observed\")\n\n\n# Stats\nfrom sklearn.metrics import balanced_accuracy_score\n\nbalanced_accuracy_score(adata.obs[\"ct\"].values, adata.obs[\"predicted\"].values)"
  },
  {
    "objectID": "notebooks/03_mouse_analysis.html",
    "href": "notebooks/03_mouse_analysis.html",
    "title": "03 - mouse analysis",
    "section": "",
    "text": "!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport scvi\nimport scanpy as sc\nimport scanpy.external as sce\nimport scFates as scf\nimport matplotlib.pyplot as plt\n\nimport warnings\nfrom numba.core.errors import NumbaDeprecationWarning\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nadata = sc.read(\"../results/02_mouse_integration/scvi/adata.h5ad\")\nadata\n\nAnnData object with n_obs  n_vars = 2004  3000\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig', 'stage', 'timepoint', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'n_genes', 'n_counts', 'batch_og', '_scvi_batch', '_scvi_labels'\n    var: 'gene_ids', 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n    uns: '_scvi_manager_uuid', '_scvi_uuid', 'hvg', 'log1p'\n    obsm: 'X_mde_scVI', 'X_scVI'\n    layers: 'counts', 'scVI_normalized'"
  },
  {
    "objectID": "notebooks/03_mouse_analysis.html#scvi",
    "href": "notebooks/03_mouse_analysis.html#scvi",
    "title": "03 - mouse analysis",
    "section": "1 1. SCVI",
    "text": "1 1. SCVI\n\nUSE_REP = 'X_scVI'\n\n\n# Ideally find 15 clusters\n\nsc.pp.neighbors(adata, use_rep=USE_REP)\nsc.tl.leiden(adata, resolution=0.8)\n\n2023-09-23 17:00:49.975107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\nfig, ax = plt.subplots(1, 2, figsize=[25, 5])\nadata.obs.groupby(['ct', 'leiden']).size().unstack().plot(kind='bar', stacked=True, ax=ax[0]).legend(loc='right')\nadata.obs.groupby(['leiden', 'ct']).size().unstack().plot(kind='bar', stacked=True, ax=ax[1]).legend(loc='right')\n\n&lt;matplotlib.legend.Legend at 0x7f1a6a933fa0&gt;\n\n\n\n\n\n\n1.1 1.0. PCA\n\nsc.tl.pca(adata)\nsc.pl.pca(adata, color=['stage', 'ct'], frameon=False, ncols=2)\n\n\n\n\n\n\n1.2 1.1. UMAP\n\nsc.tl.umap(adata)\nsc.pl.umap(adata, color=['stage', 'ct'], frameon=False, ncols=2)\n\n\n\n\n\n\n1.3 1.2. Phate\n\nsce.tl.phate(adata, n_jobs=8)\nsce.pl.phate(adata, color=['stage', 'ct'], frameon=False, ncols=2)\n\n\n\n\n\n\n1.4 1.3. t-SNE\n\nsc.tl.tsne(adata, n_jobs=8, perplexity=300)\nsc.pl.tsne(adata, color=['stage', 'ct'], frameon=False, ncols=2)\n\n\n\n\n\n\n1.5 1.4. Force Directed Graph\n\nsc.tl.draw_graph(adata, n_jobs=8)\nsc.pl.draw_graph(adata, color=['experiment', 'stage', 'ct'], frameon=False, ncols=3, wspace=0.4)\n\n\n\n\n\n\n1.6 1.5. DC\n\n# Bug: https://github.com/scverse/scanpy/issues/2254\nsc.tl.diffmap(adata)\n\nadata.obsm[\"X_diffmap_\"] = adata.obsm[\"X_diffmap\"][:, 1:] \nsc.pl.embedding(adata, \"diffmap_\", color=['stage', 'ct'], frameon=False, ncols=2)"
  },
  {
    "objectID": "notebooks/03_mouse_analysis.html#pseudotime",
    "href": "notebooks/03_mouse_analysis.html#pseudotime",
    "title": "03 - mouse analysis",
    "section": "2 2. Pseudotime",
    "text": "2 2. Pseudotime\n\nadata\n\nAnnData object with n_obs  n_vars = 2004  3000\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig', 'stage', 'timepoint', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'n_genes', 'n_counts', 'batch_og', '_scvi_batch', '_scvi_labels', 'leiden'\n    var: 'gene_ids', 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n    uns: '_scvi_manager_uuid', '_scvi_uuid', 'hvg', 'log1p', 'neighbors', 'leiden', 'pca', 'stage_colors', 'ct_colors', 'umap', 'tsne', 'draw_graph', 'experiment_colors', 'diffmap_evals'\n    obsm: 'X_mde_scVI', 'X_scVI', 'X_pca', 'X_umap', 'X_phate', 'X_tsne', 'X_draw_graph_fa', 'X_diffmap', 'X_diffmap_'\n    varm: 'PCs'\n    layers: 'counts', 'scVI_normalized'\n    obsp: 'distances', 'connectivities'\n\n\n\n2.1 2.1. DPT package\n\nsc.pp.neighbors(adata, use_rep=USE_REP)\nsc.tl.diffmap(adata)\n\nsc.tl.paga(adata, groups='ct')\nsc.pl.paga(adata, color=['ct'], frameon=False, fontoutline=True)\nsc.tl.draw_graph(adata, init_pos='paga', n_jobs=10)\n\n\n\n\n\nwith plt.rc_context({\"figure.figsize\": (6, 6), \"figure.dpi\": (300)}):\n    sc.pl.paga(adata, color=['ct'], frameon=False, fontoutline=True)\n\n\n\n\n\nadata.uns['iroot'] = np.flatnonzero(adata.obs['ct']  == 'Zygote')[0]\nsc.tl.dpt(adata)\n\n\nsc.pl.draw_graph(adata, color=['dpt_pseudotime', 'ct'], frameon=False, ncols=2, cmap='tab20')\nsc.pl.draw_graph(adata, color=['experiment', 'ct'], frameon=False, ncols=2, cmap='tab20')\n\n\n\n\n\n\n\n\n\n2.2 2.2. scFATEs\n\nsc.pp.neighbors(adata, use_rep=USE_REP)\nsc.tl.draw_graph(adata, n_jobs=10)\n\n\nsc.pl.draw_graph(adata, color=['dpt_pseudotime', 'ct'], frameon=False, ncols=2, cmap='tab20')\nsc.pl.draw_graph(adata, color=['stage', 'timepoint'], frameon=False, ncols=2, cmap='tab20')\n\n\n\n\n\n\n\n\nsig = scf.tl.explore_sigma(adata,\n                         # Nodes=20,\n                         Nodes=60,\n                         use_rep=\"X_draw_graph_fa\",\n                         sigmas=[1000,500,400,300,200,100,50,10,1],\n                         seed=42,plot=True)\n\n\n\n\n\nscf.tl.tree(adata,\n            # Nodes=30,\n            Nodes=60,\n            use_rep=\"X_draw_graph_fa\",\n            method=\"ppt\",\n            ppt_nsteps=10,\n            ppt_sigma=sig,\n            ppt_lambda=100,\n            seed=42)\n\ninferring a principal tree --&gt; parameters used \n    60 principal points, sigma = 500, lambda = 100, metric = euclidean\n    fitting: 100%|| 10/10 [00:00&lt;00:00, 265.16it/s]\n    not converged (error: 0.019733842722593525)\n    finished (0:00:00) --&gt; added \n    .uns['ppt'], dictionnary containing inferred tree.\n    .obsm['X_R'] soft assignment of cells to principal points.\n    .uns['graph']['B'] adjacency matrix of the principal points.\n    .uns['graph']['F'] coordinates of principal points in representation space.\n\n\n\nscf.pl.graph(adata)\n\n\n\n\n\nscf.tl.root(adata, 58)\n\nnode 58 selected as a root --&gt; added\n    .uns['graph']['root'] selected root.\n    .uns['graph']['pp_info'] for each PP, its distance vs root and segment assignment.\n    .uns['graph']['pp_seg'] segments network information.\n\n\n\nscf.tl.pseudotime(adata,n_jobs=10,n_map=10,seed=42)\n\nprojecting cells onto the principal graph\n    mappings: 100%|| 10/10 [00:21&lt;00:00,  2.14s/it]\n    finished (0:00:22) --&gt; added\n    .obs['edge'] assigned edge.\n    .obs['t'] pseudotime value.\n    .obs['seg'] segment of the tree assigned.\n    .obs['milestones'] milestone assigned.\n    .uns['pseudotime_list'] list of cell projection from all mappings.\n\n\n\nscf.pl.trajectory(adata)\n\n\n\n\n\nsc.pl.draw_graph(adata, color=['stage', 'seg', 'dpt_pseudotime', 't'], frameon=False, ncols=2, cmap='tab20')\n\n\n\n\n\nscf.tl.dendrogram(adata, n_jobs=8)\nwith plt.rc_context({\"figure.figsize\": (6, 6)}):\n    scf.pl.dendrogram(adata,color=\"seg\")\n    scf.pl.dendrogram(adata,color=\"ct\",legend_loc=\"on data\",color_milestones=True,legend_fontoutline=True)\n\nGenerating dendrogram of tree\n    segment : 100%|| 5/5 [00:02&lt;00:00,  2.18it/s]\n    finished (0:00:02) --&gt; added \n    .obsm['X_dendro'], new embedding generated.\n    .uns['dendro_segments'] tree segments used for plotting.\n\n\n\n\n\n\n\n\n\n\n2.3 2.3. Palantir\nNOTE: doesnt work, skipping\n\n# import logging\n# logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n\n# sc.pp.neighbors(adata, use_rep=\"X_scANVI\")\n# sce.tl.palantir(adata, use_adjacency_matrix=True, distances_key=\"distances\")\n# sc.tl.tsne(adata, n_pcs=2, use_rep='X_palantir_multiscale', perplexity=30)\n\n# sc.pl.embedding(adata, basis='X_palantir_multiscale', color=['ct', 'stage'], frameon=False, ncols=2)"
  },
  {
    "objectID": "notebooks/03_mouse_analysis.html#differentially-expressed-genes",
    "href": "notebooks/03_mouse_analysis.html#differentially-expressed-genes",
    "title": "03 - mouse analysis",
    "section": "3 3. Differentially expressed genes",
    "text": "3 3. Differentially expressed genes\n\ndef filter_markers(df: pd.DataFrame, n_genes: int = 5, upper: bool = False):\n    # significant only\n    df = df[\n        (df[\"is_de_fdr_0.05\"])\n        & (df[\"bayes_factor\"] &gt; 3)\n        & (df[\"non_zeros_proportion1\"] &gt; 0.1)\n        & (df[\"lfc_median\"] &gt; 0)\n    ]\n    comparisons = df.comparison.unique()\n\n    deg_df = {}\n    for comparison in comparisons:\n        cluster = comparison.split(\" \")[0]\n        markers = (\n            df.query(\"comparison == @comparison\")\n            .sort_values(by=\"lfc_median\", ascending=False)\n            .head(n_genes)\n        )\n        deg_df[cluster] = (\n            markers.index.str.upper().tolist() if upper else markers.index.tolist()\n        )\n\n    return deg_df\n\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi/\")\n\nINFO     File ../results/02_mouse_integration/scvi/model.pt already downloaded                                     \n\n\n\nm_ct = vae.differential_expression(groupby=\"ct\")\nm_ct_filt = filter_markers(m_ct, n_genes=10)\n\nDE...: 100%|| 15/15 [00:16&lt;00:00,  1.11s/it]\n\n\n\npd.DataFrame.from_dict(m_ct_filt, orient='index').transpose()\n\n\n\n\n\n\n\n\nZygote\n2C\n4C\n8C\n16C\nE3.25-ICM\nE3.25-TE\nE3.5-ICM\nE3.5-TE\nE3.5-EPI\nE3.5-PrE\nE3.75-ICM\nE4.5-TE\nE4.5-EPI\nE4.5-PrE\n\n\n\n\n0\naa545190\noog3\nobox8\nobox8\na430060f13rik\ngm24289\ngata3\n1700021a07rik\ntmprss2\nfbxw10\ngm19510\nrnase12\ns100a9\ncalca\nhas2\n\n\n1\noosp3\nau016765\ngm4850\ngm21731\ngm11544\ngm24920\ngm24920\ndglucy\nadh1\nnkain4\nfoxa2\niglv2\nfasl\nnphs1os\nclic5\n\n\n2\nau016765\noosp3\nb020004c17rik\ngm11544\nxkr9\ngm24616\ngm24289\ngm807\nslc15a2\nlefty2\nlefty2\nnnmt\ncald1\ngm12690\nspink1\n\n\n3\noog3\ngm4850\noog3\na430060f13rik\ndio1\nxkr9\ngm5907\naldh3a1\nepn3\nmal\nsox17\nc330004p14rik\nrhox6\nstmn2\nclic6\n\n\n4\nobox2\nomt2a\ngm36976\nb020004c17rik\ngm33508\ngm25328\ntmprss2\nnkx6-2\ncdx2\ngm26564\ndkk1\ngm30717\nh19\ncol18a1\nhabp2\n\n\n5\nc87499\naa545190\nomt2a\naf067063\ngm24289\nsnord35a\ncryab\ncrygd\ngata3\ncobl\nbmper\ngm6284\nelf5\nfgf15\ntfec\n\n\n6\ne330034g19rik\ntcl1b5\nd7ertd443e\nd7ertd443e\ngm5435\ncck\ngm6334\nsox2\ndppa1\ncd3g\nlmo2\ngpx8\nhpgd\ngm26564\nrhox6\n\n\n7\ngm43269\ntcl1b4\ngm21731\ngm13339\ngm12446\ngm25636\nau021092\nmal\nid2\nmyh13\nf2r\ngm13339\nankrd1\nctsw\nttr\n\n\n8\ntcl1b4\nc87499\ngdap1\ndynap\ndynap\ndio1\narg2\nlmo2\ncryab\ngm12688\nserpinh1\np3h2\nslc16a3\nprss50\nchst15\n\n\n9\noosp2\noosp2\nspz1\nxkr9\nsnord35a\ngm33508\nnat8\ngm5662\nserpinb6b\ngm807\nflrt3\nstfa1\ntmprss2\nc330004p14rik\np3h2\n\n\n\n\n\n\n\n\nsc.pl.dotplot(adata, m_ct_filt, groupby='ct', dendrogram=False, standard_scale='var')\nsc.pl.matrixplot(adata, m_ct_filt, groupby='ct', dendrogram=False, standard_scale='var')\n\n\n\n\n\n\n\n\n3.1 4. Markers\n\nzygote/2C: zscan4a, zscan4b, zscan4c, zscan4d, zscan4f\n8c: carm1, cdx2, pard3, pard6, apkc\ntotipotency: cdx2, gata6, nanog\napical domain: apkc, par2, par6, ezrin\nbasolateral domain: cdh1, lgl, par1\nTE: cdx2, nanog, gata6\ninner cell mass: pou5f1, nanog, gata6, sox2, lats, klf4, dppa3, esrrb\nprimitive endoderm: pou5f1, gata6, gata4, dab2, sox7, sox17, pdgfra, hnf4a\nepiblast: pou5f1, nanog, sox2, fgf4, pecam, fgf5, bmp4, klf2\n\n\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC1994725/\nhttps://link.springer.com/article/10.1007/s00441-021-03530-8\nhttps://journals.biologists.com/dev/article/143/7/1063/47817/Lineage-specification-in-the-mouse-preimplantation\n\n\nsc.tl.embedding_density(adata, basis='draw_graph_fa', groupby='ct')\nsc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_ct')\n\n\n\n\n\nlineage_markers = pd.read_excel(\"../data/external/mouse_lineage_markers.xlsx\", sheet_name=\"Sheet1\").fillna('')\nlineage_markers\n\n\n\n\n\n\n\n\nZygote\n2C\n4C\n8C\n16C\nTE\nICM\nPrE\nEPI\n\n\n\n\n0\nZswim3\nZscan4a\nSin3a\nPou5f1\nPou5f1\nCdx2\nPou5f1\nGata6\nPou5f1\n\n\n1\nTrim28\nZscan4b\nClock\nNanog\nNanog\nGata3\nGata6\nGata4\nNanog\n\n\n2\nPadi6\nZscan4c\nSox21\nSox2\nSox2\nGata2\nNanog\nSox7\nSox2\n\n\n3\n\nZscan4d\nCarm1\nCdx2\nCdx2\nEomes\nTfcp2l1\nSox17\nFgf4\n\n\n4\n\nZscan4f\n\nYap1\nEsrrb\nLats2\nDppa3\nPdgfra\nKlf2\n\n\n5\n\nZfp352\n\nEifg1\nPrdm14\nTfap2c\nEsrrb\nDab2\n\n\n\n6\n\nUsp17ld\n\nPrdm14\nTfap2c\n\nPrdm14\n\n\n\n\n7\n\nRxra\n\n\nGata3\n\n\n\n\n\n\n8\n\nTmem92\n\n\nGata2\n\n\n\n\n\n\n9\n\nPramef25\n\n\n\n\n\n\n\n\n\n10\n\nDux\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor stage, genes in lineage_markers.to_dict('list').items():\n    common_genes = adata.var_names.intersection([str.lower(g) for g in genes if g != ''])\n    \n    # print(stage, common_genes)\n    sc.pl.draw_graph(adata, color=['stage', *common_genes], title=[stage, *common_genes],\n                     groups=stage, legend_loc=None, frameon=False, ncols=len(common_genes) + 1)"
  },
  {
    "objectID": "notebooks/03_mouse_analysis.html#save-model",
    "href": "notebooks/03_mouse_analysis.html#save-model",
    "title": "03 - mouse analysis",
    "section": "4 Save model",
    "text": "4 Save model\n\nadata.write(\"../results/03_mouse.processed.h5ad\")"
  },
  {
    "objectID": "notebooks/03_mouse_analysis.html#other",
    "href": "notebooks/03_mouse_analysis.html#other",
    "title": "03 - mouse analysis",
    "section": "5 4. OTHER",
    "text": "5 4. OTHER\n\n5.1 2. scGEN\nscGen returns imputed counts only. In this case we are not able to run DEGs because we need to have normalized counts. The predict function also wont work because we dont have any perturbation in the dataset.\n\nimport scgen\n\n\nmscgen = scgen.SCGEN.load(\"../results/02_mouse_integration/scgen/\")\n\n\ncorrected_adata = mscgen.batch_removal()\ncorrected_adata\n\n\nsc.pp.neighbors(corrected_adata, use_rep='corrected_latent')\nsc.tl.draw_graph(corrected_adata)\n\n\nsc.pl.draw_graph(corrected_adata, color=['ct', 'Stage'], wspace=0.4, frameon=False)\n\n\nsc.tl.umap(corrected_adata)\nsc.pl.umap(corrected_adata, color=['batch', 'Stage'], wspace=0.4, frameon=False)\n\n\n\n5.2 3. Integration stats\n\nfrom rich import print\nfrom scib_metrics.benchmark import Benchmarker\n\n\nbm = Benchmarker(\n    adata,\n    batch_key=\"batch\",\n    label_key=\"ct\",\n    embedding_obsm_keys=[\"X_pca\", \"X_scVI\", \"X_scANVI\", \"X_scgen\"],\n    n_jobs=-1,\n)\nbm.benchmark()\n\n\nbm.plot_results_table(min_max_scale=False)\n\n\nfrom pysankey import sankey\n\n\n%run ../scripts/helpers.py\n\n\nsc.tl.dendrogram(adata, groupby=\"leiden\", key_added=\"dendrogram_leiden\")\nsc.tl.dendrogram(adata, groupby=\"ct\", key_added=\"dendrogram_ct\")\n\n\nwith plt.rc_context({\"figure.figsize\": [20, 20]}):\n    sc.pl.correlation_matrix(adata, groupby=\"ct\", show_correlation_numbers=True)\n\n\n_ = sc.pl.dendrogram(adata, groupby=\"ct\", orientation='top')\n\n\n\n5.3 3.1. Prediction\n\ndef get_predictions(lvae: scvi.model.SCANVI, threshold: float = 0.85):\n    df = pd.DataFrame(zip(predictions.idxmax(axis=1), predictions.max(axis=1)), columns=['predicted', 'score'])\n    df['predicted_filt'] = 'Unknown'\n    df.loc[df.score &gt;= threshold, 'predicted_filt'] = df.loc[df.score &gt;= threshold, 'predicted']\n    df['uncertainty'] = np.maximum(1 - df.score, 0)\n\n    return df\n\n\nlvae = scvi.model.SCANVI.load(\"../results/02-mouse/\")\nadata.obs[[\"predicted\", \"score\", \"predicted_filt\", \"uncertainty\"]] = get_predictions(lvae).values\n\n\nsc.pl.draw_graph(adata, color=['ct', 'predicted', 'uncertainty'], frameon=False, ncols=3)\n\n\ndf = adata.obs.groupby([\"ct\", \"predicted\"]).size().unstack(fill_value=0)\nnorm_df = df / df.sum(axis=0)\n\nplt.figure(figsize=(8, 8))\n_ = plt.pcolor(norm_df)\n_ = plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns, rotation=90)\n_ = plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n_ = plt.colorbar()\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Observed\")\n\n\n# Stats\nfrom sklearn.metrics import balanced_accuracy_score\n\nbalanced_accuracy_score(adata.obs[\"ct\"].values, adata.obs[\"predicted\"].values)"
  },
  {
    "objectID": "notebooks/04_human_cellrank.html",
    "href": "notebooks/04_human_cellrank.html",
    "title": "Human CellRank",
    "section": "",
    "text": "import cellrank as cr\nimport scanpy as sc\n\nsc.settings.set_figure_params(frameon=False, dpi=100)\ncr.settings.verbosity = 2\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=UserWarning)\n\nimport scvelo as scv\nscv.set_figure_params('scvelo')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nhuman_adata = sc.read('../results/02_human_integration/scvi/adata.h5ad')\nhuman_adata.obs.head()\n\n\n\n\n\n\n\n\nday\nct\nexperiment\ntechnology\nn_counts\nn_genes\nct_fine\nbatch\nstage\ntimepoint\nct_orig\n_scvi_batch\n_scvi_labels\n\n\nindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nERX3015937_ERX3015937\n5.0\nUnknown\nMeistermann et al., 2021\nSMARTSeq2\n708313.0\n5761\nUnknown\nMeistermann et al., 2021\nUnknown\nE5.0\nUnknown\n0\n0\n\n\nERX3015939_ERX3015939\n5.0\nUnknown\nMeistermann et al., 2021\nSMARTSeq2\n402557.0\n5689\nUnknown\nMeistermann et al., 2021\nUnknown\nE5.0\nUnknown\n0\n0\n\n\nERX3015940_ERX3015940\n5.0\nUnknown\nMeistermann et al., 2021\nSMARTSeq2\n511338.0\n6039\nUnknown\nMeistermann et al., 2021\nUnknown\nE5.0\nUnknown\n0\n0\n\n\nERX3015941_ERX3015941\n5.0\nUnknown\nMeistermann et al., 2021\nSMARTSeq2\n994383.0\n8383\nUnknown\nMeistermann et al., 2021\nUnknown\nE5.0\nUnknown\n0\n0\n\n\nERX3015936_ERX3015936\n5.0\nUnknown\nMeistermann et al., 2021\nSMARTSeq2\n1389486.0\n7762\nUnknown\nMeistermann et al., 2021\nUnknown\nE5.0\nUnknown\n0\n0\nsc.pp.neighbors(human_adata, use_rep='X_scVI')\nsc.tl.diffmap(human_adata)\n\nsc.tl.paga(human_adata, groups='C_scANVI_nsamples')\nsc.pl.paga(human_adata, color=['C_scANVI_nsamples'], frameon=False, fontoutline=True)\nsc.tl.draw_graph(human_adata, init_pos='paga', n_jobs=10)\n\n2024-01-12 13:25:32.739451: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\nKeyError: \"`groups` key 'C_scANVI_nsamples' not found in `adata.obs`.\"\nsc.pl.paga(human_adata, color=['C_scANVI_nsamples'], frameon=False, fontoutline=True, threshold=0.2)\nsc.pl.embedding(human_adata, basis=\"X_draw_graph_fa\", color=[\"day\"])"
  },
  {
    "objectID": "notebooks/04_human_cellrank.html#cellrank-experimental-time-kernel",
    "href": "notebooks/04_human_cellrank.html#cellrank-experimental-time-kernel",
    "title": "Human CellRank",
    "section": "1 Cellrank experimental time kernel",
    "text": "1 Cellrank experimental time kernel\n\nhuman_adata.obs.day.value_counts()\n\n\nhuman_adata_8C_and_later = human_adata[human_adata.obs.day &gt;= 3].copy()\n\n\nfrom cellrank.kernels import RealTimeKernel\n\n\nhuman_adata.obs['day_categorical'] = human_adata.obs['day'].astype('category')\n\n\nfrom moscot.problems.time import TemporalProblem\n\n\ntp = TemporalProblem(human_adata_8C_and_later)\n\n\ntp = tp.prepare(time_key=\"day_categorical\")\n\n\ntp = tp.solve(epsilon=1e-3, tau_a=0.95, scale_cost=\"mean\")\n\n\ntmk = RealTimeKernel.from_moscot(tp)\n\n\ntmk.compute_transition_matrix(self_transitions=\"all\", conn_weight=0.2, threshold=\"auto\")\n\n\ntmk.plot_random_walks(\n    max_iter=500,\n    start_ixs={\"day_categorical\": 3.0},\n    basis=\"draw_graph_fa\",\n    seed=0,\n    dpi=150,\n    size=30,\n)\n\n\nfrom cellrank.kernels import PseudotimeKernel\npk = PseudotimeKernel(human_adata, time_key=\"day\")\npk.compute_transition_matrix()\n\n\npk.plot_random_walks(\n    seed=0,\n    n_sims=100,\n    start_ixs={\"C_scANVI_nsamples\": \"Prelineage\"},\n    basis=\"X_draw_graph_fa\",\n    legend_loc=\"right\",\n    dpi=150,\n)\n\n\npk.plot_projection(basis=\"X_draw_graph_fa\", recompute=True, color='C_scANVI_nsamples')"
  },
  {
    "objectID": "notebooks/04_mouse_cellrank.html",
    "href": "notebooks/04_mouse_cellrank.html",
    "title": "04 - CellRank",
    "section": "",
    "text": "!which pip\n\n~/projects/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\nimport cellrank as cr\nimport scanpy as sc\n\nsc.settings.set_figure_params(frameon=False, dpi=100)\ncr.settings.verbosity = 2\nimport warnings\nwarnings.simplefilter(\"ignore\", category=UserWarning)\nimport scvelo as scv\nscv.set_figure_params('scvelo')\nadata = sc.read(\"../results/03_mouse.processed.h5ad\")\nadata\n\nAnnData object with n_obs  n_vars = 2004  3000\n    obs: 'batch', 'experiment', 'technology', 'ct', 'ct_orig', 'stage', 'timepoint', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'n_genes', 'n_counts', 'batch_og', '_scvi_batch', '_scvi_labels', 'leiden', 'dpt_pseudotime', 't', 'seg', 'edge', 't_sd', 'milestones', 'draw_graph_fa_density_ct'\n    var: 'gene_ids', 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n    uns: '_scvi_manager_uuid', '_scvi_uuid', 'ct_colors', 'ct_sizes', 'dendro_segments', 'diffmap_evals', 'draw_graph', 'draw_graph_fa_density_ct_params', 'experiment_colors', 'graph', 'hvg', 'iroot', 'leiden', 'log1p', 'milestones_colors', 'neighbors', 'paga', 'pca', 'ppt', 'pseudotime_list', 'seg_colors', 'stage_colors', 'timepoint_colors', 'tsne', 'umap'\n    obsm: 'X_R', 'X_dendro', 'X_diffmap', 'X_diffmap_', 'X_draw_graph_fa', 'X_mde_scVI', 'X_pca', 'X_phate', 'X_scVI', 'X_tsne', 'X_umap'\n    varm: 'PCs'\n    layers: 'counts', 'scVI_normalized'\n    obsp: 'connectivities', 'distances'\nsc.pp.neighbors(adata, use_rep='X_scVI')\nsc.tl.diffmap(adata)\n\nsc.tl.paga(adata, groups='ct')\nsc.pl.paga(adata, color=['ct'], frameon=False, fontoutline=True)\nsc.tl.draw_graph(adata, init_pos='paga', n_jobs=10)\n\n2023-11-20 20:08:29.075804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nsc.pl.paga(adata, color=['ct'], frameon=False, fontoutline=True, threshold=0.2)\nsc.pl.embedding(adata, basis=\"X_draw_graph_fa\", color=[\"stage\", \"t\", \"dpt_pseudotime\"])"
  },
  {
    "objectID": "notebooks/04_mouse_cellrank.html#pseudokernel",
    "href": "notebooks/04_mouse_cellrank.html#pseudokernel",
    "title": "04 - CellRank",
    "section": "1 1. PseudoKernel",
    "text": "1 1. PseudoKernel\n\nfrom cellrank.kernels import PseudotimeKernel\n\npk = PseudotimeKernel(adata, time_key=\"t\")\n\n\npk.compute_transition_matrix()\n\n\npk.plot_random_walks(\n    seed=0,\n    n_sims=100,\n    start_ixs={\"stage\": \"Zygote\"},\n    basis=\"X_draw_graph_fa\",\n    legend_loc=\"right\",\n    dpi=150,\n)\n\n\npk.plot_projection(basis=\"X_draw_graph_fa\", recompute=True, color='stage')\n\n\n1.1 Initial and Terminal states\n\ng = cr.estimators.GPCCA(pk)\nprint(g)\n\n\ng.fit(cluster_key=\"stage\", n_states=[4, 12])\ng.plot_macrostates(which=\"all\", discrete=True, legend_loc=\"right\", s=100, basis='X_draw_graph_fa')\n\n\ng.predict_terminal_states(n_states=3)\ng.plot_macrostates(which=\"terminal\", legend_loc=\"right\", s=100, basis='X_draw_graph_fa')\n\n\ng.plot_macrostates(which=\"terminal\", discrete=False, basis='X_draw_graph_fa')\n\n\ng.predict_initial_states(allow_overlap=True)\ng.plot_macrostates(which=\"initial\", legend_loc=\"right\", s=100, basis='X_draw_graph_fa')\n\n\ng.plot_coarse_T()\n\n\ng.compute_fate_probabilities()\ng.plot_fate_probabilities(same_plot=False, basis='X_draw_graph_fa')\n\n\ng.plot_fate_probabilities(same_plot=True, basis='X_draw_graph_fa', color=['red', 'green', 'blue', 'black'])\n\n\ng.compute_absorption_times()\n\n\ng.compute_lineage_drivers()\n\n\ng.absorption_times"
  },
  {
    "objectID": "notebooks/04_mouse_cellrank.html#realtimekernel",
    "href": "notebooks/04_mouse_cellrank.html#realtimekernel",
    "title": "04 - CellRank",
    "section": "2 2. RealtimeKernel",
    "text": "2 2. RealtimeKernel\n\nfrom cellrank.kernels import RealTimeKernel\nfrom moscot.problems.time import TemporalProblem\n\n\nadata.obs['cr_timepoint'] = adata.obs.timepoint.cat.rename_categories({\n    'Zygote': 0.5,\n    '2C': 1.5, \n    '4C': 2.0, \n    '8C': 2.5, \n    '16C': 3, \n    'E3.25': 3.25, \n    'E3.5': 3.5, \n    'E3.75': 3.75, \n    'E4.5': 4.5,\n})\n\n\nadata.obs.cr_timepoint.value_counts()\n\n3.5     995\n4.5     343\n3.0     198\n2.5     115\n2.0     114\n3.25     87\n1.5      86\n3.75     48\n0.5      18\nName: cr_timepoint, dtype: int64\n\n\n\nsc.pl.embedding(adata, basis=\"X_draw_graph_fa\", color=[\"stage\", \"t\", \"cr_timepoint\"])\n\n\n\n\n\nadata_sub = adata[adata.obs.cr_timepoint != 0.5].copy()\nadata_sub.obs.cr_timepoint.value_counts()\n# adata_sub = adata.copy()\n\n3.5     995\n4.5     343\n3.0     198\n2.5     115\n2.0     114\n3.25     87\n1.5      86\n3.75     48\nName: cr_timepoint, dtype: int64\n\n\n\nsc.pp.pca(adata_sub)\nsc.pp.neighbors(adata_sub, random_state=0)\n\n\ntp = TemporalProblem(adata_sub)\n\n\n# tp = tp.prepare(time_key=\"cr_timepoint\", joint_attr='X_scVI')\ntp = tp.prepare(time_key=\"cr_timepoint\")\n\nINFO     Ordering Index(['SRX259148', 'SRX259191', 'SRX259121', 'SRX259140', 'SRX259161',                          \n                'SRX259210', 'SRX259133', 'SRX259142', 'SRX259106', 'SRX386064',                                   \n                ...                                                                                                \n                'GSM2687789', 'GSM2687797', 'GSM2687761', 'GSM2687760', 'GSM2687841',                              \n                'GSM2687771', 'GSM2687764', 'GSM2687837', 'GSM2687752', 'GSM2687839'],                             \n               dtype='object', length=1986) in ascending order.                                                    \nINFO     Computing pca with `n_comps=30` for `xy` using `adata.X`                                                  \nINFO     Computing pca with `n_comps=30` for `xy` using `adata.X`                                                  \nINFO     Computing pca with `n_comps=30` for `xy` using `adata.X`                                                  \nINFO     Computing pca with `n_comps=30` for `xy` using `adata.X`                                                  \nINFO     Computing pca with `n_comps=30` for `xy` using `adata.X`                                                  \nINFO     Computing pca with `n_comps=30` for `xy` using `adata.X`                                                  \nINFO     Computing pca with `n_comps=30` for `xy` using `adata.X`                                                  \n\n\n\ntp = tp.solve(epsilon=1e-3, tau_a=0.95, scale_cost=\"mean\")\n\nINFO     Solving `7` problems                                                                                      \nINFO     Solving problem BirthDeathProblem[stage='prepared', shape=(48, 343)].                                     \nINFO     Solving problem BirthDeathProblem[stage='prepared', shape=(115, 198)].                                    \nINFO     Solving problem BirthDeathProblem[stage='prepared', shape=(87, 48)].                                      \nINFO     Solving problem BirthDeathProblem[stage='prepared', shape=(995, 87)].                                     \nINFO     Solving problem BirthDeathProblem[stage='prepared', shape=(198, 995)].                                    \nINFO     Solving problem BirthDeathProblem[stage='prepared', shape=(114, 115)].                                    \nINFO     Solving problem BirthDeathProblem[stage='prepared', shape=(86, 114)].                                     \n\n\n\ntmk = RealTimeKernel.from_moscot(tp)\n\n\ntmk.compute_transition_matrix()\n\n100%|| 7/7 [00:00&lt;00:00, 58254.22time pair/s]\n\n\nUsing automatic `threshold=2.4929099680338496e-42`\nComputing transition matrix based on `adata.obsp['connectivities']`\n    Finish (0:00:00)\n\n\nRealTimeKernel[n=1986, threshold='auto', self_transitions='connectivities']\n\n\n\ntmk.plot_random_walks(\n    max_iter=500,\n    start_ixs={\"cr_timepoint\": 1.5},\n    basis=\"draw_graph_fa\",\n    seed=0,\n    dpi=150,\n    size=30,\n)\n\nSimulating `100` random walks of maximum length `500`\n    Finish (0:00:07)\nPlotting random walks\n\n\n100%|| 100/100 [00:06&lt;00:00, 14.52sim/s]\n\n\n\n\n\n\nax = tmk.plot_single_flow(cluster_key='stage', time_key=\"cr_timepoint\", cluster=\"ICM\", show=False)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.invert_xaxis()\n\nWARNING: Categories are not ordered. Using ascending order\nComputing flow from `ICM` into `7` cluster(s) in `7` time points\nPlotting flow from `ICM` into `3` cluster(s) in `7` time points\n\n\n\n\n\n\ng = cr.estimators.GPCCA(tmk)\ng\n\nGPCCA[kernel=RealTimeKernel[n=1986], initial_states=None, terminal_states=None]\n\n\n\ng.fit(cluster_key=\"stage\", n_states=[4, 12])\ng.plot_macrostates(which=\"all\", discrete=True, legend_loc=\"right\", s=100, basis='X_draw_graph_fa')\n\nWARNING: Unable to import `petsc4py` or `slepc4py`. Using `method='brandts'`\nWARNING: For `method='brandts'`, dense matrix is required. Densifying\nComputing Schur decomposition\nAdding `adata.uns['eigendecomposition_fwd']`\n       `.schur_vectors`\n       `.schur_matrix`\n       `.eigendecomposition`\n    Finish (0:00:10)\nCalculating minChi criterion in interval `[4, 12]`\nComputing `6` macrostates\nAdding `.macrostates`\n       `.macrostates_memberships`\n       `.coarse_T`\n       `.coarse_initial_distribution\n       `.coarse_stationary_distribution`\n       `.schur_vectors`\n       `.schur_matrix`\n       `.eigendecomposition`\n    Finish (0:00:02)\n\n\n\n\n\n\ng.predict_terminal_states(n_states=3, allow_overlap=True)\ng.plot_macrostates(which=\"terminal\", legend_loc=\"right\", s=100, basis='X_draw_graph_fa')\n\nAdding `adata.obs['term_states_fwd']`\n       `adata.obs['term_states_fwd_probs']`\n       `.terminal_states`\n       `.terminal_states_probabilities`\n       `.terminal_states_memberships\n    Finish`\n\n\n\n\n\n\ng.plot_macrostates(which=\"terminal\", discrete=False, basis='X_draw_graph_fa')\n\n\n\n\n\ng.predict_initial_states(allow_overlap=True)\ng.plot_macrostates(which=\"initial\", legend_loc=\"right\", s=100, basis='X_draw_graph_fa')\n\nAdding `adata.obs['init_states_fwd']`\n       `adata.obs['init_states_fwd_probs']`\n       `.initial_states`\n       `.initial_states_probabilities`\n       `.initial_states_memberships\n    Finish`"
  },
  {
    "objectID": "notebooks/04_mouse_cellrank.html#pseudotime",
    "href": "notebooks/04_mouse_cellrank.html#pseudotime",
    "title": "04 - CellRank",
    "section": "3 Pseudotime",
    "text": "3 Pseudotime\n\nimport scvelo as scv\nscv.set_figure_params('scvelo')\n\n\ntest = scv.datasets.pancreas()\ntest\n\n\nscv.pp.filter_genes(test, min_shared_counts=20)\nscv.pp.normalize_per_cell(test)\nscv.pp.filter_genes_dispersion(test, n_top_genes=2000)\nscv.pp.log1p(test)\n\n\nscv.pp.filter_and_normalize(test, min_shared_counts=20, n_top_genes=2000)\nscv.pp.moments(test, n_pcs=30, n_neighbors=30)\n\n\nscv.tl.velocity(test)\n\n\nscv.tl.velocity_graph(test)\n\n\ntest\n\n\ntest.uns.keys()\n\n\ntest.uns['velocity_graph']\n\n\nscv.pl.velocity_embedding_stream(test, basis='umap')\n\n\nscv.pl.velocity_graph(test, threshold=.1)\n\n\nscv.tl.velocity_pseudotime(test, use_velocity_graph=False)\nscv.pl.scatter(test, color='velocity_pseudotime', cmap='gnuplot')\n\n\ntest.obs.end_points"
  },
  {
    "objectID": "notebooks/04_mouse_cellrank.html#hack",
    "href": "notebooks/04_mouse_cellrank.html#hack",
    "title": "04 - CellRank",
    "section": "4 Hack",
    "text": "4 Hack\n\n# tmk.adata.obs[tmk.adata.obs.timepoint == 'E4.5'].sort_values(by='t')\n\n\nfrom scvelo.tl.velocity_pseudotime import VPT\nfrom scvelo.utils import scale\nimport numpy as np\n\n\n# vpt = VPT(test)\nvpt = VPT(tmk.adata)\n\n\nvpt._transitions_sym = tmk.transition_matrix\n\n\nvpt.compute_eigen(n_comps=10)\n\n\nvpt.set_iroot('SRX259216')\nvpt.compute_pseudotime()\ndpt_root = vpt.pseudotime\n\n\nvpt.set_iroot('Lib1-2_E4.5_CAGCTGGGTAACGCGA')\nvpt.compute_pseudotime(inverse=True)\ndpt_end = vpt.pseudotime\n\n\n# merge dpt_root and inverse dpt_end together\nvpt.pseudotime = np.nan_to_num(dpt_root) + np.nan_to_num(dpt_end)\nvpt.pseudotime[np.isfinite(dpt_root) & np.isfinite(dpt_end)] /= 2\nvpt.pseudotime = scale(vpt.pseudotime)\nvpt.pseudotime[np.isnan(dpt_root) & np.isnan(dpt_end)] = np.nan\n\n\nvpt.branchings_segments()\n\n\nadata.obs['hack'] = 0\nadata.obs.loc[tmk.adata.obs_names, 'hack'] = vpt.pseudotime\n\n\nsc.pl.embedding(adata, basis=\"X_draw_graph_fa\", color=[\"stage\", \"t\", \"hack\"], cmap='tab10')"
  },
  {
    "objectID": "notebooks/04_mouse_cellrank.html#save-session",
    "href": "notebooks/04_mouse_cellrank.html#save-session",
    "title": "04 - CellRank",
    "section": "5 Save session",
    "text": "5 Save session\n\n# Doesn't work\n# TypeError: _write_lineage() got an unexpected keyword argument '_writer'\n# Above error raised while writing key 'macrostates_fwd_memberships' of &lt;class 'h5py._hl.group.Group'&gt; to /\n\n# adata.write(\"../results/04_mouse.cellrank.h5ad\")"
  },
  {
    "objectID": "notebooks/05_human_classifier.html",
    "href": "notebooks/05_human_classifier.html",
    "title": "Re-annotation and classification",
    "section": "",
    "text": "import scvi\nimport pandas as pd\nimport scanpy as sc\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nfrom rich import print\nfrom scib_metrics.benchmark import Benchmarker\nfrom scvi.model.utils import mde\n\n\nimport warnings\nfrom lightning_fabric.plugins.environments.slurm import PossibleUserWarning\nwarnings.simplefilter(action='ignore', category=PossibleUserWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nscvi.settings.seed = 42\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n[rank: 0] Global seed set to 42\n\n\n\n%run ../scripts/helpers.py\n\n\nsc.set_figure_params(figsize=(10, 6))\n\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n%config InlineBackend.figure_format='retina'\n\n\nlvae = scvi.model.SCANVI.load(\"../results/02_human_integration/scanvi/\")\nhuman_adata = lvae.adata.copy()\n\nINFO     File ../results/02_human_integration/scanvi/model.pt already downloaded                                   \n\n\n\nhuman_adata.obs['C_scANVI'] = lvae.predict(human_adata)\n\nhuman_adata.obs['updated_ct'] = human_adata.obs['ct_fine'].tolist()\nhuman_adata.obs.loc[human_adata.obs['updated_ct'] == 'Unknown','updated_ct'] = human_adata.obs.loc[human_adata.obs['updated_ct'] == 'Unknown','C_scANVI']\n\nINFO     AnnData object appears to be a copy. Attempting to transfer setup.                                        \n\n\n\ncmtx = sc.metrics.confusion_matrix(\"ct_fine\", \"C_scANVI\", human_adata.obs)\nwith sns.axes_style(\"ticks\"):\n    sns.heatmap(cmtx, cmap=sns.dark_palette(\"white\", reverse=True, as_cmap=True),linewidth=.5)\n\n\n\n\n\nlvae_nsamples = scvi.model.SCANVI.from_scvi_model(\n    scvi.model.SCVI.load(\"../results/02_human_integration/scvi/\"),\n    adata=human_adata,\n    labels_key=\"ct_fine\",\n    unlabeled_category=\"Unknown\",\n)\nlvae_nsamples.train(\n    n_samples_per_label = 15,\n)\n\nINFO     File ../results/02_human_integration/scvi/model.pt already downloaded                                     \nINFO     Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \nINFO     Training for 10 epochs.                                                                                   \nEpoch 10/10: 100%|| 10/10 [00:03&lt;00:00,  3.14it/s, v_num=1, train_loss_step=6.53e+3, train_loss_epoch=6.54e+3]Epoch 10/10: 100%|| 10/10 [00:03&lt;00:00,  3.12it/s, v_num=1, train_loss_step=6.53e+3, train_loss_epoch=6.54e+3]\n\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n`Trainer.fit` stopped: `max_epochs=10` reached.\n\n\n\nhuman_adata.obs[\"C_scANVI_nsamples\"] = lvae_nsamples.predict(human_adata)\n\n\ncmtx = sc.metrics.confusion_matrix(\"ct_fine\", \"C_scANVI_nsamples\", human_adata.obs)\n\nwith sns.axes_style(\"ticks\"):\n    sns.heatmap(cmtx, cmap=sns.dark_palette(\"white\", reverse=True, as_cmap=True),linewidth=.5)\n\n\n\n\n\nlvae_nsamples\n\nScanVI Model with the following params: \nunlabeled_category: Unknown, n_hidden: 128, n_latent: 10, n_layers: 2, dropout_rate: 0.1, dispersion: gene, \ngene_likelihood: nb\nTraining status: Trained\nModel's adata is minified?: False\n\n\n\n\n\n\n\nlvae_nsamples.save('../results/02_human_integration/05_scanvi_ns15/', save_anndata=True)"
  },
  {
    "objectID": "notebooks/05_mouse_classifier.html",
    "href": "notebooks/05_mouse_classifier.html",
    "title": "05 - mouse classifier",
    "section": "",
    "text": "In this notebook we construct multiple classifier which will try to predict cell type (ct):\n!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\n%matplotlib inline\n\nimport scvi\nimport scgen\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom typing import Tuple\n\nfrom numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\nimport warnings\n\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\nscvi.settings.seed = 0\n\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n[rank: 0] Global seed set to 0\n%run ../scripts/helpers.py\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n\n\ndef prediction_stats(label: str, model, y_test, y_pred, X, Y):\n    \n    stats = [ \n        label,\n        accuracy_score(y_test, y_pred),\n        balanced_accuracy_score(y_test, y_pred),\n        f1_score(y_test, y_pred, average=\"micro\"),\n        f1_score(y_test, y_pred, average=\"macro\"),\n        np.nan\n    ]\n\n    if model is None:\n        return stats\n\n    # Cross Validation\n    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    scores = cross_val_score(model, X, Y, cv = kfold, n_jobs = 8)\n    stats[-1] = scores.mean()\n    \n    return stats\n\n\nstats = []"
  },
  {
    "objectID": "notebooks/05_mouse_classifier.html#scanvi",
    "href": "notebooks/05_mouse_classifier.html#scanvi",
    "title": "05 - mouse classifier",
    "section": "1 1. scANVI",
    "text": "1 1. scANVI\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\n\nINFO     File ../results/02_mouse_integration/scanvi/model.pt already downloaded                                   \n\n\n\ny_test = lvae.adata.obs.ct.values\ny_pred = lvae.predict(lvae.adata)\n\nstats.append(prediction_stats(\"scANVI\", None, y_test, y_pred, None, None))"
  },
  {
    "objectID": "notebooks/05_mouse_classifier.html#scanvi-n_samples_per_label15",
    "href": "notebooks/05_mouse_classifier.html#scanvi-n_samples_per_label15",
    "title": "05 - mouse classifier",
    "section": "2 2. scANVI (n_samples_per_label=15)",
    "text": "2 2. scANVI (n_samples_per_label=15)\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi/\")\nlvae = scvi.model.SCANVI.from_scvi_model(vae, labels_key=\"ct\", unlabeled_category=\"Unknown\")\nlvae.train(max_epochs=20, n_samples_per_label=15)\nlvae.save(\"../results/02_mouse_integration/scanvi_ns_15/\", overwrite=True, save_anndata=True)\n\nINFO     File ../results/02_mouse_integration/scvi/model.pt already downloaded                                     \nINFO     Training for 20 epochs.                                                                                   \nEpoch 20/20: 100%|| 20/20 [00:06&lt;00:00,  3.11it/s, v_num=1, train_loss_step=5.75e+3, train_loss_epoch=5.12e+3]Epoch 20/20: 100%|| 20/20 [00:06&lt;00:00,  3.15it/s, v_num=1, train_loss_step=5.75e+3, train_loss_epoch=5.12e+3]\n\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1,2]\n`Trainer.fit` stopped: `max_epochs=20` reached.\n\n\n\ny_test = lvae.adata.obs.ct.values\ny_pred = lvae.predict()\n\nstats.append(prediction_stats(\"scANVI_ns15\", None, y_test, y_pred, None, None))"
  },
  {
    "objectID": "notebooks/05_mouse_classifier.html#xgboost",
    "href": "notebooks/05_mouse_classifier.html#xgboost",
    "title": "05 - mouse classifier",
    "section": "3 3. XGBoost",
    "text": "3 3. XGBoost\n\n3.1 3.1. scVI\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi/\")\n\nINFO     File ../results/02_mouse_integration/scvi/model.pt already downloaded                                     \n\n\n\nvae_df = pd.DataFrame(vae.get_normalized_expression(return_mean=True))\nvae_df['target'] = vae.adata.obs.ct\nvae_df.head()\n\n\n\n\n\n\n\n\nsox17\nppp1r42\narfgef1\nprdm14\nxkr9\nmsc\nube2w\ngm7654\ntmem70\nly96\n...\nstn1\ngsto1\n1700054a03rik\ngm50273\nhabp2\nccdc186\nafap1l2\npnlip\npnliprp2\ntarget\n\n\n\n\nSRX259148\n9.244410e-09\n1.495744e-07\n0.000106\n0.000002\n0.000030\n2.020811e-04\n0.000375\n1.544236e-09\n0.000513\n0.000280\n...\n0.000278\n0.004330\n7.987154e-08\n3.248621e-10\n5.573803e-09\n0.000101\n5.110550e-08\n1.434869e-09\n4.117884e-05\n16C\n\n\nSRX259191\n2.290104e-07\n2.459044e-09\n0.000065\n0.000006\n0.000080\n4.674523e-05\n0.000086\n4.516714e-07\n0.000462\n0.000328\n...\n0.000394\n0.001819\n6.749668e-11\n1.539256e-09\n6.671179e-09\n0.000118\n2.692376e-07\n8.009134e-07\n9.071199e-05\n8C\n\n\nSRX259121\n9.530742e-11\n1.176371e-06\n0.000106\n0.000005\n0.000014\n4.688524e-04\n0.000103\n7.302969e-12\n0.000299\n0.000452\n...\n0.000032\n0.001475\n1.854037e-07\n1.135729e-09\n1.288587e-10\n0.000048\n1.281698e-08\n7.423926e-10\n6.965978e-06\n16C\n\n\nSRX259140\n2.935074e-08\n1.263999e-08\n0.000069\n0.000011\n0.000058\n8.229597e-05\n0.000256\n1.905268e-08\n0.000314\n0.000802\n...\n0.000497\n0.003291\n1.695690e-09\n4.987342e-10\n1.461652e-08\n0.000127\n1.668044e-07\n5.001769e-08\n9.694348e-05\n16C\n\n\nSRX259161\n4.501800e-08\n3.915447e-09\n0.000240\n0.000057\n0.000007\n3.080844e-07\n0.000202\n1.228954e-06\n0.000794\n0.000154\n...\n0.000211\n0.000063\n4.561012e-12\n9.231247e-08\n3.405940e-10\n0.000431\n3.755741e-05\n2.560960e-06\n7.125635e-07\n4C\n\n\n\n\n5 rows  3001 columns\n\n\n\n\nX_train, y_train, X_test, y_test = train_test_split_by_group(vae_df)\n\n\nvae_xgboost = train_xgboost(vae_df, X_train, y_train, X_test, y_test)\n\n[0] validation_0-merror:0.03004 validation_0-mlogloss:1.09462   validation_1-merror:0.08128 validation_1-mlogloss:1.19250\n[1] validation_0-merror:0.01877 validation_0-mlogloss:0.77131   validation_1-merror:0.05419 validation_1-mlogloss:0.88954\n[2] validation_0-merror:0.01690 validation_0-mlogloss:0.56525   validation_1-merror:0.05172 validation_1-mlogloss:0.69790\n[3] validation_0-merror:0.01189 validation_0-mlogloss:0.42255   validation_1-merror:0.04433 validation_1-mlogloss:0.56222\n[4] validation_0-merror:0.00876 validation_0-mlogloss:0.32044   validation_1-merror:0.04680 validation_1-mlogloss:0.46083\n[5] validation_0-merror:0.00626 validation_0-mlogloss:0.24549   validation_1-merror:0.04926 validation_1-mlogloss:0.38825\n[6] validation_0-merror:0.00438 validation_0-mlogloss:0.18819   validation_1-merror:0.04926 validation_1-mlogloss:0.33157\n[7] validation_0-merror:0.00375 validation_0-mlogloss:0.14573   validation_1-merror:0.04926 validation_1-mlogloss:0.29007\n[8] validation_0-merror:0.00188 validation_0-mlogloss:0.11385   validation_1-merror:0.04926 validation_1-mlogloss:0.25384\n[9] validation_0-merror:0.00125 validation_0-mlogloss:0.08912   validation_1-merror:0.05172 validation_1-mlogloss:0.22724\n[10]    validation_0-merror:0.00125 validation_0-mlogloss:0.07097   validation_1-merror:0.04926 validation_1-mlogloss:0.20505\n[11]    validation_0-merror:0.00000 validation_0-mlogloss:0.05642   validation_1-merror:0.04433 validation_1-mlogloss:0.18941\n[12]    validation_0-merror:0.00000 validation_0-mlogloss:0.04556   validation_1-merror:0.04187 validation_1-mlogloss:0.17663\n[13]    validation_0-merror:0.00000 validation_0-mlogloss:0.03727   validation_1-merror:0.04187 validation_1-mlogloss:0.16720\n[14]    validation_0-merror:0.00000 validation_0-mlogloss:0.03082   validation_1-merror:0.04187 validation_1-mlogloss:0.16092\n[15]    validation_0-merror:0.00000 validation_0-mlogloss:0.02581   validation_1-merror:0.03941 validation_1-mlogloss:0.15553\n[16]    validation_0-merror:0.00000 validation_0-mlogloss:0.02199   validation_1-merror:0.03941 validation_1-mlogloss:0.14887\n[17]    validation_0-merror:0.00000 validation_0-mlogloss:0.01899   validation_1-merror:0.03941 validation_1-mlogloss:0.14508\n[18]    validation_0-merror:0.00000 validation_0-mlogloss:0.01656   validation_1-merror:0.03941 validation_1-mlogloss:0.14449\n[19]    validation_0-merror:0.00000 validation_0-mlogloss:0.01463   validation_1-merror:0.03941 validation_1-mlogloss:0.14215\n[20]    validation_0-merror:0.00000 validation_0-mlogloss:0.01305   validation_1-merror:0.03695 validation_1-mlogloss:0.14105\n[21]    validation_0-merror:0.00000 validation_0-mlogloss:0.01174   validation_1-merror:0.03941 validation_1-mlogloss:0.14084\n[22]    validation_0-merror:0.00000 validation_0-mlogloss:0.01067   validation_1-merror:0.03941 validation_1-mlogloss:0.14050\n[23]    validation_0-merror:0.00000 validation_0-mlogloss:0.00981   validation_1-merror:0.03941 validation_1-mlogloss:0.14013\n[24]    validation_0-merror:0.00000 validation_0-mlogloss:0.00909   validation_1-merror:0.03941 validation_1-mlogloss:0.14064\n[25]    validation_0-merror:0.00000 validation_0-mlogloss:0.00851   validation_1-merror:0.03941 validation_1-mlogloss:0.14045\n[26]    validation_0-merror:0.00000 validation_0-mlogloss:0.00804   validation_1-merror:0.03941 validation_1-mlogloss:0.14129\n[27]    validation_0-merror:0.00000 validation_0-mlogloss:0.00768   validation_1-merror:0.03941 validation_1-mlogloss:0.14126\n[28]    validation_0-merror:0.00000 validation_0-mlogloss:0.00735   validation_1-merror:0.03941 validation_1-mlogloss:0.14149\n[29]    validation_0-merror:0.00000 validation_0-mlogloss:0.00707   validation_1-merror:0.03941 validation_1-mlogloss:0.14218\n[30]    validation_0-merror:0.00000 validation_0-mlogloss:0.00686   validation_1-merror:0.03941 validation_1-mlogloss:0.14375\n[31]    validation_0-merror:0.00000 validation_0-mlogloss:0.00665   validation_1-merror:0.03941 validation_1-mlogloss:0.14360\n[32]    validation_0-merror:0.00000 validation_0-mlogloss:0.00648   validation_1-merror:0.03941 validation_1-mlogloss:0.14413\n\n\n\n\n\n\ny_pred = vae_xgboost.predict(X_test)\n\n\nstats.append(prediction_stats(\"XGB_scVI\", vae_xgboost, y_test, y_pred, vae_df.values[:, :-1], vae_df['target'].cat.codes.to_numpy()))\n\n\nvae_xgboost.save_model(\"../results/02_mouse_integration/05_scVI_xgboost.json\")\n\n\n\n3.2 3.2. scANVI\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\n\nINFO     File ../results/02_mouse_integration/scanvi/model.pt already downloaded                                   \n\n\n\nlvae_df = pd.DataFrame(lvae.get_normalized_expression(return_mean=True))\nlvae_df['target'] = lvae.adata.obs.ct\nlvae_df.head()\n\n\n\n\n\n\n\n\nsox17\nppp1r42\narfgef1\nprdm14\nxkr9\nmsc\nube2w\ngm7654\ntmem70\nly96\n...\nstn1\ngsto1\n1700054a03rik\ngm50273\nhabp2\nccdc186\nafap1l2\npnlip\npnliprp2\ntarget\n\n\n\n\nSRX259148\n1.499321e-08\n7.591232e-08\n0.000068\n0.000003\n0.000065\n0.000326\n0.000131\n1.483101e-08\n0.000298\n0.000150\n...\n0.000185\n0.005562\n8.425851e-07\n4.370481e-09\n1.569241e-09\n0.000072\n4.824862e-08\n1.690867e-09\n0.000051\n16C\n\n\nSRX259191\n1.535953e-07\n3.323944e-08\n0.000084\n0.000012\n0.000095\n0.000061\n0.000062\n1.126642e-06\n0.000531\n0.000390\n...\n0.000336\n0.002567\n1.206273e-08\n3.697671e-08\n8.405232e-09\n0.000134\n1.122398e-06\n5.098362e-07\n0.000258\n8C\n\n\nSRX259121\n2.234061e-10\n1.818486e-07\n0.000059\n0.000002\n0.000023\n0.000644\n0.000123\n3.998329e-11\n0.000119\n0.000196\n...\n0.000069\n0.001645\n4.700184e-07\n2.258681e-09\n1.102188e-10\n0.000037\n5.974784e-09\n1.568855e-09\n0.000009\n16C\n\n\nSRX259140\n8.150251e-08\n4.920110e-08\n0.000055\n0.000010\n0.000060\n0.000158\n0.000128\n1.852338e-07\n0.000286\n0.000275\n...\n0.000263\n0.004427\n1.616031e-07\n1.186041e-08\n5.657514e-09\n0.000073\n3.052841e-07\n3.905111e-08\n0.000125\n16C\n\n\nSRX259161\n2.039545e-07\n1.044988e-07\n0.000329\n0.000031\n0.000166\n0.000001\n0.000171\n3.242764e-05\n0.000807\n0.000285\n...\n0.000279\n0.000124\n4.134634e-10\n1.175266e-07\n7.103967e-09\n0.000540\n9.310104e-05\n2.019131e-06\n0.000002\n4C\n\n\n\n\n5 rows  3001 columns\n\n\n\n\nX_train, y_train, X_test, y_test = train_test_split_by_group(lvae_df)\n\n\nlvae_xgboost = train_xgboost(lvae_df, X_train, y_train, X_test, y_test)\n\n[0] validation_0-merror:0.03504 validation_0-mlogloss:1.11435   validation_1-merror:0.16502 validation_1-mlogloss:1.35171\n[1] validation_0-merror:0.02566 validation_0-mlogloss:0.78891   validation_1-merror:0.12315 validation_1-mlogloss:1.04526\n[2] validation_0-merror:0.01815 validation_0-mlogloss:0.58309   validation_1-merror:0.11084 validation_1-mlogloss:0.85486\n[3] validation_0-merror:0.01314 validation_0-mlogloss:0.43796   validation_1-merror:0.09852 validation_1-mlogloss:0.72215\n[4] validation_0-merror:0.01064 validation_0-mlogloss:0.33298   validation_1-merror:0.10099 validation_1-mlogloss:0.62165\n[5] validation_0-merror:0.00688 validation_0-mlogloss:0.25603   validation_1-merror:0.09852 validation_1-mlogloss:0.54944\n[6] validation_0-merror:0.00501 validation_0-mlogloss:0.19739   validation_1-merror:0.09606 validation_1-mlogloss:0.49209\n[7] validation_0-merror:0.00250 validation_0-mlogloss:0.15305   validation_1-merror:0.09852 validation_1-mlogloss:0.44675\n[8] validation_0-merror:0.00250 validation_0-mlogloss:0.12090   validation_1-merror:0.09606 validation_1-mlogloss:0.41005\n[9] validation_0-merror:0.00188 validation_0-mlogloss:0.09542   validation_1-merror:0.09852 validation_1-mlogloss:0.38280\n[10]    validation_0-merror:0.00125 validation_0-mlogloss:0.07578   validation_1-merror:0.10099 validation_1-mlogloss:0.36633\n[11]    validation_0-merror:0.00000 validation_0-mlogloss:0.06099   validation_1-merror:0.10099 validation_1-mlogloss:0.35114\n[12]    validation_0-merror:0.00000 validation_0-mlogloss:0.04939   validation_1-merror:0.09852 validation_1-mlogloss:0.34063\n[13]    validation_0-merror:0.00000 validation_0-mlogloss:0.04041   validation_1-merror:0.10345 validation_1-mlogloss:0.33141\n[14]    validation_0-merror:0.00000 validation_0-mlogloss:0.03370   validation_1-merror:0.10099 validation_1-mlogloss:0.32415\n[15]    validation_0-merror:0.00000 validation_0-mlogloss:0.02832   validation_1-merror:0.10099 validation_1-mlogloss:0.31757\n[16]    validation_0-merror:0.00000 validation_0-mlogloss:0.02422   validation_1-merror:0.09852 validation_1-mlogloss:0.30989\n[17]    validation_0-merror:0.00000 validation_0-mlogloss:0.02089   validation_1-merror:0.09852 validation_1-mlogloss:0.30725\n[18]    validation_0-merror:0.00000 validation_0-mlogloss:0.01818   validation_1-merror:0.10099 validation_1-mlogloss:0.30426\n[19]    validation_0-merror:0.00000 validation_0-mlogloss:0.01608   validation_1-merror:0.09852 validation_1-mlogloss:0.30231\n[20]    validation_0-merror:0.00000 validation_0-mlogloss:0.01431   validation_1-merror:0.09852 validation_1-mlogloss:0.29995\n[21]    validation_0-merror:0.00000 validation_0-mlogloss:0.01292   validation_1-merror:0.09606 validation_1-mlogloss:0.29890\n[22]    validation_0-merror:0.00000 validation_0-mlogloss:0.01174   validation_1-merror:0.09852 validation_1-mlogloss:0.29805\n[23]    validation_0-merror:0.00000 validation_0-mlogloss:0.01074   validation_1-merror:0.09606 validation_1-mlogloss:0.29816\n[24]    validation_0-merror:0.00000 validation_0-mlogloss:0.00989   validation_1-merror:0.09606 validation_1-mlogloss:0.29815\n[25]    validation_0-merror:0.00000 validation_0-mlogloss:0.00927   validation_1-merror:0.09852 validation_1-mlogloss:0.29669\n[26]    validation_0-merror:0.00000 validation_0-mlogloss:0.00875   validation_1-merror:0.09852 validation_1-mlogloss:0.29431\n[27]    validation_0-merror:0.00000 validation_0-mlogloss:0.00831   validation_1-merror:0.09852 validation_1-mlogloss:0.29328\n[28]    validation_0-merror:0.00000 validation_0-mlogloss:0.00794   validation_1-merror:0.10099 validation_1-mlogloss:0.29464\n[29]    validation_0-merror:0.00000 validation_0-mlogloss:0.00760   validation_1-merror:0.09852 validation_1-mlogloss:0.29632\n[30]    validation_0-merror:0.00000 validation_0-mlogloss:0.00732   validation_1-merror:0.09852 validation_1-mlogloss:0.29805\n[31]    validation_0-merror:0.00000 validation_0-mlogloss:0.00708   validation_1-merror:0.10099 validation_1-mlogloss:0.29762\n[32]    validation_0-merror:0.00000 validation_0-mlogloss:0.00684   validation_1-merror:0.10099 validation_1-mlogloss:0.29781\n[33]    validation_0-merror:0.00000 validation_0-mlogloss:0.00666   validation_1-merror:0.10099 validation_1-mlogloss:0.29910\n[34]    validation_0-merror:0.00000 validation_0-mlogloss:0.00649   validation_1-merror:0.10099 validation_1-mlogloss:0.29847\n[35]    validation_0-merror:0.00000 validation_0-mlogloss:0.00634   validation_1-merror:0.10099 validation_1-mlogloss:0.29821\n[36]    validation_0-merror:0.00000 validation_0-mlogloss:0.00619   validation_1-merror:0.10099 validation_1-mlogloss:0.29706\n\n\n\n\n\n\ny_pred = lvae_xgboost.predict(X_test)\n\n\nstats.append(prediction_stats(\"XGB_scANVI\", lvae_xgboost, y_test, y_pred, lvae_df.values[:, :-1], lvae_df['target'].cat.codes.to_numpy()))\n\n\nlvae_xgboost.save_model(\"../results/02_mouse_integration/05_scANVI_xgboost.json\")\n\n\n\n3.3 3.3. scGEN\n\nmscgen = scgen.SCGEN.load(\"../results/02_mouse_integration/scgen/\")\n\nINFO     File ../results/02_mouse_integration/scgen/model.pt already downloaded                                    \n\n\n\nmscgen_df = pd.DataFrame(mscgen.get_decoded_expression(), \n                         index=mscgen.adata.obs_names, columns=mscgen.adata.var_names)\nmscgen_df['target'] = mscgen.adata.obs['ct']\nmscgen_df.head()\n\n\n\n\n\n\n\n\nsox17\nppp1r42\narfgef1\nprdm14\nxkr9\nmsc\nube2w\ngm7654\ntmem70\nly96\n...\nstn1\ngsto1\n1700054a03rik\ngm50273\nhabp2\nccdc186\nafap1l2\npnlip\npnliprp2\ntarget\n\n\n\n\nSRX259148\n0.129524\n-0.009126\n0.580587\n-0.027672\n0.165227\n0.593042\n0.868470\n-0.005957\n1.724664\n1.235015\n...\n1.047719\n3.994854\n0.026034\n0.019212\n-0.022841\n0.752102\n0.036959\n0.001139\n0.642708\n16C\n\n\nSRX259191\n0.042759\n-0.009889\n0.608965\n0.035671\n0.257579\n0.512698\n0.708813\n-0.007634\n1.550365\n1.364577\n...\n1.072520\n3.394770\n0.016012\n0.020248\n-0.048329\n0.858443\n0.036058\n0.028643\n0.485618\n8C\n\n\nSRX259121\n-0.062429\n-0.002099\n0.516726\n-0.141183\n0.291033\n0.251529\n0.438559\n-0.008837\n1.417975\n1.416850\n...\n0.471408\n2.301015\n0.038988\n0.019344\n0.005064\n0.552338\n-0.009445\n-0.026622\n0.361133\n16C\n\n\nSRX259140\n-0.067408\n-0.014072\n0.476634\n0.038267\n0.143380\n0.544186\n0.797441\n-0.009345\n1.724418\n1.436977\n...\n0.957134\n3.538107\n0.023010\n0.025978\n-0.022783\n0.754117\n0.064578\n0.004726\n0.577420\n16C\n\n\nSRX259161\n0.009253\n0.033485\n1.305035\n0.533173\n-0.025159\n0.184909\n1.239522\n0.022633\n2.215558\n1.189655\n...\n1.302740\n1.088298\n0.003135\n0.037767\n0.004102\n1.716617\n0.146538\n0.081518\n0.166842\n4C\n\n\n\n\n5 rows  3001 columns\n\n\n\n\nX_train, y_train, X_test, y_test = train_test_split_by_group(mscgen_df)\n\n\nmscgen_xgboost = train_xgboost(mscgen_df, X_train, y_train, X_test, y_test)\n\n[0] validation_0-merror:0.02753 validation_0-mlogloss:1.10220   validation_1-merror:0.07882 validation_1-mlogloss:1.17242\n[1] validation_0-merror:0.01815 validation_0-mlogloss:0.77531   validation_1-merror:0.07389 validation_1-mlogloss:0.88407\n[2] validation_0-merror:0.01252 validation_0-mlogloss:0.56490   validation_1-merror:0.06650 validation_1-mlogloss:0.69409\n[3] validation_0-merror:0.00876 validation_0-mlogloss:0.42008   validation_1-merror:0.06404 validation_1-mlogloss:0.56456\n[4] validation_0-merror:0.00688 validation_0-mlogloss:0.31672   validation_1-merror:0.06158 validation_1-mlogloss:0.46782\n[5] validation_0-merror:0.00501 validation_0-mlogloss:0.24033   validation_1-merror:0.06158 validation_1-mlogloss:0.40182\n[6] validation_0-merror:0.00375 validation_0-mlogloss:0.18417   validation_1-merror:0.06404 validation_1-mlogloss:0.35392\n[7] validation_0-merror:0.00125 validation_0-mlogloss:0.14143   validation_1-merror:0.06158 validation_1-mlogloss:0.31127\n[8] validation_0-merror:0.00063 validation_0-mlogloss:0.10950   validation_1-merror:0.05911 validation_1-mlogloss:0.28430\n[9] validation_0-merror:0.00063 validation_0-mlogloss:0.08584   validation_1-merror:0.05419 validation_1-mlogloss:0.26294\n[10]    validation_0-merror:0.00000 validation_0-mlogloss:0.06750   validation_1-merror:0.05419 validation_1-mlogloss:0.24574\n[11]    validation_0-merror:0.00000 validation_0-mlogloss:0.05349   validation_1-merror:0.05419 validation_1-mlogloss:0.23149\n[12]    validation_0-merror:0.00000 validation_0-mlogloss:0.04296   validation_1-merror:0.05172 validation_1-mlogloss:0.22194\n[13]    validation_0-merror:0.00000 validation_0-mlogloss:0.03500   validation_1-merror:0.05419 validation_1-mlogloss:0.21303\n[14]    validation_0-merror:0.00000 validation_0-mlogloss:0.02891   validation_1-merror:0.05172 validation_1-mlogloss:0.20760\n[15]    validation_0-merror:0.00000 validation_0-mlogloss:0.02419   validation_1-merror:0.05172 validation_1-mlogloss:0.20254\n[16]    validation_0-merror:0.00000 validation_0-mlogloss:0.02050   validation_1-merror:0.05419 validation_1-mlogloss:0.20035\n[17]    validation_0-merror:0.00000 validation_0-mlogloss:0.01761   validation_1-merror:0.05419 validation_1-mlogloss:0.19680\n[18]    validation_0-merror:0.00000 validation_0-mlogloss:0.01529   validation_1-merror:0.05419 validation_1-mlogloss:0.19592\n[19]    validation_0-merror:0.00000 validation_0-mlogloss:0.01347   validation_1-merror:0.05419 validation_1-mlogloss:0.19497\n[20]    validation_0-merror:0.00000 validation_0-mlogloss:0.01202   validation_1-merror:0.05419 validation_1-mlogloss:0.19207\n[21]    validation_0-merror:0.00000 validation_0-mlogloss:0.01080   validation_1-merror:0.05419 validation_1-mlogloss:0.19109\n[22]    validation_0-merror:0.00000 validation_0-mlogloss:0.00985   validation_1-merror:0.05419 validation_1-mlogloss:0.19257\n[23]    validation_0-merror:0.00000 validation_0-mlogloss:0.00908   validation_1-merror:0.05419 validation_1-mlogloss:0.19313\n[24]    validation_0-merror:0.00000 validation_0-mlogloss:0.00847   validation_1-merror:0.05419 validation_1-mlogloss:0.19265\n[25]    validation_0-merror:0.00000 validation_0-mlogloss:0.00794   validation_1-merror:0.05419 validation_1-mlogloss:0.19297\n[26]    validation_0-merror:0.00000 validation_0-mlogloss:0.00753   validation_1-merror:0.05419 validation_1-mlogloss:0.19289\n[27]    validation_0-merror:0.00000 validation_0-mlogloss:0.00718   validation_1-merror:0.05419 validation_1-mlogloss:0.19182\n[28]    validation_0-merror:0.00000 validation_0-mlogloss:0.00689   validation_1-merror:0.05419 validation_1-mlogloss:0.19347\n[29]    validation_0-merror:0.00000 validation_0-mlogloss:0.00664   validation_1-merror:0.05419 validation_1-mlogloss:0.19384\n[30]    validation_0-merror:0.00000 validation_0-mlogloss:0.00646   validation_1-merror:0.05419 validation_1-mlogloss:0.19353\n\n\n\n\n\n\nstats.append(prediction_stats(\"XGB_scGEN\", mscgen_xgboost, y_test, y_pred, mscgen_df.values[:, :-1], mscgen_df['target'].cat.codes.to_numpy()))\n\n\nmscgen_xgboost.save_model(\"../results/02_mouse_integration/05_scGEN_xgboost.json\")"
  },
  {
    "objectID": "notebooks/05_mouse_classifier.html#summary",
    "href": "notebooks/05_mouse_classifier.html#summary",
    "title": "05 - mouse classifier",
    "section": "4 4. Summary",
    "text": "4 4. Summary\n\nstats_df = pd.DataFrame(stats, columns=['method', 'accuracy', 'balanced_accuracy', 'f1_micro', 'f1_macro', 'cv_accuracy']).set_index('method')\nstats_df.to_csv(\"../results/05_mouse_classifier_stats.csv\")\n\nstats_df\n\n\n\n\n\n\n\n\naccuracy\nbalanced_accuracy\nf1_micro\nf1_macro\ncv_accuracy\n\n\nmethod\n\n\n\n\n\n\n\n\n\nscANVI\n0.830339\n0.649818\n0.830339\n0.634290\nNaN\n\n\nscANVI_ns15\n0.793413\n0.879503\n0.793413\n0.777624\nNaN\n\n\nXGB_scVI\n0.960591\n0.963041\n0.960591\n0.967656\n0.935637\n\n\nXGB_scANVI\n0.901478\n0.917235\n0.901478\n0.923392\n0.920664\n\n\nXGB_scGEN\n0.901478\n0.917235\n0.901478\n0.923392\n0.942602\n\n\n\n\n\n\n\n\nstats_df.plot(kind='bar')\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(title='Metrics', bbox_to_anchor=(0.99, 1.02), loc='upper left')\n\n&lt;matplotlib.legend.Legend at 0x7f01bfb91390&gt;"
  },
  {
    "objectID": "notebooks/05_mouse_classifier_accuracy.html",
    "href": "notebooks/05_mouse_classifier_accuracy.html",
    "title": "05 - mouse classifier accuracy",
    "section": "",
    "text": "Measure classifier accuracies\n!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\n%matplotlib inline\n\nimport scvi\nimport squarify\nimport scgen\nimport scanpy as sc\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom typing import Tuple\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n\nfrom numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\nimport warnings\n\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\nscvi.settings.seed = 0\n\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n[rank: 0] Global seed set to 0\n# %run ../scripts/helpers.py\nmouse_ct_colors = {\n    'Zygote': '#7985A5',\n    '2C': '#B3C81E',\n    '4C': '#67BB30',\n    '8C': '#028A46',\n    '16C': '#657cbd',\n    'E3.25-ICM': '#fadc8f',\n    'E3.25-TE': '#5185b9',\n    'E3.5-ICM': '#f8d06a',\n    'E3.5-TE': '#7ba9d8',\n    'E3.5-EPI': '#c38cb0',\n    'E3.5-PrE': '#d97c81',\n    'E3.75-ICM': '#F6C445',\n    'E4.5-TE': '#5a94ce',\n    'E4.5-EPI': '#B46F9C',\n    'E4.5-PrE': '#D05B61'\n}"
  },
  {
    "objectID": "notebooks/05_mouse_classifier_accuracy.html#overall-accuracy",
    "href": "notebooks/05_mouse_classifier_accuracy.html#overall-accuracy",
    "title": "05 - mouse classifier accuracy",
    "section": "1 Overall accuracy",
    "text": "1 Overall accuracy\n\nimport scgen\nimport squarify\nimport xgboost as xgb\nimport matplotlib.cm as cm\n\n\nfrom matplotlib.colors import Normalize\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n\n\nmouse = sc.read(\"../results/03_mouse.processed.h5ad\")\nmouse.obs.stage = mouse.obs.stage.astype('category').cat.reorder_categories(['Zygote', '2C', '4C', '8C', '16C', 'ICM', 'TE', 'EPI', 'PrE'])\n\n\nmouse.obs.ct.value_counts()\n\nE3.5-ICM     459\nE3.5-PrE     254\nE4.5-PrE     207\n16C          198\nE3.5-EPI     175\n8C           115\n4C           114\nE4.5-EPI     108\nE3.5-TE      107\n2C            86\nE3.75-ICM     48\nE3.25-TE      47\nE3.25-ICM     40\nE4.5-TE       28\nZygote        18\nName: ct, dtype: int64\n\n\n\nCLFS_ORDER = ['xg_scVI', 'xg_scANVI', 'xg_scGEN', 'scANVI', 'scANVI_ns15']\n\n\npredictions = mouse.obs[['ct']].copy()\nxg_clf = xgb.XGBClassifier()\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\npredictions['scANVI'] = lvae.predict()\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\")\npredictions['scANVI_ns15'] = lvae.predict()\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi/\")\nxg_clf.load_model(\"../results/05_scVI_xgboost.json\")\npredictions['xg_scVI'] = predictions.ct.cat.categories[xg_clf.predict(vae.get_normalized_expression(return_mean=True, return_numpy=True))]\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\nxg_clf.load_model(\"../results/05_scANVI_xgboost.json\")\npredictions['xg_scANVI'] = predictions.ct.cat.categories[xg_clf.predict(lvae.get_normalized_expression(return_mean=True, return_numpy=True))]\n\nmscgen = scgen.SCGEN.load(\"../results/02_mouse_integration/scgen/\")\nxg_clf.load_model(\"../results/05_scGEN_xgboost.json\")\npredictions['xg_scGEN'] = predictions.ct.cat.categories[xg_clf.predict(mscgen.get_decoded_expression())]\n\nINFO     File ../results/02_mouse_integration/scanvi/model.pt already downloaded                                   \nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded                             \nINFO     File ../results/02_mouse_integration/scvi/model.pt already downloaded                                     \nINFO     File ../results/02_mouse_integration/scanvi/model.pt already downloaded                                   \nINFO     File ../results/02_mouse_integration/scgen/model.pt already downloaded                                    \n\n\n\nmouse_accuracy = pd.DataFrame([\n    [\n        accuracy_score(predictions.ct.tolist(), predictions[clf].tolist()), \n        balanced_accuracy_score(predictions.ct.tolist(), predictions[clf].tolist()),\n        f1_score(predictions.ct.tolist(), predictions[clf].tolist(), average=\"micro\"),\n        f1_score(predictions.ct.tolist(), predictions[clf].tolist(), average=\"macro\")\n    ] for clf in predictions.columns[1:]\n], index=predictions.columns[1:], columns=['Accuracy', 'Bal. Accuracy', 'F1 (micro)', 'F1 (macro)'])\n\nmouse_accuracy.loc[CLFS_ORDER]\n\n\n\n\n\n\n\n\nAccuracy\nBal. Accuracy\nF1 (micro)\nF1 (macro)\n\n\n\n\nxg_scVI\n0.955090\n0.969146\n0.955090\n0.970610\n\n\nxg_scANVI\n0.944611\n0.959064\n0.944611\n0.961897\n\n\nxg_scGEN\n0.984531\n0.988347\n0.984531\n0.988487\n\n\nscANVI\n0.830339\n0.649818\n0.830339\n0.634290\n\n\nscANVI_ns15\n0.793413\n0.879503\n0.793413\n0.777624\n\n\n\n\n\n\n\n\nmouse_accuracy.loc[CLFS_ORDER[::-1]].plot(kind='barh')\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(title='Metrics', bbox_to_anchor=(0.99, 1.02), loc='upper left')\n\n&lt;matplotlib.legend.Legend at 0x7fd1db6a5b40&gt;\n\n\n\n\n\n\nicm_accuracy = (sc.metrics.confusion_matrix('ct', 'scANVI_ns15', data=predictions).loc['E3.5-ICM'] * 100).round()\nicm_accuracy = icm_accuracy[icm_accuracy != 0].sort_values()\n\nfig = plt.figure(figsize=[4.5,4.5])\nax = fig.add_subplot(111)\nsquarify.plot(sizes=icm_accuracy, \n              label=icm_accuracy.index + '\\n(' + icm_accuracy.values.astype(str) + ')%', \n              color=[mouse_ct_colors[ct] for ct in icm_accuracy.index],\n              text_kwargs={'fontsize': '10'}, ax=ax\n             )\n_ = plt.axis(\"off\")\nplt.title('ICM prediction composition')\nfig.savefig(\"../figures/mouse/05_ICM_prediction_zoom.svg\")\n\n\nmouse_subset = mouse[predictions[(predictions.ct == \"E3.5-ICM\") & (predictions.scANVI_ns15.isin(icm_accuracy.index))].index].copy()\nmouse_subset.obs['scANVI_ns15'] = predictions.loc[mouse_subset.obs_names, 'scANVI_ns15']\nsc.pl.dotplot(mouse_subset, ['gata6', 'nanog', 'sox2', 'pou5f1', 'cdx2', 'pdgfra'], groupby='scANVI_ns15', use_raw=True, standard_scale='var')\n\n\nfig, ax = plt.subplots(1, 5, figsize=[20, 6], sharey=True, sharex=False)\nfor idx, clf in enumerate(CLFS_ORDER):\n    conf_df = pd.DataFrame(0, index=predictions.ct.cat.categories, columns=predictions.ct.cat.categories) + sc.metrics.confusion_matrix('ct', clf, data=predictions)\n    conf_df = conf_df.fillna(0)[predictions.ct.cat.categories]\n    sns.heatmap(conf_df, linewidths=0.2, cmap='viridis', ax=ax[idx], square=True, cbar=None)\n    ax[idx].set_title(clf)\n    ax[idx].set_xticklabels(predictions.ct.cat.categories.tolist(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\nfig.colorbar(cm.ScalarMappable(norm=Normalize(0,1), cmap='viridis'), ax=ax.ravel(), fraction=0.048)\nfig.supxlabel('Predicted')\nfig.supylabel('Observed')\nfig.tight_layout()\nfig.savefig(\"../figures/mouse/05_clf_confusion_mat.svg\")"
  },
  {
    "objectID": "notebooks/05_mouse_classifier_accuracy.html#suppl.-table-2",
    "href": "notebooks/05_mouse_classifier_accuracy.html#suppl.-table-2",
    "title": "05 - mouse classifier accuracy",
    "section": "2 Suppl. Table 2",
    "text": "2 Suppl. Table 2\n\nwriter = pd.ExcelWriter(\"../results/suppl-tab-2.xlsx\", engine=\"xlsxwriter\")\n\npd.read_csv(\"../results/05_mouse_classifier_stats.csv\", index_col=0).to_excel(writer, sheet_name=\"mouse_overall\")\nfor clf in mouse_accuracy.index:\n    df = pd.DataFrame(0, index=predictions.ct.cat.categories, columns=predictions.ct.cat.categories) + sc.metrics.confusion_matrix('ct', clf, data=predictions)\n    df = df.fillna(0)[predictions.ct.cat.categories]\n    df.to_excel(writer, sheet_name=f\"mouse_{clf}\")\nwriter.close()"
  },
  {
    "objectID": "notebooks/06_human_query_Rivron_SRR.html",
    "href": "notebooks/06_human_query_Rivron_SRR.html",
    "title": "Rivron blastoids cleaning",
    "section": "",
    "text": "%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport scvi\nimport scanpy as sc\nimport scanpy.external as sce\nimport scFates as scf\nimport matplotlib.pyplot as plt\n\nimport warnings\nfrom numba.core.errors import NumbaDeprecationWarning\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\nsc.set_figure_params(figsize=(10, 6))\n\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n%config InlineBackend.figure_format='retina'"
  },
  {
    "objectID": "notebooks/06_human_query_Rivron_SRR.html#rivron-dataset-srr-filtering",
    "href": "notebooks/06_human_query_Rivron_SRR.html#rivron-dataset-srr-filtering",
    "title": "Rivron blastoids cleaning",
    "section": "1 Rivron dataset SRR filtering",
    "text": "1 Rivron dataset SRR filtering\n\nkagawa_samplesheet = pd.read_csv('../data/external/kagawa_samplesheet.csv')\n\n\nkagawa_exclude = pd.read_csv('../data/external/kagawa_exclude.txt', header=None)\n\n\nkagawa_include = pd.read_csv('../data/external/kagawa_include.txt', header=None)\n\n\nnew_kagawa_samplesheet = kagawa_samplesheet.loc[kagawa_samplesheet['sample'].isin(kagawa_include[0])].copy()\n\n\nnew_kagawa_samplesheet.to_csv('../data/external/kagawa_samplesheet_filtered.csv',\n                              index=None,\n                             quoting=csv.QUOTE_NONNUMERIC)"
  },
  {
    "objectID": "notebooks/06_human_query_Rivron_SRR.html#fetch-ngs",
    "href": "notebooks/06_human_query_Rivron_SRR.html#fetch-ngs",
    "title": "Rivron blastoids cleaning",
    "section": "2 fetch-ngs",
    "text": "2 fetch-ngs\n~/Brickman/helper-scripts/nf-core_tower.sh Kagawa_2022 nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.human.config \\\n    --input /scratch/Brickman/pipelines/Kagawa_2022/results/samplesheet/samplesheet_filtered.csv"
  },
  {
    "objectID": "notebooks/06_human_query_Rivron_SRR.html#rivron-dataset-preprocessing",
    "href": "notebooks/06_human_query_Rivron_SRR.html#rivron-dataset-preprocessing",
    "title": "Rivron blastoids cleaning",
    "section": "3 Rivron dataset preprocessing",
    "text": "3 Rivron dataset preprocessing\n\nadata_rivron = sc.read('../data/external/aligned/human/rivron_2022_reprocessed.h5ad')\n\n\nadata_rivron\n\nAnnData object with n_obs  n_vars = 2673  62754\n    obs: 'sample', 'fastq_1', 'fastq_2', 'run_accession', 'experiment_accession', 'sample_accession', 'secondary_sample_accession', 'study_accession', 'secondary_study_accession', 'submission_accession', 'run_alias', 'experiment_alias', 'sample_alias', 'study_alias', 'library_layout', 'library_selection', 'library_source', 'library_strategy', 'instrument_model', 'instrument_platform', 'scientific_name', 'sample_title', 'experiment_title', 'study_title', 'sample_description', 'fastq_md5', 'fastq_bytes', 'fastq_ftp', 'fastq_galaxy', 'fastq_aspera'\n    var: 'gene_symbol'\n\n\n\ngtf = pd.read_table(\"../data/external/human/Homo_sapiens.GRCh38.110.gene_length.tsv\", index_col=0)\ngene_lengths = gtf[['median']].copy()\ngene_lengths.columns = ['length']\ndef normalize_smartseq(adata: sc.AnnData, gene_len: pd.DataFrame) -&gt; sc.AnnData:\n    print(\"SMART-SEQ: Normalization\")\n\n    common_genes = adata.var_names.intersection(gene_len.index)\n    print(f\"SMART-SEQ: Common genes {common_genes.shape[0]}\")\n\n    lengths = gene_len.loc[common_genes, \"length\"].values\n    normalized = sc.AnnData(adata[:, common_genes].X, obs=adata.obs, dtype=np.float32)\n    normalized.var_names = common_genes\n    normalized.X = normalized.X / lengths * np.median(lengths)\n    normalized.X = np.rint(normalized.X)\n\n    return normalized\n\n\nnormalize_smartseq(adata_rivron, gene_lengths)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 62663\n\n\nAnnData object with n_obs  n_vars = 2673  62663\n    obs: 'sample', 'fastq_1', 'fastq_2', 'run_accession', 'experiment_accession', 'sample_accession', 'secondary_sample_accession', 'study_accession', 'secondary_study_accession', 'submission_accession', 'run_alias', 'experiment_alias', 'sample_alias', 'study_alias', 'library_layout', 'library_selection', 'library_source', 'library_strategy', 'instrument_model', 'instrument_platform', 'scientific_name', 'sample_title', 'experiment_title', 'study_title', 'sample_description', 'fastq_md5', 'fastq_bytes', 'fastq_ftp', 'fastq_galaxy', 'fastq_aspera'\n\n\n\nmetadata_rivron = adata_rivron.obs\n\n\nmetadata_rivron_clean = metadata_rivron.loc[:,['sample']]\n\n\nmetadata_rivron_clean['sample_title'] = metadata_rivron.sample_title.str.extract(r'^(.*)-', expand = False)\n\n\nmetadata_rivron_clean.sample_title.unique()\n\narray(['primed H9', 'blastoid 96h TROP2 pl', 'naive H9', 'okae bts5',\n       'blastoid 24h', 'blastoid 60h TROP2 pl', 'blastoid 60h TROP2 min',\n       'blastoid 96h DN', 'blastoid 96h PDGFRa pl',\n       'blastoid 60h PDGFRa pl'], dtype=object)\n\n\n\nmetadata_rivron_clean = metadata_rivron_clean.loc[metadata_rivron_clean.sample_title.isin(['blastoid 96h TROP2 pl', 'naive H9', 'blastoid 24h', 'blastoid 60h TROP2 pl', 'blastoid 60h TROP2 min', 'blastoid 96h DN', 'blastoid 96h PDGFRa pl', 'blastoid 60h PDGFRa pl'])].copy()\n\n\nmetadata_rivron_clean['batch'] = 'Rivron'\nmetadata_rivron_clean['time'] = metadata_rivron_clean['sample_title']\nmetadata_rivron_clean['flow'] = metadata_rivron_clean['sample_title']\n\n\ntime_replace_dict = {\n    'naive H9': '0h',\n    'blastoid 24h': '24h',\n    'blastoid 60h TROP2 pl': '60h',\n    'blastoid 60h TROP2 min': '60h',\n    'blastoid 60h PDGFRa pl': '60h',\n    'blastoid 96h DN': '96h',\n    'blastoid 96h PDGFRa pl': '96h',\n    'blastoid 96h TROP2 pl': '96h'\n}\n\nflow_replace_dict = {\n    'naive H9': 'naive',\n    'blastoid 24h': 'na',\n    'blastoid 60h TROP2 pl': 'TROP2+',\n    'blastoid 60h TROP2 min': 'TROP2-',\n    'blastoid 60h PDGFRa pl': 'PDGFRA+',\n    'blastoid 96h DN': 'Double-neg',\n    'blastoid 96h PDGFRa pl': 'PDGFRA+',\n    'blastoid 96h TROP2 pl': 'TROP2+'\n}\n\nmetadata_rivron_clean = metadata_rivron_clean.replace({'time': time_replace_dict, 'flow': flow_replace_dict})\n\n\nadata_rivron = adata_rivron[metadata_rivron_clean.index].copy()\n\n\nadata_rivron.obs = metadata_rivron_clean\n\n\nadata_rivron\n\nAnnData object with n_obs  n_vars = 2421  62754\n    obs: 'sample', 'sample_title', 'batch', 'time', 'flow'\n    var: 'gene_symbol'\n\n\n\nadata_rivron.var['mt'] = adata_rivron.var.gene_symbol.str.startswith('MT-')\n\n\n\nsc.pp.calculate_qc_metrics(adata_rivron, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n\n\nsns.violinplot(y=adata_rivron.obs['pct_counts_mt'], orient='v')\n\n&lt;Axes: ylabel='pct_counts_mt'&gt;\n\n\n\n\n\n\nadata_rivron.obs\n\n\n\n\n\n\n\n\nsample\nsample_title\nbatch\ntime\nflow\nn_genes_by_counts\ntotal_counts\ntotal_counts_mt\npct_counts_mt\n\n\n\n\nSRX11129000_SRX11129000\nSRX11129000\nblastoid 96h TROP2 pl\nRivron\n96h\nTROP2+\n2897\n1081299.0\n450085.0\n41.624470\n\n\nSRX11128994_SRX11128994\nSRX11128994\nblastoid 96h TROP2 pl\nRivron\n96h\nTROP2+\n6437\n2058883.0\n172783.0\n8.392075\n\n\nSRX11129132_SRX11129132\nSRX11129132\nnaive H9\nRivron\n0h\nnaive\n6808\n2237799.0\n217539.0\n9.721114\n\n\nSRX11129146_SRX11129146\nSRX11129146\nnaive H9\nRivron\n0h\nnaive\n7966\n1798534.0\n115297.0\n6.410610\n\n\nSRX11129013_SRX11129013\nSRX11129013\nblastoid 96h TROP2 pl\nRivron\n96h\nTROP2+\n6160\n1677046.0\n143402.0\n8.550869\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nSRX11131981_SRX11131981\nSRX11131981\nblastoid 60h TROP2 min\nRivron\n60h\nTROP2-\n43\n4086.0\n0.0\n0.000000\n\n\nSRX11131985_SRX11131985\nSRX11131985\nblastoid 60h TROP2 min\nRivron\n60h\nTROP2-\n5215\n837410.0\n196307.0\n23.442162\n\n\nSRX11131982_SRX11131982\nSRX11131982\nblastoid 60h TROP2 min\nRivron\n60h\nTROP2-\n8915\n1567157.0\n90066.0\n5.747095\n\n\nSRX11131984_SRX11131984\nSRX11131984\nblastoid 60h TROP2 min\nRivron\n60h\nTROP2-\n5978\n1709532.0\n0.0\n0.000000\n\n\nSRX11131980_SRX11131980\nSRX11131980\nblastoid 60h TROP2 min\nRivron\n60h\nTROP2-\n7449\n1845767.0\n67667.0\n3.666064\n\n\n\n\n2421 rows  9 columns\n\n\n\n\nsns.scatterplot(x='total_counts', y='n_genes_by_counts', data=adata_rivron.obs, hue='batch')\n\n&lt;Axes: xlabel='total_counts', ylabel='n_genes_by_counts'&gt;\n\n\n\n\n\n\nadata_rivron = adata_rivron[adata_rivron.obs.pct_counts_mt &lt; 12.5].copy()\nsc.pp.filter_cells(adata_rivron, min_counts=2.5e5)\nsc.pp.filter_cells(adata_rivron, max_counts=2.5e6)\nsc.pp.filter_cells(adata_rivron, min_genes=2_000)\nadata_rivron.layers[\"counts\"] = adata_rivron.X.copy()\nsc.pp.normalize_total(adata_rivron, target_sum=10_000)\nsc.pp.log1p(adata_rivron)\nadata_rivron.raw = adata_rivron\n\n\n# remove mitochondrial genes\nadata_rivron = adata_rivron[:, adata_rivron.var[~adata_rivron.var.gene_symbol.str.startswith('MT-')].index].copy()\n\n# remove ribosomal genes\nadata_rivron = adata_rivron[:, adata_rivron.var[~adata_rivron.var.gene_symbol.str.startswith(('RPS', 'RPL'))].index].copy()\n\n\nadata_rivron.write_h5ad('../results/06_human_Rivron.h5ad')\n\n\nquery = sc.read_h5ad('../results/06_human_Rivron.h5ad')\nquery.obs['experiment'] = 'Rivron'\nquery\n\nAnnData object with n_obs  n_vars = 1762  61002\n    obs: 'sample', 'sample_title', 'batch', 'time', 'flow', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'n_counts', 'n_genes', 'experiment'\n    var: 'gene_symbol', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'\n    uns: 'log1p'\n    layers: 'counts'\n\n\n\nlvae = scvi.model.SCANVI.load(\"../results/02_human_integration/05_scanvi_ns15/\")\n#lvae = scvi.model.SCANVI.load(\"../results/deprecated/human_integration/version_1/scanvi/\")\n\nINFO     File ../results/02_human_integration/05_scanvi_ns15/model.pt already downloaded                           \n\n\n\nscvi.model.SCVI.prepare_query_anndata(query, lvae)\n\nINFO     Found 92.96666666666667% reference vars in query data.                                                    \n\n\n\nlvae_q = scvi.model.SCANVI.load_query_data(query, lvae)\n\n\nlvae_q.train(\n    max_epochs=100,\n    plan_kwargs=dict(weight_decay=0.0),\n    check_val_every_n_epoch=10,\n    early_stopping=True\n)\n\nINFO     Training for 100 epochs.                                                                                  \nEpoch 100/100: 100%|| 100/100 [00:20&lt;00:00,  4.97it/s, v_num=1, train_loss_step=4.93e+3, train_loss_epoch=4.65e+3]Epoch 100/100: 100%|| 100/100 [00:20&lt;00:00,  4.83it/s, v_num=1, train_loss_step=4.93e+3, train_loss_epoch=4.65e+3]\n\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n\n\n\nquery.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nquery.obs[\"predictions\"] = lvae_q.predict()\nquery.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\n\npd.crosstab(query.obs.predictions, query.obs.flow)\n\n\n\n\n\n\n\nflow\nDouble-neg\nPDGFRA+\nTROP2+\nTROP2-\nna\nnaive\n\n\npredictions\n\n\n\n\n\n\n\n\n\n\n8C_3.0\n1\n0\n0\n0\n0\n0\n\n\nEpiblast_6.0\n146\n8\n52\n80\n72\n49\n\n\nEpiblast_7.0\n120\n9\n71\n65\n88\n39\n\n\nInner Cell Mass\n0\n1\n0\n0\n0\n0\n\n\nLate epiblast\n124\n12\n42\n18\n32\n42\n\n\nMorula_4.0\n1\n0\n0\n0\n0\n0\n\n\nPrimitive Endoderm\n33\n121\n33\n36\n16\n6\n\n\nTrophectoderm_10.0\n3\n0\n4\n0\n0\n0\n\n\nTrophectoderm_5.0\n0\n0\n1\n0\n4\n0\n\n\nTrophectoderm_6.0\n4\n0\n76\n2\n6\n1\n\n\nTrophectoderm_7.0\n15\n0\n140\n1\n1\n0\n\n\nTrophectoderm_8.0\n14\n2\n52\n0\n0\n1\n\n\nTrophectoderm_9.0\n7\n0\n111\n0\n0\n0\n\n\n\n\n\n\n\n\npd.crosstab(query.obs.predictions, query.obs.time)\n\n\n\n\n\n\n\ntime\n0h\n24h\n60h\n96h\n\n\npredictions\n\n\n\n\n\n\n\n\n8C_3.0\n0\n0\n0\n1\n\n\nEpiblast_6.0\n49\n72\n120\n166\n\n\nEpiblast_7.0\n39\n88\n111\n154\n\n\nInner Cell Mass\n0\n0\n1\n0\n\n\nLate epiblast\n42\n32\n38\n158\n\n\nMorula_4.0\n0\n0\n0\n1\n\n\nPrimitive Endoderm\n6\n16\n66\n157\n\n\nTrophectoderm_10.0\n0\n0\n0\n7\n\n\nTrophectoderm_5.0\n0\n4\n1\n0\n\n\nTrophectoderm_6.0\n1\n6\n62\n20\n\n\nTrophectoderm_7.0\n0\n1\n30\n126\n\n\nTrophectoderm_8.0\n1\n0\n4\n64\n\n\nTrophectoderm_9.0\n0\n0\n5\n113\n\n\n\n\n\n\n\n\nsc.pp.highly_variable_genes(\n    query,\n    flavor=\"seurat_v3\",\n    n_top_genes=5_000,\n    layer=\"counts\",\n    batch_key=\"batch\",\n    subset=True,\n)\nsc.pp.neighbors(query)\nsc.tl.umap(query)\n\nWARNING: Youre trying to run this on 3000 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n         Falling back to preprocessing with `sc.pp.pca` and default params.\n\n\n2024-01-12 17:05:15.412966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\nsc.pl.umap(query, color=['predictions','time', 'flow', 'entropy'], ncols=1)"
  },
  {
    "objectID": "notebooks/06_mouse_query.html",
    "href": "notebooks/06_mouse_query.html",
    "title": "06 - mouse query",
    "section": "",
    "text": "%matplotlib inline\n\nimport scvi\nimport scanpy as sc\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\nimport warnings\n\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\nscvi.settings.seed = 0\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n[rank: 0] Global seed set to 0\nplt.rcParams['svg.fonttype'] = 'none'\n\nct_colors = {\n    'Zygote': '#7985A5',\n    '2C': '#B3C81E',\n    '4C': '#67BB30',\n    '8C': '#028A46',\n    '16C': '#657cbd',\n    'E3.25-ICM': '#fadc8f',\n    'E3.25-TE': '#5185b9',\n    'E3.5-ICM': '#f8d06a',\n    'E3.5-TE': '#7ba9d8',\n    'E3.5-EPI': '#c38cb0',\n    'E3.5-PrE': '#d97c81',\n    'E3.75-ICM': '#F6C445',\n    'E4.5-TE': '#5a94ce',\n    'E4.5-EPI': '#B46F9C',\n    'E4.5-PrE': '#D05B61'\n}"
  },
  {
    "objectID": "notebooks/06_mouse_query.html#load-scanvi-reference-model",
    "href": "notebooks/06_mouse_query.html#load-scanvi-reference-model",
    "title": "06 - mouse query",
    "section": "1 1. Load scANVI reference model",
    "text": "1 1. Load scANVI reference model\n\n# lvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\")\n\nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded"
  },
  {
    "objectID": "notebooks/06_mouse_query.html#query-integration",
    "href": "notebooks/06_mouse_query.html#query-integration",
    "title": "06 - mouse query",
    "section": "2 2. Query integration",
    "text": "2 2. Query integration\n\nimport anndata\nimport pandas as pd\nimport scanpy as sc\nimport numpy as np\nimport seaborn as sns\n\n\ndef normalize_smartseq(adata: sc.AnnData, gene_len: pd.DataFrame) -&gt; sc.AnnData:\n    print(\"SMART-SEQ: Normalization\")\n\n    common_genes = adata.var_names.intersection(gene_len.index)\n    print(f\"SMART-SEQ: Common genes {common_genes.shape[0]}\")\n\n    lengths = gene_len.loc[common_genes, \"length\"].values\n    normalized = adata[:, common_genes].copy()\n    normalized.X = normalized.X / lengths * np.median(lengths)\n    normalized.X = np.rint(normalized.X)\n\n    return normalized\n\n\ndef load_experiment(filename: str, GEO: str, left_on: str = 'sample', right_on='SRX'):\n    adata = sc.read(filename)\n    metadata = pd.read_csv(f\"../pipeline/fetchngs/{GEO}_metadata.csv\")\n\n    # sometimes we have duplicates because the ID is not unique\n    adata.obs = pd.merge(adata.obs, metadata, left_on=left_on, right_on=right_on)\\\n                    .drop_duplicates(left_on)\\\n                    .set_index(left_on)\n\n    adata.obs['ct_orig'] = adata.obs['sample_title']\n\n    return adata\n\n\ngenes_length = pd.read_table(\"../data/external/Mus_musculus_GRCm38_102_gene_length.txt\").set_index('gene')\ngenes_length['length'] = genes_length['mean']\n\n\n2.1 2.1. Borensztein et al., 2017 [GSE80810]\nnf-core_tower.sh \\\n    Borensztein_query \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.10.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/GSE80810_query.txt\n\nnf-core_tower.sh Borensztein_query nextflow run brickmanlab/scrnaseq \\\n    -r feature/smartseq \\\n    -c /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/smartseq.config \\\n    --input /scratch/Brickman/pipelines/Borensztein_query/results/samplesheet/samplesheet.csv\n\nborenszrtein_metadata = pd.read_table(\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE80nnn/GSE80810/matrix/GSE80810_series_matrix.txt.gz\",\n                                      skiprows=31, index_col=0).T\nborenszrtein_metadata['SRX'] = borenszrtein_metadata[['!Sample_relation']].iloc[:, :2].agg(' '.join, axis=1).str.extract(r'(SRX[0-9]{6})')\nborenszrtein_metadata['ct'] = borenszrtein_metadata['!Sample_characteristics_ch1'].iloc[:, 1].values\nborenszrtein_metadata = borenszrtein_metadata.reset_index()\n\nlegend = {\n    'developmental stage: 32-cell': '32-cell',\n    'developmental stage: 64-cell': '64-cell'\n}\n\nfor old_name, new_name in legend.items():\n    borenszrtein_metadata.loc[borenszrtein_metadata.ct == old_name, 'ct'] = new_name\n    \nborenszrtein_metadata = borenszrtein_metadata[borenszrtein_metadata.ct.isin(legend.values())].copy()\nborenszrtein_metadata = borenszrtein_metadata[borenszrtein_metadata['!Sample_characteristics_ch1'].iloc[:, 2].str.contains('wt/wt')].copy()\n\nborenszrtein_metadata['!Sample_geo_accession'].to_csv(\"../pipeline/fetchngs/GSE80810_query.txt\", index=None, header=None)\nborenszrtein_metadata.set_index('SRX').to_csv(\"../pipeline/fetchngs/GSE80810_query_metadata.csv\")\n\n\nborensztein = load_experiment(\n    \"../data/external/aligned/mouse/Borensztein_query/results/star/mtx_conversions/combined_matrix.h5ad\",\n    GEO=\"GSE80810_query\", left_on='sample_alias', right_on='ID_REF'\n)\n\nborensztein.obs['batch'] = \"BORENSZTEIN_1\"\nborensztein.obs['experiment'] = \"Borensztein et al., 2017\"\nborensztein.obs['technology'] = \"qRT-PCR\"\n\nborensztein.obs = borensztein.obs[['batch', 'experiment', 'technology', 'ct', 'ct_orig']]\nborensztein.obs['_ct'] = borensztein.obs['ct']\nborensztein.obs.ct = 'Unknown'\n\nborensztein = normalize_smartseq(borensztein, genes_length)\n\nborensztein.var = borensztein.var.gene_symbol.str.lower().reset_index().set_index('gene_symbol')\nborensztein.var_names_make_unique()\n\nborensztein.X = np.asarray(borensztein.X) \nborensztein.layers['counts'] = np.asarray(borensztein.X)\n\nsc.pp.normalize_total(borensztein)\nsc.pp.log1p(borensztein)\nsc.pp.highly_variable_genes(borensztein, n_top_genes=3000)\nsc.pp.pca(borensztein)\n\nsc.pp.neighbors(borensztein)\nsc.tl.leiden(borensztein)\n\n\nsc.pl.pca(borensztein, color=['_ct', 'leiden'], size=200)\n\n\nscvi.model.SCANVI.prepare_query_anndata(borensztein, lvae)\nlvae_q = scvi.model.SCANVI.load_query_data(borensztein, lvae)\nlvae_q.train(\n    max_epochs=100,\n    plan_kwargs=dict(weight_decay=0.0),\n    check_val_every_n_epoch=10,\n)\n\n\nborensztein.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nborensztein.obs[\"predictions\"] = lvae_q.predict()\nborensztein.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\n\nsc.pl.pca(borensztein, color=['_ct', 'leiden', 'predictions'], size=200)\n\n\nsc.metrics.confusion_matrix('_ct', 'predictions', borensztein.obs).plot(kind='barh', stacked=True)\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(frameon=False, bbox_to_anchor=(1, 1))\n\n\nsc.metrics.confusion_matrix('leiden', 'predictions', borensztein.obs).plot(kind='barh', stacked=True)\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.gca().legend(frameon=False, bbox_to_anchor=(1, 1))\n\n\n\n2.2 2.2. Proks et al., 2023\n\n# !wget https://zenodo.org/record/8016374/files/02_dataset.h5ad?download=1 -O ../data/external/Proks_et_al_2023/02_dataset.h5ad\n\n\nvitro = sc.read(\"../data/external/Proks_et_al_2023/02_dataset.h5ad\")\nvitro_raw = sc.AnnData(vitro.raw.X, var=vitro.raw.var, obs=vitro.obs)\nvitro_raw.var_names = vitro_raw.var_names.str.lower()\nvitro_raw.layers['counts'] = vitro_raw.X\nvitro_raw\n\nAnnData object with n_obs  n_vars = 1575  20459\n    obs: 'Well_coordinates', 'plate_ID', 'Amp_batch_ID', 'Cell_barcode', 'Pool_barcode', 'Batch', 'Condition', 'SampleName', 'Stage', 'Source', 'Day', 'Index sort', 'All.Events.FSC-A.Geo.Mean', 'All.Events.SSC-A.Geo.Mean', 'All.Events.GFP-A.Geo.Mean', 'All.Events.mCherry.561D-A.Geo.Mean', 'All.Events.DAPI-A.Geo.Mean', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ercc', 'pct_counts_ercc', 'total_counts_ribo', 'pct_counts_ribo', 'n_genes', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain', 'leiden', 'umap_density_Stage', 'batch', 'initial_size_spliced', 'initial_size_unspliced', 'initial_size', 'velocity_self_transition', 'root_cells', 'end_points', 'velocity_pseudotime', 'latent_time', 'velocity_length', 'velocity_confidence', 'velocity_confidence_transition'\n    var: 'mt', 'ercc', 'ribo', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'gene_ids'\n    layers: 'counts'\n\n\n\nsc.pl.umap(vitro, color=['Stage', 'leiden'])\n\n\n\n\n\nfig, ax = plt.subplots(1, 2, figsize=[14, 4])\n\nhhex_protein = vitro.obs['All.Events.mCherry.561D-A.Geo.Mean']\nhhex_cutoff = hhex_protein.median() + hhex_protein.std()\nhhex_protein.plot(kind='hist', bins=30, label='Hhex+', alpha=0.6, ax=ax[0], color='olive')\nax[0].axvline(x=hhex_protein.mean(), c='r', ls='--', label='$med$')\nax[0].axvline(x=hhex_cutoff, c='b', ls='--', label='$med + \\sigma$')\nax[0].legend()\n\nsox2_protein = vitro.obs['All.Events.GFP-A.Geo.Mean']\nsox2_cutoff = sox2_protein.median() + sox2_protein.std()\nsox2_protein.plot(kind='hist', bins=30, label='Sox2+', alpha=0.6, ax=ax[1], color='orange')\nax[1].axvline(x=sox2_protein.mean(), c='r', ls='--', label='$med$')\nax[1].axvline(x=sox2_cutoff, c='b', ls='--', label='$med + \\sigma$')\nax[1].legend()\n\nvitro.obs['FACS'] = \"Unknown\"\nvitro.obs.loc[vitro.obs['All.Events.mCherry.561D-A.Geo.Mean'] &gt; hhex_cutoff, 'FACS'] = 'Hhex+'\nvitro.obs.loc[vitro.obs['All.Events.GFP-A.Geo.Mean'] &gt; hhex_cutoff, 'FACS'] = 'Sox2+'\n\n\n\n\n\nvitro_raw.obs['batch'] = vitro_raw.obs['Batch']\nvitro_raw.obs['technology'] = \"MARS-seq\"\n\n\nscvi.model.SCANVI.prepare_query_anndata(vitro_raw, lvae)\n\nINFO     Found 76.6% reference vars in query data.                                                                 \n\n\n\nlvae_q = scvi.model.SCANVI.load_query_data(vitro_raw, lvae)\n\n\nlvae_q.train(\n    max_epochs=100,\n    plan_kwargs=dict(weight_decay=0.0),\n    check_val_every_n_epoch=10,\n)\n\nINFO     Training for 100 epochs.                                                                                  \nEpoch 100/100: 100%|| 100/100 [00:14&lt;00:00,  6.74it/s, v_num=1, train_loss_step=1.1e+3, train_loss_epoch=1.06e+3]Epoch 100/100: 100%|| 100/100 [00:14&lt;00:00,  6.88it/s, v_num=1, train_loss_step=1.1e+3, train_loss_epoch=1.06e+3]\n\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n\n\n\nvitro.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nvitro.obs[\"predictions\"] = lvae_q.predict()\nvitro.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\n\nsc.pl.umap(vitro, color=['Stage', 'leiden', 'predictions', 'FACS', 'All.Events.GFP-A.Geo.Mean', 'All.Events.mCherry.561D-A.Geo.Mean'], ncols=3)\n\n\n\n\n\nsc.pl.umap(vitro, color=['predictions', 'entropy'], vmax=1, vmin=0, frameon=False, save=\"\")\n\n\n\n\n\nfig, ax = plt.subplots(1, 3, figsize=[20, 6])\nsns.heatmap(sc.metrics.confusion_matrix(\"Stage\", \"predictions\", vitro.obs), annot=True, fmt='.2%', cmap='Blues', ax=ax[0], cbar=False)\nsns.heatmap(sc.metrics.confusion_matrix(\"leiden\", \"predictions\", vitro.obs), annot=True, fmt='.2%', cmap='Blues', ax=ax[1], cbar=False)\nsns.heatmap(sc.metrics.confusion_matrix(\"FACS\", \"predictions\", vitro.obs), annot=True, fmt='.2%', cmap='Blues', ax=ax[2])\n\n&lt;Axes: xlabel='predictions', ylabel='FACS'&gt;\n\n\n\n\n\n\nconf_mat = (sc.metrics.confusion_matrix('FACS', 'predictions', vitro.obs) * 100)[['E3.5-TE', 'E3.5-EPI', 'E3.5-PrE', 'E4.5-EPI', 'E4.5-PrE']]\nconf_mat.plot.barh(stacked=True, color=ct_colors)\nplt.legend(conf_mat.columns.str.replace('_', ' '), loc='center right', bbox_to_anchor=(1.25, 0.5), frameon=False)\nplt.gca().spines[['right', 'top']].set_visible(False)\nplt.xlabel('% of cells')\nplt.ylabel('FACS labeled cells')\nplt.title('in vitro mouse PrE conpositional prediction')\n\nplt.savefig(\"../figures/mouse/00_query_facs_predictions.svg\")\nsc.metrics.confusion_matrix('FACS', 'predictions', vitro.obs, normalize=False).to_csv(\"../results/00_mouse_query.csv\")"
  },
  {
    "objectID": "notebooks/06_mouse_query.html#timepoint-prediction-deprecated",
    "href": "notebooks/06_mouse_query.html#timepoint-prediction-deprecated",
    "title": "06 - mouse query",
    "section": "3 Timepoint prediction (deprecated)",
    "text": "3 Timepoint prediction (deprecated)\n\nimport pickle\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi/\")\nvae_q = scvi.model.SCVI.load_query_data(vitro_raw, vae)\n\n\nX = vae_q.get_normalized_expression(return_mean=True, return_numpy=True)\n\n\ndef tp_predict(adata: sc.AnnData, model_pkl: str, X_):\n    model = pickle.load(open(model_pkl, 'rb'))\n    adata.obs[\"tp_predictions\"] = vae.adata.obs.timepoint.cat.categories[model.predict(X_)]\n    \n    sc.pl.umap(adata, color=['Stage', 'tp_predictions', 'leiden'], ncols=3)\n    display(sc.metrics.confusion_matrix('Stage', 'tp_predictions', adata.obs) * 100)\n\n\ntp_predict(vitro, \"../results/05_mouse_timepoint_rbf.pkl\", X)\n\n\ntp_predict(\n    vitro, \n    \"../results/05_mouse_timepoint_rbf_pca15.pkl\", \n    PCA(n_components=15, svd_solver='arpack').fit_transform(StandardScaler().fit(X).transform(X))\n)\n\n\ntp_predict(\n    vitro, \n    \"../results/05_mouse_timepoint_poly3_pca2.pkl\", \n    PCA(n_components=2, svd_solver='arpack').fit_transform(StandardScaler().fit(X).transform(X))\n)\n\n\ntp_predict(\n    vitro, \n    \"../results/05_mouse_timepoint_poly3_pca30.pkl\", \n    PCA(n_components=30, svd_solver='arpack').fit_transform(StandardScaler().fit(X).transform(X))\n)\n\n\ntp_predict(vitro, \"../results/05_mouse_timepoint_knn15.pkl\", X)\n\n\n\nvitro.write(\"../results/06_proks_et_al.h5ad\")"
  },
  {
    "objectID": "notebooks/08_shap_explainers.html",
    "href": "notebooks/08_shap_explainers.html",
    "title": "SHAP explainers for SCANVI",
    "section": "",
    "text": "In this notebook we have tried to modify the SHAP to accept SCVI/SCANVI object. Withing the tool, there are two option which can be used.\nKernelExplainer which is agnostic to the model, only requires a prediction function and input. The problem is that its very slow.\nAlternative approach which is recommended when dealign with NN is to use the DeepExplainer (supports both PyTorch and Tensorflow).\nDeepExplainer will propage through the network and extract the weights and then will determine after penalization which features are the crucial one for classification.\n!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\n%matplotlib inline\n\nimport scvi\nimport scgen\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom typing import Tuple\n\nfrom numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\nimport warnings\n\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\nscvi.settings.seed = 0\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n[rank: 0] Global seed set to 0\n%run ../scripts/deep_scanvi.py\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\nlvae\n\nINFO     File ../results/02_mouse_integration/scanvi/model.pt already downloaded                                   \n\n\nScanVI Model with the following params: \nunlabeled_category: Unknown, n_hidden: 128, n_latent: 10, n_layers: 2, dropout_rate: 0.005, dispersion: gene, \ngene_likelihood: nb\nTraining status: Trained\nModel's adata is minified?: False\nimport anndata\nimport torch\nfrom sklearn.model_selection import train_test_split\n\n\ndef train_test_group_split(adata: anndata.AnnData, groupby: str):\n    \"\"\"\n    Function to split anndata object 80/20 per group in format\n    required for SCANVIDeep explainer.\n    \"\"\"\n    groups = adata.obs.groupby(groupby)\n    train, test = [], []\n    for _, cells in groups.groups.items():\n        train_test = train_test_split(cells.values, test_size=0.1)\n        \n        train.append(train_test[0])\n        test.append(train_test[1])\n\n    train, test = np.concatenate(train), np.concatenate(test)\n\n    X_train = {\n        'X': torch.from_numpy(adata[train].layers['counts'].A).type(torch.DoubleTensor),\n        'batch': torch.from_numpy(adata[train].obs.batch.cat.codes.values[:, np.newaxis]),\n        'labels': torch.from_numpy(adata[train].obs.ct.cat.codes.values[:, np.newaxis])\n    }\n\n    X_test = {\n        'X': torch.from_numpy(adata[test].layers['counts'].A).type(torch.DoubleTensor),\n        'batch': torch.from_numpy(adata[test].obs.batch.cat.codes.values[:, np.newaxis]),\n        'labels': torch.from_numpy(adata[test].obs.ct.cat.codes.values[:, np.newaxis])\n    }\n    \n    return X_train, X_test\n\n\ndef feature_plot(X_test, shap_values: np.ndarray, classes: pd.Index, features: np.ndarray, subset: bool = False):\n    \"\"\"\n    Prints feature contribution (absolute mean SHAP value) for each cell type (top 10).\n\n    X_test: \n        test dataset\n    shap_values: \n        SHAP values\n    classes: \n        list of classifiers (cell types in this case)\n    features: \n        list of genes (HVGs)\n    subset: \n        If True calculate contribution by subsetting for test cells which belong to that particual classifier\n        Else Be generic and return contributing features even when testing set has different cell types\n    \"\"\"\n    fig, ax = plt.subplots(7, 2, sharex=False, figsize=[20, 40])\n    \n    for idx, ct in enumerate(classes):\n    \n        shaps = pd.DataFrame(shap_values[idx], columns=features)\n\n        if subset:\n            shaps['ct'] = X_test['labels']\n            shaps = shaps.query('ct == @idx').iloc[:, :-1]\n\n            tmp_avg = shaps\\\n                .mean(axis=0)\\\n                .sort_values(ascending=False)\\\n                .reset_index()\\\n                .rename(columns={'index':'feature',0:'weight'})\\\n            \n            positive = tmp_avg.query('weight &gt; 0').head(5)\n            negative = tmp_avg.query('weight &lt; 0').tail(5)\n\n            avg = pd.concat([positive, negative])\n            title = f'Mean(SHAP value average importance for: {ct}'\n            \n        else:\n            avg = shaps\\\n                .abs()\\\n                .mean(axis=0)\\\n                .sort_values(ascending=False)\\\n                .reset_index()\\\n                .rename(columns={'index':'feature',0:'weight'})\\\n                .query('weight &gt; 0')\\\n                .head(10)\n            title = f'Mean(|SHAP value|) average importance for: {ct}'\n    \n        sns.barplot(x='weight', y='feature', data=avg, ax=ax[idx // 2, idx % 2])\n        ax[idx // 2, idx % 2].set_title(title)\nbackground, test = train_test_group_split(lvae.adata, groupby='ct')"
  },
  {
    "objectID": "notebooks/08_shap_explainers.html#kernelexplainer",
    "href": "notebooks/08_shap_explainers.html#kernelexplainer",
    "title": "SHAP explainers for SCANVI",
    "section": "1 KernelExplainer",
    "text": "1 KernelExplainer\n\nfrom anndata import AnnData\nfrom tqdm import tqdm\nfrom shap.explainers._kernel import Kernel\nfrom shap.utils._legacy import (\n    IdentityLink,\n    convert_to_instance_with_index,\n    convert_to_instance,\n    match_instance_to_data,\n)\nfrom scipy.special import binom\n\nimport copy\nimport logging\nimport pandas as pd\nimport itertools\nimport numpy as np\n\nlog = logging.getLogger(\"shap\")\nBATCH = \"batch\"\n\n\nclass SCANVIExplainer(Kernel):\n    def __init__(self, model, adata: AnnData, link=IdentityLink(), **kwargs):\n\n        # self.batch = adata.obs[BATCH]\n        data = adata.to_df()\n\n        super().__init__(model, data, link=IdentityLink(), **kwargs)\n\n    def explain(self, incoming_instance, **kwargs):\n\n        index_hardcode = kwargs.get(\"index_hardcode\")\n        # convert incoming input to a standardized iml object\n        instance = convert_to_instance(incoming_instance)\n        match_instance_to_data(instance, self.data)\n\n        # find the feature groups we will test. If a feature does not change from its\n        # current value then we know it doesn't impact the model\n\n        self.varyingInds = self.varying_groups(instance.x)\n        if self.data.groups is None:\n            self.varyingFeatureGroups = np.array([i for i in self.varyingInds])\n            self.M = self.varyingFeatureGroups.shape[0]\n        else:\n            self.varyingFeatureGroups = [self.data.groups[i] for i in self.varyingInds]\n            self.M = len(self.varyingFeatureGroups)\n            groups = self.data.groups\n            # convert to numpy array as it is much faster if not jagged array (all groups of same length)\n            if self.varyingFeatureGroups and all(\n                len(groups[i]) == len(groups[0]) for i in self.varyingInds\n            ):\n                self.varyingFeatureGroups = np.array(self.varyingFeatureGroups)\n                # further performance optimization in case each group has a single value\n                if self.varyingFeatureGroups.shape[1] == 1:\n                    self.varyingFeatureGroups = self.varyingFeatureGroups.flatten()\n\n        # find f(x)\n        if self.keep_index:\n            # pass_df = instance.convert_to_df()\n            pass_df = pd.DataFrame(instance.x, index=index_hardcode)\n            # pass_df.index = index_hardcode\n            # display(pass_df)\n            model_out = self.model.f(pass_df)\n        else:\n            model_out = self.model.f(instance.x)\n        if isinstance(model_out, (pd.DataFrame, pd.Series)):\n            model_out = model_out.values\n        self.fx = model_out[0]\n\n        if not self.vector_out:\n            self.fx = np.array([self.fx])\n\n        # if no features vary then no feature has an effect\n        if self.M == 0:\n            phi = np.zeros((self.data.groups_size, self.D))\n            phi_var = np.zeros((self.data.groups_size, self.D))\n\n        # if only one feature varies then it has all the effect\n        elif self.M == 1:\n            phi = np.zeros((self.data.groups_size, self.D))\n            phi_var = np.zeros((self.data.groups_size, self.D))\n            diff = self.link.f(self.fx) - self.link.f(self.fnull)\n            for d in range(self.D):\n                phi[self.varyingInds[0], d] = diff[d]\n\n        # if more than one feature varies then we have to do real work\n        else:\n            self.l1_reg = kwargs.get(\"l1_reg\", \"auto\")\n\n            # pick a reasonable number of samples if the user didn't specify how many they wanted\n            self.nsamples = kwargs.get(\"nsamples\", \"auto\")\n            if self.nsamples == \"auto\":\n                self.nsamples = 2 * self.M + 2**11\n\n            # if we have enough samples to enumerate all subsets then ignore the unneeded samples\n            self.max_samples = 2**30\n            if self.M &lt;= 30:\n                self.max_samples = 2**self.M - 2\n                if self.nsamples &gt; self.max_samples:\n                    self.nsamples = self.max_samples\n\n            # reserve space for some of our computations\n            self.allocate()\n\n            # weight the different subset sizes\n            num_subset_sizes = np.int(np.ceil((self.M - 1) / 2.0))\n            num_paired_subset_sizes = np.int(np.floor((self.M - 1) / 2.0))\n            weight_vector = np.array(\n                [\n                    (self.M - 1.0) / (i * (self.M - i))\n                    for i in range(1, num_subset_sizes + 1)\n                ]\n            )\n            weight_vector[:num_paired_subset_sizes] *= 2\n            weight_vector /= np.sum(weight_vector)\n            log.debug(\"weight_vector = {0}\".format(weight_vector))\n            log.debug(\"num_subset_sizes = {0}\".format(num_subset_sizes))\n            log.debug(\"num_paired_subset_sizes = {0}\".format(num_paired_subset_sizes))\n            log.debug(\"M = {0}\".format(self.M))\n\n            # fill out all the subset sizes we can completely enumerate\n            # given nsamples*remaining_weight_vector[subset_size]\n            num_full_subsets = 0\n            num_samples_left = self.nsamples\n            group_inds = np.arange(self.M, dtype=\"int64\")\n            mask = np.zeros(self.M)\n            remaining_weight_vector = copy.copy(weight_vector)\n            for subset_size in range(1, num_subset_sizes + 1):\n\n                # determine how many subsets (and their complements) are of the current size\n                nsubsets = binom(self.M, subset_size)\n                if subset_size &lt;= num_paired_subset_sizes:\n                    nsubsets *= 2\n                log.debug(\"subset_size = {0}\".format(subset_size))\n                log.debug(\"nsubsets = {0}\".format(nsubsets))\n                log.debug(\n                    \"self.nsamples*weight_vector[subset_size-1] = {0}\".format(\n                        num_samples_left * remaining_weight_vector[subset_size - 1]\n                    )\n                )\n                log.debug(\n                    \"self.nsamples*weight_vector[subset_size-1]/nsubsets = {0}\".format(\n                        num_samples_left\n                        * remaining_weight_vector[subset_size - 1]\n                        / nsubsets\n                    )\n                )\n\n                # see if we have enough samples to enumerate all subsets of this size\n                if (\n                    num_samples_left\n                    * remaining_weight_vector[subset_size - 1]\n                    / nsubsets\n                    &gt;= 1.0 - 1e-8\n                ):\n                    num_full_subsets += 1\n                    num_samples_left -= nsubsets\n\n                    # rescale what's left of the remaining weight vector to sum to 1\n                    if remaining_weight_vector[subset_size - 1] &lt; 1.0:\n                        remaining_weight_vector /= (\n                            1 - remaining_weight_vector[subset_size - 1]\n                        )\n\n                    # add all the samples of the current subset size\n                    w = weight_vector[subset_size - 1] / binom(self.M, subset_size)\n                    if subset_size &lt;= num_paired_subset_sizes:\n                        w /= 2.0\n                    for inds in itertools.combinations(group_inds, subset_size):\n                        mask[:] = 0.0\n                        mask[np.array(inds, dtype=\"int64\")] = 1.0\n                        self.addsample(instance.x, mask, w)\n                        if subset_size &lt;= num_paired_subset_sizes:\n                            mask[:] = np.abs(mask - 1)\n                            self.addsample(instance.x, mask, w)\n                else:\n                    break\n            log.info(\"num_full_subsets = {0}\".format(num_full_subsets))\n\n            # add random samples from what is left of the subset space\n            nfixed_samples = self.nsamplesAdded\n            samples_left = self.nsamples - self.nsamplesAdded\n            log.debug(\"samples_left = {0}\".format(samples_left))\n            if num_full_subsets != num_subset_sizes:\n                remaining_weight_vector = copy.copy(weight_vector)\n                remaining_weight_vector[\n                    :num_paired_subset_sizes\n                ] /= 2  # because we draw two samples each below\n                remaining_weight_vector = remaining_weight_vector[num_full_subsets:]\n                remaining_weight_vector /= np.sum(remaining_weight_vector)\n                log.info(\n                    \"remaining_weight_vector = {0}\".format(remaining_weight_vector)\n                )\n                log.info(\n                    \"num_paired_subset_sizes = {0}\".format(num_paired_subset_sizes)\n                )\n                ind_set = np.random.choice(\n                    len(remaining_weight_vector),\n                    4 * samples_left,\n                    p=remaining_weight_vector,\n                )\n                ind_set_pos = 0\n                used_masks = {}\n                while samples_left &gt; 0 and ind_set_pos &lt; len(ind_set):\n                    mask.fill(0.0)\n                    ind = ind_set[\n                        ind_set_pos\n                    ]  # we call np.random.choice once to save time and then just read it here\n                    ind_set_pos += 1\n                    subset_size = ind + num_full_subsets + 1\n                    mask[np.random.permutation(self.M)[:subset_size]] = 1.0\n\n                    # only add the sample if we have not seen it before, otherwise just\n                    # increment a previous sample's weight\n                    mask_tuple = tuple(mask)\n                    new_sample = False\n                    if mask_tuple not in used_masks:\n                        new_sample = True\n                        used_masks[mask_tuple] = self.nsamplesAdded\n                        samples_left -= 1\n                        self.addsample(instance.x, mask, 1.0)\n                    else:\n                        self.kernelWeights[used_masks[mask_tuple]] += 1.0\n\n                    # add the compliment sample\n                    if samples_left &gt; 0 and subset_size &lt;= num_paired_subset_sizes:\n                        mask[:] = np.abs(mask - 1)\n\n                        # only add the sample if we have not seen it before, otherwise just\n                        # increment a previous sample's weight\n                        if new_sample:\n                            samples_left -= 1\n                            self.addsample(instance.x, mask, 1.0)\n                        else:\n                            # we know the compliment sample is the next one after the original sample, so + 1\n                            self.kernelWeights[used_masks[mask_tuple] + 1] += 1.0\n\n                # normalize the kernel weights for the random samples to equal the weight left after\n                # the fixed enumerated samples have been already counted\n                weight_left = np.sum(weight_vector[num_full_subsets:])\n                log.info(\"weight_left = {0}\".format(weight_left))\n                self.kernelWeights[nfixed_samples:] *= (\n                    weight_left / self.kernelWeights[nfixed_samples:].sum()\n                )\n\n            # execute the model on the synthetic samples we have created\n            self.run()\n\n            # solve then expand the feature importance (Shapley value) vector to contain the non-varying features\n            phi = np.zeros((self.data.groups_size, self.D))\n            phi_var = np.zeros((self.data.groups_size, self.D))\n            for d in range(self.D):\n                vphi, vphi_var = self.solve(self.nsamples / self.max_samples, d)\n                phi[self.varyingInds, d] = vphi\n                phi_var[self.varyingInds, d] = vphi_var\n\n        if not self.vector_out:\n            phi = np.squeeze(phi, axis=1)\n            phi_var = np.squeeze(phi_var, axis=1)\n\n        return phi\n\n    @staticmethod\n    def not_equal(i, j):\n        return Kernel.not_equal(i, j)\n\n    def varying_groups(self, x):\n        return super().varying_groups(x)\n\n    def allocate(self):\n        super().allocate()\n\n    def addsample(self, x, m, w):\n        super().addsample(x, m, w)\n\n    def run(self):\n        super().run()\n\n    def solve(self, fraction_evaluated, dim):\n        return super().solve(fraction_evaluated, dim)\n\n    def shap_values(self, adata: AnnData, **kwargs):\n        \"\"\"Estimate the SHAP values for a set of samples.\n\n        Parameters\n        ----------\n        adata : anndata.AnnData\n            AnnData deal with it\n\n        nsamples : \"auto\" or int\n            Number of times to re-evaluate the model when explaining each prediction. More samples\n            lead to lower variance estimates of the SHAP values. The \"auto\" setting uses\n            `nsamples = 2 * X.shape[1] + 2048`.\n\n        l1_reg : \"num_features(int)\", \"auto\" (default for now, but deprecated), \"aic\", \"bic\", or float\n            The l1 regularization to use for feature selection (the estimation procedure is based on\n            a debiased lasso). The auto option currently uses \"aic\" when less that 20% of the possible sample\n            space is enumerated, otherwise it uses no regularization. THE BEHAVIOR OF \"auto\" WILL CHANGE\n            in a future version to be based on num_features instead of AIC.\n            The \"aic\" and \"bic\" options use the AIC and BIC rules for regularization.\n            Using \"num_features(int)\" selects a fix number of top features. Passing a float directly sets the\n            \"alpha\" parameter of the sklearn.linear_model.Lasso model used for feature selection.\n\n        gc_collect : bool\n           Run garbage collection after each explanation round. Sometime needed for memory intensive explanations (default False).\n\n        Returns\n        -------\n        array or list\n            For models with a single output this returns a matrix of SHAP values\n            (# samples x # features). Each row sums to the difference between the model output for that\n            sample and the expected value of the model output (which is stored as expected_value\n            attribute of the explainer). For models with vector outputs this returns a list\n            of such matrices, one for each output.\n        \"\"\"\n\n        #         # convert dataframes\n        #         if str(type(X)).endswith(\"pandas.core.series.Series'&gt;\"):\n        #             X = X.values\n        #         elif str(type(X)).endswith(\"'pandas.core.frame.DataFrame'&gt;\"):\n        #             if self.keep_index:\n        #                 index_value = X.index.values\n        #                 index_name = X.index.name\n        #                 column_name = list(X.columns)\n        #             X = X.values\n\n        #         x_type = str(type(X))\n        #         arr_type = \"'numpy.ndarray'&gt;\"\n        #         # if sparse, convert to lil for performance\n        #         if sp.sparse.issparse(X) and not sp.sparse.isspmatrix_lil(X):\n        #             X = X.tolil()\n        #         assert x_type.endswith(arr_type) or sp.sparse.isspmatrix_lil(X), \"Unknown instance type: \" + x_type\n        #         assert len(X.shape) == 1 or len(X.shape) == 2, \"Instance must have 1 or 2 dimensions!\"\n        from scipy.sparse import issparse\n        \n        X = adata.X\n        if issparse(X):\n            X = X.A\n        # index_value = adata.obs_names.values.tolist()\n        # index_value = np.arange(adata.shape[0])\n        # index_name = adata.obs_names.values\n        index_value = adata.to_df().index.values\n        index_name = adata.to_df().index.name\n        column_name = adata.var_names.tolist()\n\n        # single instance\n        if len(X.shape) == 1:\n            raise \"Unsupported, fuck you!\"\n        if X.shape[0] == 1:\n            data = X.reshape((1, X.shape[1]))\n            if self.keep_index:\n                data = convert_to_instance_with_index(\n                    data, column_name, index_name, index_value\n                )\n\n            # Edited to pass index manually\n            explanation = self.explain(data, index_hardcode=index_value, **kwargs)\n\n            # # vector-output\n            # s = explanation.shape\n            # if len(s) == 2:\n            #     outs = [np.zeros(s[0]) for j in range(s[1])]\n            #     for j in range(s[1]):\n            #         outs[j] = explanation[:, j]\n            #     return outs\n\n            # # single-output\n            # else:\n            #     out = np.zeros(s[0])\n            #     out[:] = explanation\n            #     return out\n\n        # explain the whole dataset\n        elif len(X.shape) == 2:\n            raise \"Unsupported, fuck you!\"\n            # explanations = []\n            # for i in tqdm(range(X.shape[0]), disable=kwargs.get(\"silent\", False)):\n            #     data = X[i : i + 1, :]\n            #     if self.keep_index:\n            #         data = convert_to_instance_with_index(\n            #             data, column_name, index_value[i : i + 1], index_name\n            #         )\n            #     explanations.append(self.explain(data, **kwargs))\n            #     if kwargs.get(\"gc_collect\", False):\n            #         gc.collect()\n\n            # # vector-output\n            # s = explanations[0].shape\n            # if len(s) == 2:\n            #     outs = [np.zeros((X.shape[0], s[0])) for j in range(s[1])]\n            #     for i in range(X.shape[0]):\n            #         for j in range(s[1]):\n            #             outs[j][i] = explanations[i][:, j]\n            #     return outs\n\n            # # single-output\n            # else:\n            #     out = np.zeros((X.shape[0], s[0]))\n            #     for i in range(X.shape[0]):\n            #         out[i] = explanations[i]\n            #     return out\n\n\ndef run_predict(X):\n    if X.shape[0] != 1:\n        X_anndata = AnnData(X)\n        X_anndata.layers['counts'] = X\n        X_anndata.obs['batch'] = list(mouse_dataset_df.loc[X.index,'_Batch'])\n        X_anndata.obs['ct'] = np.repeat('Unknown', repeats=X_anndata.n_obs)\n        scvi.model.SCANVI.setup_anndata(X_anndata, labels_key = 'ct', unlabeled_category='Unknown', batch_key = 'batch')\n        return lvae.predict(X_anndata, soft = True)\n    else:\n        X_index = X.index\n        X = np.tile(X,(2,1))\n        X_anndata = AnnData(X)\n        X_anndata.layers['counts'] = X        \n        X_anndata.obs['batch'] = list(mouse_dataset_df.loc[X_index, '_Batch']) * 2\n        X_anndata.obs['ct'] = np.repeat('Unknown', repeats=X_anndata.n_obs)\n        display(mouse_dataset_df.loc[X_index, '_Batch'])\n        scvi.model.SCANVI.setup_anndata(X_anndata, labels_key = 'ct', unlabeled_category='Unknown', batch_key = 'batch')\n        duplicate_prediction =  lvae.predict(X_anndata, soft = True)\n        return duplicate_prediction.iloc[0:1,:]\n\n\nmouse_dataset = lvae.adata.copy()\n\n\nmouse_dataset_df = pd.DataFrame(\n    mouse_dataset.layers['counts'].A,\n    columns=mouse_dataset.var_names,\n)\nmouse_dataset_df.index = mouse_dataset.obs_names\nmouse_dataset_df['_Batch'] = mouse_dataset.obs['batch']\n\n\nexplainer = SCANVIExplainer(run_predict, mouse_dataset[1:10], keep_index=True)\n\n\nshap_values = explainer.shap_values(mouse_dataset[0, :].copy(), n_samples=2)\n\n\nexplainer.expected_value"
  },
  {
    "objectID": "notebooks/08_shap_explainers.html#deepexplainer",
    "href": "notebooks/08_shap_explainers.html#deepexplainer",
    "title": "SHAP explainers for SCANVI",
    "section": "2 DeepExplainer",
    "text": "2 DeepExplainer\nSCANVI requires multiple parameters which are required for SCVI. The codebase tries to propagade them in and call classifier. The logic is as follows:\n\nCreate SHAP object and encode the dataset to 10 dims (specified during training)\nTake the test dataset, encode it and classify\nPropagade though the network, do magic\n\n\nimport shap\n\n\n# data = lvae.adata_manager.create_torch_dataset().data\n# X = data['X']\n\n# rand_idx = np.random.choice(X.shape[0], 1_000, replace=False)\n# X_train = { \n#     'X': torch.from_numpy(X.A[rand_idx]).type(torch.DoubleTensor),\n#     'batch': torch.from_numpy(data['batch'][rand_idx]), \n#     'labels': torch.from_numpy(data['labels'][rand_idx]),\n# }\n\n# rand_idx = range(20,30)\n# X_test = { \n#     'X': torch.from_numpy(X.A[rand_idx]).type(torch.DoubleTensor),\n#     'batch': torch.from_numpy(data['batch'][rand_idx]), \n#     'labels': torch.from_numpy(data['labels'][rand_idx]),\n# }\n\n\n# integrate, to get Z for classification (n_latent)\n# e = PyTorchDeep(lvae.module, lvae.module(X_train)[0]['z'])\n\ne = SCANVIDeep(lvae.module, background)\n\n\n# shap_values = e.shap_values(lvae.module(X_test)[0]['z'])\n\nshap_values = e.shap_values(test)\n\n100%|| 14/14 [07:36&lt;00:00, 32.58s/it]\n\n\n\nshap.summary_plot(\n    shap_values, \n    test['X'], \n    feature_names=lvae.adata.var_names, \n    class_names=lvae.adata.obs.ct.cat.categories\n)\n\n\n\n\n\nfeature_plot(test, shap_values, classes=lvae.adata.obs.ct.cat.categories, features=lvae.adata.var_names, subset=True)\n\n\n\n\n\nfeature_plot(test, shap_values, classes=lvae.adata.obs.ct.cat.categories, features=lvae.adata.var_names, subset=False)"
  },
  {
    "objectID": "notebooks/09_classification_explanation.html",
    "href": "notebooks/09_classification_explanation.html",
    "title": "09 - Classification explanation",
    "section": "",
    "text": "Looks like all the classifiers have their own internal genes for prediction.\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '1,2'\nimport warnings\nfrom numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\nimport anndata\nimport shap\nimport scvi\nimport scgen\nimport pandas as pd\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nfrom upsetplot import UpSet, from_contents, plot\nfrom matplotlib_venn import venn3\n\nscvi.settings.seed = 0\n\n\ndef train_test_group_split(adata: anndata.AnnData, groupby: str):\n    \"\"\"\n    Function to split anndata object 80/20 per group in format\n    required for SCANVIDeep explainer.\n    \"\"\"\n    import torch\n    groups = adata.obs.groupby(groupby)\n    train, test = [], []\n    for _, cells in groups.groups.items():\n        train_test = train_test_split(cells.values, test_size=0.1)\n        \n        train.append(train_test[0])\n        test.append(train_test[1])\n\n    train, test = np.concatenate(train), np.concatenate(test)\n    \n    X_train = {\n        'X': torch.from_numpy(adata[train].layers['counts'].A).type(torch.DoubleTensor),\n        'batch': torch.from_numpy(adata[train].obs.batch.cat.codes.values[:, np.newaxis]),\n        'labels': torch.from_numpy(adata[train].obs.ct.cat.codes.values[:, np.newaxis])\n    }\n\n    X_test = {\n        'X': torch.from_numpy(adata[test].layers['counts'].A).type(torch.DoubleTensor),\n        'batch': torch.from_numpy(adata[test].obs.batch.cat.codes.values[:, np.newaxis]),\n        'labels': torch.from_numpy(adata[test].obs.ct.cat.codes.values[:, np.newaxis])\n    }\n    \n    return train, X_train, test, X_test\n\n[rank: 0] Global seed set to 0\n%run ../scripts/deep_scanvi.py\nmouse = anndata.read_h5ad(\"../results/03_mouse.processed.h5ad\")\nbackground_idx, background, test_idx, test = train_test_group_split(mouse, groupby='ct')"
  },
  {
    "objectID": "notebooks/09_classification_explanation.html#scanvi",
    "href": "notebooks/09_classification_explanation.html#scanvi",
    "title": "09 - Classification explanation",
    "section": "1 1. scANVI",
    "text": "1 1. scANVI\n\ndef get_shap_feature(adata, shaps, clf_name: str):\n    result = []\n    \n    for idx, ct in enumerate(adata.obs.ct.cat.categories):\n        vals = pd.DataFrame(shaps[idx], index=adata.obs_names, columns=adata.var_names)\n        vals['ct'] = adata.obs.ct.cat.codes.values\n        vals = vals.query('ct == @idx').iloc[:, :-1]\n        \n        weights = vals\\\n            .mean(axis=0)\\\n            .sort_values(ascending=False)\\\n            .reset_index()\\\n            .rename(columns={'index':'feature',0:'weight'})\n            # .query('weight &gt; 0.5')\n        \n        weights['ct'] = adata.obs.ct.cat.categories[idx]\n        result.append(weights)\n    \n    result = pd.concat(result)\n    result['clf'] = clf_name\n    \n    return result\n\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\")\n\nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded                             \n\n\n\nshap_values = SCANVIDeep(lvae.module, background).shap_values(test)\n\n 33%|                                                       | 5/15 [04:18&lt;08:41, 52.10s/it]\n\n\n\n# shap.summary_plot(shap_values, test['X'], feature_names=FEATURES, class_names=CATEGORIES)\n\n\nshap_scANVI = get_shap_feature(mouse[test_idx], shap_values, 'scANVI')\n\n\nshap_scANVI\n\n\n\n\n\n\n\n\nfeature\nweight\nct\nclf\n\n\n\n\n0\noosp1\n16.723852\nZygote\nscANVI\n\n\n1\ne330021d16rik\n16.723083\nZygote\nscANVI\n\n\n2\nbtg4\n15.874923\nZygote\nscANVI\n\n\n3\nzbed3\n15.021937\nZygote\nscANVI\n\n\n4\ne330034g19rik\n14.736804\nZygote\nscANVI\n\n\n...\n...\n...\n...\n...\n\n\n2995\ncst3\n-0.025896\nE4.5-PrE\nscANVI\n\n\n2996\ngpx2\n-0.030260\nE4.5-PrE\nscANVI\n\n\n2997\nglipr1\n-0.044704\nE4.5-PrE\nscANVI\n\n\n2998\ncyp4f14\n-0.047850\nE4.5-PrE\nscANVI\n\n\n2999\ns100g\n-0.064436\nE4.5-PrE\nscANVI\n\n\n\n\n45000 rows  4 columns"
  },
  {
    "objectID": "notebooks/09_classification_explanation.html#xgboost",
    "href": "notebooks/09_classification_explanation.html#xgboost",
    "title": "09 - Classification explanation",
    "section": "2 2. XGBoost",
    "text": "2 2. XGBoost\n\ndef get_shap_features_from_explainer(adata, shaps, clf_name: str):\n    \n    result = []\n    for idx, ct in enumerate(adata.obs.ct.cat.categories):\n        vals = pd.DataFrame(shaps[:, :, idx].values, index=adata.obs_names, columns=adata.var_names)\n        vals['ct'] = adata.obs.ct.cat.codes.values\n        vals = vals.query('ct == @idx').iloc[:, :-1]\n        \n        weights = vals\\\n            .mean(axis=0)\\\n            .sort_values(ascending=False)\\\n            .reset_index()\\\n            .rename(columns={'index':'feature',0:'weight'})\n            # .query('weight &gt; 0.5')\n        \n        weights['ct'] = adata.obs.ct.cat.categories[idx]\n        result.append(weights)\n\n    result = pd.concat(result)\n    result['clf'] = clf_name\n    \n    return result\n\n\n2.1 2.1. scVI\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi\")\nxg_clf = xgb.XGBClassifier()\nxg_clf.load_model(\"../results/05_scVI_xgboost.json\")\n\nshap_values = shap.GPUTreeExplainer(xg_clf)(vae.get_normalized_expression(return_mean=True).values, check_additivity=False)\nshap_xg_scVI = get_shap_features_from_explainer(mouse, shap_values, 'xg_scVI')\n\n\n\n2.2 2.2. scANVI\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi/\")\nxg_clf = xgb.XGBClassifier()\nxg_clf.load_model(\"../results/05_scANVI_xgboost.json\")\n\nshap_values = shap.GPUTreeExplainer(xg_clf)(lvae.get_normalized_expression(return_mean=True).values, check_additivity=False)\nshap_xg_scANVI = get_shap_features_from_explainer(mouse, shap_values, 'xg_scANVI')\n\n\n\n2.3 2.3. scGEN\n\nmscgen = scgen.SCGEN.load(\"../results/02_mouse_integration/scgen/\")\nxg_clf = xgb.XGBClassifier()\nxg_clf.load_model(\"../results/05_scGEN_xgboost.json\")\n\nshap_values = shap.GPUTreeExplainer(xg_clf)(mscgen.get_decoded_expression(), check_additivity=False)\nshap_xg_scGEN = get_shap_features_from_explainer(mouse, shap_values, 'xg_scGEN')\n\n\n# xg_clfs = pd.concat([shap_scANVI, shap_xg_scVI, shap_xg_scANVI, shap_xg_scGEN], ignore_index=True)\n# xg_clfs.to_feather(\"../results/09_clf.feather\")\n# xg_clfs\n\n\nxg_clfs = pd.read_feather(\"../results/09_clf.feather\")\n\n\npos = xg_clfs.query('weight &gt; 0').groupby('clf')['feature'].apply(set).to_dict()\nneg = xg_clfs.query('weight &lt; 0').groupby('clf')['feature'].apply(set).to_dict()\n\n\nfig = plt.figure(figsize=(10, 4))\nfig.suptitle('Positive weights')\n_ = plot(from_contents(pos), fig=fig, element_size=None, show_counts=True)\n\nfig = plt.figure(figsize=(10, 4))\nfig.suptitle('Negative weights')\n_ = plot(from_contents(neg), fig=fig, element_size=None, show_counts=True)"
  },
  {
    "objectID": "notebooks/09_classification_explanation.html#comparisons",
    "href": "notebooks/09_classification_explanation.html#comparisons",
    "title": "09 - Classification explanation",
    "section": "3 Comparisons",
    "text": "3 Comparisons\n\ndef run_clf_scanvi(clf, adata, clf_name: str, n: int=10) -&gt; pd.DataFrame:\n    results = []\n    \n    for i in tqdm(range(n)):\n        background_idx, background, test_idx, test = train_test_group_split(adata, groupby='ct')\n        shap_values = SCANVIDeep(clf.module, background).shap_values(test)\n        weights = get_shap_feature(mouse[test_idx], shap_values, 'scANVI')\n        weights['iteration'] = i + 1\n        results.append(weights)\n    res = pd.concat(results)\n\n    res_means = pd.DataFrame(res.query('weight &gt; 0').groupby(['ct', 'feature']).weight.mean())\n    res_means['n'] = res.query('weight &gt; 0').groupby(['ct', 'feature']).count().loc[res_means.index, 'iteration']\n    res_means = res_means.query('n == @n')\n    res_th = res.query('weight &gt; 0').groupby(['clf', 'ct']).weight.quantile(0.9).unstack().T\n    res_means = pd.merge(res_means.reset_index(), res_th, left_on='ct', right_index=True)\n    res_means = res_means[res_means['weight'] &gt;= res_means[clf_name]]\n\n    return res\n\ndef run_clf(clf, adata, sampler, clf_name: str, n: int=10) -&gt; pd.DataFrame:\n    \"\"\"\n    This function runs GPUTreeExplainer on XGBoost classifiers to extract SHAP values.\n    For each class, we take features which have &gt;0 contribution (weight) for the prediction.\n    To make sure each feature is consistent, it has to occur n-times during bootstrap.\n    From the remaining features which comply with the above filter, we calculate 90% quantile\n    and keep only those features as the core predictors of a class.\n\n    clf:\n        XGBoost classifier\n    adata:\n        Dataset h5ad\n    sampler:\n        Decoder for estimating denoised expression\n    clf_name:\n        Name of the classifier (which latent space)\n    n: \n        Number of bootstraps\n    \"\"\"\n    results = []\n    \n    for i in tqdm(range(n)):\n        if type(sampler) is scgen._scgen.SCGEN:\n            X = sampler.get_decoded_expression()\n        else:\n            X = sampler.get_normalized_expression(return_mean=True).values\n        shap_values = shap.GPUTreeExplainer(clf)(X, check_additivity=False)\n        weights = get_shap_features_from_explainer(adata, shap_values, clf_name)\n        weights['iteration'] = i + 1\n        results.append(weights)\n    res = pd.concat(results)\n\n    res_means = pd.DataFrame(res.query('weight &gt; 0').groupby(['ct', 'feature']).weight.mean())\n    res_means['n'] = res.query('weight &gt; 0').groupby(['ct', 'feature']).count().loc[res_means.index, 'iteration']\n    res_means = res_means.query('n == @n')\n    res_th = res.query('weight &gt; 0').groupby(['clf', 'ct']).weight.quantile(0.9).unstack().T\n    res_means = pd.merge(res_means.reset_index(), res_th, left_on='ct', right_index=True)\n    res_means = res_means[res_means['weight'] &gt;= res_means[clf_name]]\n\n    return res_means\n\n\n3.1 3.1. XGBoost UpSet plots\nImportant features from XGBoost are almost unique for each classifier.\n\nvae = scvi.model.SCVI.load(\"../results/02_mouse_integration/scvi\")\nxg_clf = xgb.XGBClassifier()\nxg_clf.load_model(\"../results/05_scVI_xgboost.json\")\nxg_scVI = run_clf(xg_clf, mouse, vae, 'xg_scVI')\n\n\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi\")\nxg_clf = xgb.XGBClassifier()\nxg_clf.load_model(\"../results/05_scANVI_xgboost.json\")\nxg_scANVI = run_clf(xg_clf, mouse, lvae, 'xg_scANVI')\n\n\nmscgen = scgen.SCGEN.load(\"../results/02_mouse_integration/scgen/\")\nxg_clf = xgb.XGBClassifier()\nxg_clf.load_model(\"../results/05_scGEN_xgboost.json\")\nxg_scGEN = run_clf(xg_clf, mouse, mscgen, 'xg_scGEN')\n\n\npd.concat([xg_scVI, xg_scANVI, xg_scGEN], ignore_index=True).to_feather(\"../results/09_xg_shap_features_n_10.feather\")\n\n\nxg_shaps = pd.read_feather(\"../results/09_xg_shap_features_n_10.feather\")\nxg_shaps['clf'] = xg_shaps.fillna(0)[['xg_scVI', 'xg_scANVI', 'xg_scGEN']].idxmax(axis=1, skipna=True)\nxg_shaps\n\n\n\n\n\n\n\n\nct\nfeature\nweight\nn\nxg_scVI\nxg_scANVI\nxg_scGEN\nclf\n\n\n\n\n0\n16C\narid5b\n0.574749\n10\n0.087677\nNaN\nNaN\nxg_scVI\n\n\n1\n16C\nbcat1\n0.993409\n10\n0.087677\nNaN\nNaN\nxg_scVI\n\n\n2\n16C\nbmyc\n0.097852\n10\n0.087677\nNaN\nNaN\nxg_scVI\n\n\n3\n16C\ngm26542\n0.123040\n10\n0.087677\nNaN\nNaN\nxg_scVI\n\n\n4\n16C\ngm45564\n0.117891\n10\n0.087677\nNaN\nNaN\nxg_scVI\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n223\nE4.5-PrE\nsox7\n2.043959\n10\nNaN\nNaN\n0.695141\nxg_scGEN\n\n\n224\nE4.5-TE\nddias\n1.565134\n10\nNaN\nNaN\n0.752304\nxg_scGEN\n\n\n225\nE4.5-TE\nrnd3\n0.752304\n10\nNaN\nNaN\n0.752304\nxg_scGEN\n\n\n226\nZygote\ngm15913\n2.330400\n10\nNaN\nNaN\n1.279902\nxg_scGEN\n\n\n227\nZygote\ngm23020\n1.279902\n10\nNaN\nNaN\n1.279902\nxg_scGEN\n\n\n\n\n228 rows  8 columns\n\n\n\n\nfig, ax = plt.subplots(5, 3, figsize=[20, 20])\nfor idx, ct in enumerate(mouse.obs.ct.cat.categories):\n    data = xg_shaps.query('ct == @ct').groupby('clf')['feature'].apply(set)\n    venn3(data.values, set_labels=data.keys(), ax=ax[idx // 3, idx % 3])\n    ax[idx // 3, idx % 3].set_title(ct)\n\n\n\n\n\nfor ct in mouse.obs.ct.cat.categories:\n    fig = plt.figure(figsize=(5, 4))\n    fig.suptitle(ct)\n    data = xg_shaps.query('ct == @ct').groupby('clf')['feature'].apply(set).to_dict()\n    # display(data)\n    _ = plot(from_contents(data), fig=fig, element_size=None, show_counts=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 3.2. scANVI\n\nshap_scANVI = run_clf_scanvi(lvae, mouse, 'scANVI', n=10)\nshap_scANVI.to_feather(\"../results/09_scanvi_shap_features_n_10.feather\")\n\n\n\n\n\n  0%|                                                                                           | 0/15 [00:00&lt;?, ?it/s]\n  7%|                                                                             | 1/15 [00:46&lt;10:49, 46.41s/it]\n 13%|                                                                        | 2/15 [01:31&lt;09:56, 45.85s/it]\n 20%|                                                                  | 3/15 [02:17&lt;09:07, 45.63s/it]\n 27%|                                                            | 4/15 [03:03&lt;08:24, 45.84s/it]\n 33%|                                                       | 5/15 [03:47&lt;07:32, 45.27s/it]\n 40%|                                                 | 6/15 [04:31&lt;06:43, 44.85s/it]\n 47%|                                            | 7/15 [05:15&lt;05:56, 44.62s/it]\n 53%|                                      | 8/15 [05:59&lt;05:11, 44.43s/it]\n 60%|                                 | 9/15 [06:44&lt;04:26, 44.38s/it]\n 67%|                           | 10/15 [07:28&lt;03:41, 44.29s/it]\n 73%|                     | 11/15 [08:13&lt;02:58, 44.54s/it]\n 80%|                | 12/15 [08:57&lt;02:13, 44.43s/it]\n 87%|           | 13/15 [09:41&lt;01:28, 44.38s/it]\n 93%|     | 14/15 [10:26&lt;00:44, 44.43s/it]\n100%|| 15/15 [11:10&lt;00:00, 44.73s/it]\n\n  0%|                                                                                           | 0/15 [00:00&lt;?, ?it/s]\n  7%|                                                                             | 1/15 [00:45&lt;10:37, 45.52s/it]\n 13%|                                                                        | 2/15 [01:31&lt;09:52, 45.54s/it]\n 20%|                                                                  | 3/15 [02:16&lt;09:06, 45.58s/it]\n 27%|                                                            | 4/15 [03:01&lt;08:16, 45.13s/it]\n 33%|                                                       | 5/15 [03:45&lt;07:27, 44.79s/it]\n 40%|                                                 | 6/15 [04:30&lt;06:44, 44.91s/it]\n 47%|                                            | 7/15 [05:14&lt;05:57, 44.72s/it]\n 53%|                                      | 8/15 [05:59&lt;05:13, 44.72s/it]\n 60%|                                 | 9/15 [06:44&lt;04:28, 44.67s/it]\n 67%|                           | 10/15 [07:29&lt;03:44, 44.83s/it]\n 73%|                     | 11/15 [08:13&lt;02:59, 44.78s/it]\n 80%|                | 12/15 [08:58&lt;02:13, 44.66s/it]\n 87%|           | 13/15 [09:42&lt;01:29, 44.57s/it]\n 93%|     | 14/15 [10:27&lt;00:44, 44.53s/it]\n100%|| 15/15 [11:11&lt;00:00, 44.76s/it]\n\n  0%|                                                                                           | 0/15 [00:00&lt;?, ?it/s]\n  7%|                                                                             | 1/15 [00:43&lt;10:10, 43.59s/it]\n 13%|                                                                        | 2/15 [01:27&lt;09:32, 44.03s/it]\n 20%|                                                                  | 3/15 [02:11&lt;08:44, 43.68s/it]\n 27%|                                                            | 4/15 [02:56&lt;08:07, 44.32s/it]\n 33%|                                                       | 5/15 [03:50&lt;07:57, 47.74s/it]\n 40%|                                                 | 6/15 [04:45&lt;07:33, 50.44s/it]\n 47%|                                            | 7/15 [05:39&lt;06:50, 51.29s/it]\n 53%|                                      | 8/15 [06:24&lt;05:45, 49.29s/it]\n 60%|                                 | 9/15 [07:09&lt;04:49, 48.20s/it]\n 67%|                           | 10/15 [07:54&lt;03:56, 47.23s/it]\n 73%|                     | 11/15 [08:39&lt;03:06, 46.54s/it]\n 80%|                | 12/15 [09:24&lt;02:18, 46.06s/it]\n 87%|           | 13/15 [10:09&lt;01:31, 45.73s/it]\n 93%|     | 14/15 [10:54&lt;00:45, 45.51s/it]\n100%|| 15/15 [11:39&lt;00:00, 46.64s/it]\n\n  0%|                                                                                           | 0/15 [00:00&lt;?, ?it/s]\n  7%|                                                                             | 1/15 [00:45&lt;10:40, 45.73s/it]\n 13%|                                                                        | 2/15 [01:33&lt;10:07, 46.71s/it]\n 20%|                                                                  | 3/15 [02:27&lt;10:04, 50.41s/it]\n 27%|                                                            | 4/15 [03:21&lt;09:26, 51.50s/it]\n 33%|                                                       | 5/15 [04:22&lt;09:09, 54.99s/it]\n 40%|                                                 | 6/15 [05:13&lt;08:04, 53.79s/it]\n 47%|                                            | 7/15 [05:59&lt;06:49, 51.24s/it]\n 53%|                                      | 8/15 [06:47&lt;05:51, 50.16s/it]\n 60%|                                 | 9/15 [07:35&lt;04:56, 49.40s/it]\n 67%|                           | 10/15 [08:22&lt;04:04, 48.80s/it]\n 73%|                     | 11/15 [09:16&lt;03:21, 50.45s/it]\n 80%|                | 12/15 [10:02&lt;02:26, 48.86s/it]\n 87%|           | 13/15 [10:47&lt;01:35, 47.72s/it]\n 93%|     | 14/15 [11:32&lt;00:46, 46.96s/it]\n100%|| 15/15 [12:18&lt;00:00, 49.24s/it]\n\n  0%|                                                                                           | 0/15 [00:00&lt;?, ?it/s]\n  7%|                                                                             | 1/15 [00:43&lt;10:15, 43.99s/it]\n 13%|                                                                        | 2/15 [01:27&lt;09:24, 43.42s/it]\n 20%|                                                                  | 3/15 [02:09&lt;08:38, 43.20s/it]\n 27%|                                                            | 4/15 [02:55&lt;08:03, 43.94s/it]\n 33%|                                                       | 5/15 [03:45&lt;07:42, 46.28s/it]\n 40%|                                                 | 6/15 [04:37&lt;07:12, 48.09s/it]\n 47%|                                            | 7/15 [05:32&lt;06:43, 50.41s/it]\n 53%|                                      | 8/15 [06:27&lt;06:03, 51.96s/it]\n 60%|                                 | 9/15 [07:21&lt;05:16, 52.72s/it]\n\n\n\nshap_scANVI = pd.read_feather(\"../results/09_scanvi_shap_features_n_10.feather\")\nshap_scANVI['clf'] = 'scANVI'\n\n\nshap_scANVI_with_xg = pd.concat([shap_scANVI, xg_shaps])\n\n\nfor ct in mouse.obs.ct.cat.categories:\n    fig = plt.figure(figsize=(8, 4))\n    fig.suptitle(ct)\n    data = shap_scANVI_with_xg.query('ct == @ct').groupby('clf')['feature'].apply(set).to_dict()\n    # display(data)\n    _ = plot(from_contents(data), fig=fig, element_size=None, show_counts=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3 3.x. XGBoost plotting trees\n\nxg_clf.best_ntree_limit\n\n\nxg_clf.best_iteration\n\n\nxgb.plot_importance(xg_clf, max_num_features=20)\n\n\nxg_clf.get_booster().feature_names = mouse.var_names.tolist()\n\n\nfig, ax = plt.subplots(figsize=(30, 30))\nxgb.plot_tree(xg_clf, num_trees=xg_clf.best_ntree_limit, ax=ax)\nplt.show()"
  },
  {
    "objectID": "notebooks/10_mouse_beyond_celltypes.html",
    "href": "notebooks/10_mouse_beyond_celltypes.html",
    "title": "05 - mouse classifier",
    "section": "",
    "text": "In this notebook we test what happens if we go beyond the preimplantation development and how does the scANVI deal with the annotation\n!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\n%matplotlib inline\n\nimport scvi\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport scanpy as sc\nimport matplotlib.pyplot as plt\n\nfrom typing import Tuple\n\nfrom numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\nimport warnings\n\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\nscvi.settings.seed = 0\n\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '3'\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n[rank: 0] Global seed set to 0\nlvae = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\")\n\nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded"
  },
  {
    "objectID": "notebooks/10_mouse_beyond_celltypes.html#nowotschin-et-al.-until-e6.5",
    "href": "notebooks/10_mouse_beyond_celltypes.html#nowotschin-et-al.-until-e6.5",
    "title": "05 - mouse classifier",
    "section": "1 Nowotschin et al., until E6.5",
    "text": "1 Nowotschin et al., until E6.5\n\nquery = sc.read(\"../data/external/Nowotschin_et_al_2019/sc_endoderm_all_cells.h5ad\")\nquery.var_names = query.var_names.str.lower()\nmeta = pd.read_csv(\"../data/external/Nowotschin_et_al_2019/e35_cell_types.csv\", index_col=0)\n\n\nquery = query[query.obs.Timepoint.isin(['E3.5', 'E4.5', 'E5.5', 'E6.5'])].copy()\nquery.obs.CellType = query.obs.CellType.astype(str)\nquery.obs.loc[meta.index, 'CellType'] = meta.CellType\n\n\nquery.obs['experiment'] = 'Nowotschin et al., 2019'\nquery.layers['counts'] = query.X\nquery.obs['batch'] = query.obs.Timepoint\n# query.obs['ct'] = query.obs[['Timepoint', 'CellType']].agg('-'.join, axis=1)"
  },
  {
    "objectID": "notebooks/10_mouse_beyond_celltypes.html#query",
    "href": "notebooks/10_mouse_beyond_celltypes.html#query",
    "title": "05 - mouse classifier",
    "section": "2 Query",
    "text": "2 Query\nIf going beyond annotation, it will throw an error\nIf we set query.obs['ct'] = query.obs[['Timepoint', 'CellType']].agg('-'.join, axis=1) we get an error\nValueError: Category E5.5-EPI not found in source registry. Cannot transfer setup without `extend_categories = True`.\nRef: https://discourse.scverse.org/t/dont-extend-labels-for-query-data/1196/2\n\nscvi.model.SCVI.prepare_query_anndata(query, lvae)\nlvae_q = scvi.model.SCANVI.load_query_data(query, lvae)\nlvae_q.train(\n    max_epochs=100,\n    plan_kwargs=dict(weight_decay=0.0),\n    check_val_every_n_epoch=10,\n    # early_stopping=True\n)\n\nquery.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nquery.obs[\"predictions\"] = lvae_q.predict()\nquery.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\nINFO     Found 77.63333333333333% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nEpoch 100/100: 100%|| 100/100 [05:35&lt;00:00,  3.38s/it, v_num=1, train_loss_step=1.55e+3, train_loss_epoch=1.58e+3]Epoch 100/100: 100%|| 100/100 [05:35&lt;00:00,  3.36s/it, v_num=1, train_loss_step=1.55e+3, train_loss_epoch=1.58e+3]\n\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n\n\n\nquery.obs['orig'] = query.obs[['Timepoint', 'CellType']].agg('-'.join, axis=1)\n\n\n_ = sns.heatmap(sc.metrics.confusion_matrix('orig', 'predictions', data=query.obs), cmap='Greys', square=True, linewidth=0.2, linecolor='black').set(ylabel='Original', xlabel='Predicted', title='Nowotschin et al., 2019 [E3.5 - E6.5]')"
  },
  {
    "objectID": "notebooks/11_human_query_Smith.html",
    "href": "notebooks/11_human_query_Smith.html",
    "title": "Austin Smith paper",
    "section": "",
    "text": "%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport scvi\nimport scanpy as sc\nimport scanpy.external as sce\nimport scFates as scf\nimport matplotlib.pyplot as plt\n\nimport warnings\nfrom numba.core.errors import NumbaDeprecationWarning\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\nsc.set_figure_params(figsize=(10, 6))\n\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n%config InlineBackend.figure_format='retina'"
  },
  {
    "objectID": "notebooks/11_human_query_Smith.html#austin-smith-dataset",
    "href": "notebooks/11_human_query_Smith.html#austin-smith-dataset",
    "title": "Austin Smith paper",
    "section": "1 Austin Smith dataset",
    "text": "1 Austin Smith dataset\n\nAS_MATRIX_URL = \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE166nnn/GSE166422/matrix/GSE166422_series_matrix.txt.gz\"\n\n\nmetadata = pd.read_table(AS_MATRIX_URL, skiprows=27, index_col = 0).T\n\n\nmetadata['ID_REF'].to_csv('../pipeline/fetchngs/human_GSE166422.tsv', index=None, header=None, sep='\\t')"
  },
  {
    "objectID": "notebooks/11_human_query_Smith.html#fetch-ngs",
    "href": "notebooks/11_human_query_Smith.html#fetch-ngs",
    "title": "Austin Smith paper",
    "section": "2 fetch-ngs",
    "text": "2 fetch-ngs\nnf-core_tower.sh Guo_2021 \\\n    nextflow run nf-core/fetchngs \\\n    -r 1.11.0 \\\n    --input /projects/dan1/data/Brickman/projects/proks-salehin-et-al-2023/pipeline/fetchngs/human_GSE166422.tsv"
  },
  {
    "objectID": "notebooks/11_human_query_Smith.html#dataset-preprocessing",
    "href": "notebooks/11_human_query_Smith.html#dataset-preprocessing",
    "title": "Austin Smith paper",
    "section": "3 Dataset preprocessing",
    "text": "3 Dataset preprocessing\n\nadata_rivron = sc.read('../data/external/aligned/human/rivron_2022_reprocessed.h5ad')\n\n\nadata_rivron\n\n\ngtf = pd.read_table(\"../data/external/human/Homo_sapiens.GRCh38.110.gene_length.tsv\", index_col=0)\ngene_lengths = gtf[['median']].copy()\ngene_lengths.columns = ['length']\ndef normalize_smartseq(adata: sc.AnnData, gene_len: pd.DataFrame) -&gt; sc.AnnData:\n    print(\"SMART-SEQ: Normalization\")\n\n    common_genes = adata.var_names.intersection(gene_len.index)\n    print(f\"SMART-SEQ: Common genes {common_genes.shape[0]}\")\n\n    lengths = gene_len.loc[common_genes, \"length\"].values\n    normalized = sc.AnnData(adata[:, common_genes].X, obs=adata.obs, dtype=np.float32)\n    normalized.var_names = common_genes\n    normalized.X = normalized.X / lengths * np.median(lengths)\n    normalized.X = np.rint(normalized.X)\n\n    return normalized\n\n\nnormalize_smartseq(adata_rivron, gene_lengths)\n\n\nmetadata_rivron = adata_rivron.obs\n\n\nmetadata_rivron_clean = metadata_rivron.loc[:,['sample']]\n\n\nmetadata_rivron_clean['sample_title'] = metadata_rivron.sample_title.str.extract(r'^(.*)-', expand = False)\n\n\nmetadata_rivron_clean.sample_title.unique()\n\n\nmetadata_rivron_clean = metadata_rivron_clean.loc[metadata_rivron_clean.sample_title.isin(['blastoid 96h TROP2 pl', 'naive H9', 'blastoid 24h', 'blastoid 60h TROP2 pl', 'blastoid 60h TROP2 min', 'blastoid 96h DN', 'blastoid 96h PDGFRa pl', 'blastoid 60h PDGFRa pl'])].copy()\n\n\nmetadata_rivron_clean['batch'] = 'Rivron'\nmetadata_rivron_clean['time'] = metadata_rivron_clean['sample_title']\nmetadata_rivron_clean['flow'] = metadata_rivron_clean['sample_title']\n\n\ntime_replace_dict = {\n    'naive H9': '0h',\n    'blastoid 24h': '24h',\n    'blastoid 60h TROP2 pl': '60h',\n    'blastoid 60h TROP2 min': '60h',\n    'blastoid 60h PDGFRa pl': '60h',\n    'blastoid 96h DN': '96h',\n    'blastoid 96h PDGFRa pl': '96h',\n    'blastoid 96h TROP2 pl': '96h'\n}\n\nflow_replace_dict = {\n    'naive H9': 'naive',\n    'blastoid 24h': 'na',\n    'blastoid 60h TROP2 pl': 'TROP2+',\n    'blastoid 60h TROP2 min': 'TROP2-',\n    'blastoid 60h PDGFRa pl': 'PDGFRA+',\n    'blastoid 96h DN': 'Double-neg',\n    'blastoid 96h PDGFRa pl': 'PDGFRA+',\n    'blastoid 96h TROP2 pl': 'TROP2+'\n}\n\nmetadata_rivron_clean = metadata_rivron_clean.replace({'time': time_replace_dict, 'flow': flow_replace_dict})\n\n\nadata_rivron = adata_rivron[metadata_rivron_clean.index].copy()\n\n\nadata_rivron.obs = metadata_rivron_clean\n\n\nadata_rivron\n\n\nadata_rivron.var['mt'] = adata_rivron.var.gene_symbol.str.startswith('MT-')\n\n\n\nsc.pp.calculate_qc_metrics(adata_rivron, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n\n\nsns.violinplot(y=adata_rivron.obs['pct_counts_mt'], orient='v')\n\n\nadata_rivron.obs\n\n\nsns.scatterplot(x='total_counts', y='n_genes_by_counts', data=adata_rivron.obs, hue='batch')\n\n\nadata_rivron = adata_rivron[adata_rivron.obs.pct_counts_mt &lt; 12.5].copy()\nsc.pp.filter_cells(adata_rivron, min_counts=2.5e5)\nsc.pp.filter_cells(adata_rivron, max_counts=2.5e6)\nsc.pp.filter_cells(adata_rivron, min_genes=2_000)\nadata_rivron.layers[\"counts\"] = adata_rivron.X.copy()\nsc.pp.normalize_total(adata_rivron, target_sum=10_000)\nsc.pp.log1p(adata_rivron)\nadata_rivron.raw = adata_rivron\n\n\n# remove mitochondrial genes\nadata_rivron = adata_rivron[:, adata_rivron.var[~adata_rivron.var.gene_symbol.str.startswith('MT-')].index].copy()\n\n# remove ribosomal genes\nadata_rivron = adata_rivron[:, adata_rivron.var[~adata_rivron.var.gene_symbol.str.startswith(('RPS', 'RPL'))].index].copy()\n\n\nadata_rivron.write_h5ad('../results/06_human_Rivron.h5ad')\n\n\nquery = sc.read_h5ad('../results/06_human_Rivron.h5ad')\nquery.obs['experiment'] = 'Rivron'\nquery\n\n\nlvae = scvi.model.SCANVI.load(\"../results/02_human_integration/05_scanvi_ns15/\")\n#lvae = scvi.model.SCANVI.load(\"../results/deprecated/human_integration/version_1/scanvi/\")\n\n\nscvi.model.SCVI.prepare_query_anndata(query, lvae)\n\n\nlvae_q = scvi.model.SCANVI.load_query_data(query, lvae)\n\n\nlvae_q.train(\n    max_epochs=100,\n    plan_kwargs=dict(weight_decay=0.0),\n    check_val_every_n_epoch=10,\n    early_stopping=True\n)\n\n\nquery.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nquery.obs[\"predictions\"] = lvae_q.predict()\nquery.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\n\npd.crosstab(query.obs.predictions, query.obs.flow)\n\n\npd.crosstab(query.obs.predictions, query.obs.time)\n\n\nsc.pp.highly_variable_genes(\n    query,\n    flavor=\"seurat_v3\",\n    n_top_genes=5_000,\n    layer=\"counts\",\n    batch_key=\"batch\",\n    subset=True,\n)\nsc.pp.neighbors(query)\nsc.tl.umap(query)\n\n\nsc.pl.umap(query, color=['predictions','time', 'flow', 'entropy'], ncols=1)"
  },
  {
    "objectID": "notebooks/11_xgboost_vs_scanvi.html",
    "href": "notebooks/11_xgboost_vs_scanvi.html",
    "title": "11 - XGBoost vs scANVI",
    "section": "",
    "text": "In this notebook we compare the accuracy between XGBoost and scANVI\n!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/bin/pip\n%matplotlib inline\n\nimport scvi\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport scanpy as sc\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom typing import Tuple\n\nfrom numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\nimport warnings\n\nwarnings.simplefilter('ignore', category=NumbaDeprecationWarning)\nwarnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\nwarnings.simplefilter('ignore', category=FutureWarning)\nwarnings.simplefilter('ignore', category=UserWarning)\n\nscvi.settings.seed = 0\n\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '3'\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/projects/dan1/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n[rank: 0] Global seed set to 0\nimport anndata\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n\n\ndef cripple_classifiers(adata: anndata.AnnData, lvae: scvi.model.SCANVI, xgb_clf: xgb.XGBClassifier, groupby: str):\n    \"\"\"\n    To prove a point that scANVI is better in term of prediction compared to XGBoost\n    due to it's ability to use full list of HVGs, we sort features (genes) based on\n    their normalized dispertion and remove them during prediction.\n    We expect that if they are not present the XGBoost performance double downs on its\n    performance as it will be missing these features to make a correct prediction.\n    \"\"\"\n\n    denoised = lvae.get_normalized_expression(return_mean=True)\n    features = adata.var.sort_values(by='dispersions_norm', ascending=False).index\n\n    metrics = {\n        'scANVI': { m: [] for m in ['accuracy', 'balanced', 'f1_micro', 'f1_macro'] },\n        'XGBoost': { m: [] for m in ['accuracy', 'balanced', 'f1_micro', 'f1_macro'] }\n    }\n    \n    for i in tqdm([0, 10, 20, 50, 100, 200, 500]):\n        less_features = features[i:]\n\n        # XGBoost prediction\n        xgb_denoised = denoised.copy()\n        if i != 0:\n            xgb_denoised.loc[:, less_features] = 0\n        xgb_pred = xgb_clf.predict(xgb_denoised)\n        \n        # scANVI query\n        subset = adata[:, less_features].copy()\n        subset.obs = subset.obs[['batch']].copy()\n        scvi.model.SCANVI.prepare_query_anndata(subset, lvae)\n        lvae_q = scvi.model.SCANVI.load_query_data(subset, lvae)\n        lvae_q.train(max_epochs=100, plan_kwargs=dict(weight_decay=0.0), check_val_every_n_epoch=10, enable_progress_bar=False)\n        scANVI_pred = lvae_q.predict()\n\n        metrics['scANVI']['accuracy'].append(accuracy_score(adata.obs[groupby], scANVI_pred))\n        metrics['XGBoost']['accuracy'].append(accuracy_score(adata.obs[groupby].cat.codes.values, xgb_pred))\n        \n        metrics['scANVI']['balanced'].append(balanced_accuracy_score(adata.obs[groupby], scANVI_pred))\n        metrics['XGBoost']['balanced'].append(balanced_accuracy_score(adata.obs[groupby].cat.codes.values, xgb_pred))\n\n        metrics['scANVI']['f1_micro'].append(f1_score(adata.obs[groupby], scANVI_pred, average=\"micro\"))\n        metrics['XGBoost']['f1_micro'].append(f1_score(adata.obs[groupby].cat.codes.values, xgb_pred, average=\"micro\"))\n\n        metrics['scANVI']['f1_macro'].append(f1_score(adata.obs[groupby], scANVI_pred, average=\"macro\"))\n        metrics['XGBoost']['f1_macro'].append(f1_score(adata.obs[groupby].cat.codes.values, xgb_pred, average=\"macro\"))\n    \n    return metrics"
  },
  {
    "objectID": "notebooks/11_xgboost_vs_scanvi.html#mouse",
    "href": "notebooks/11_xgboost_vs_scanvi.html#mouse",
    "title": "11 - XGBoost vs scANVI",
    "section": "1 Mouse",
    "text": "1 Mouse\n\n# base dataset\nmouse = sc.read(\"../results/02_mouse_integration/scanvi_ns_15/adata.h5ad\")\n\n# XGBoost\nmouse_xg_scVI = xgb.XGBClassifier()\nmouse_xg_scVI.load_model(\"../results/02_mouse_integration/05_scVI_xgboost.json\")\n\n# scANVI\nmouse_scANVI = scvi.model.SCANVI.load(\"../results/02_mouse_integration/scanvi_ns_15/\")\n\nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded                             \n\n\n\nmouse_stats = cripple_classifiers(mouse, mouse_scANVI, mouse_xg_scVI, groupby='ct')\n\n  0%|                                                                                                              | 0/7 [00:00&lt;?, ?it/s]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 14%|                                                                                       | 1/7 [00:19&lt;01:57, 19.50s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 29%|                                                                        | 2/7 [00:39&lt;01:37, 19.59s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 43%|                                                          | 3/7 [00:59&lt;01:19, 19.78s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 57%|                                           | 4/7 [01:19&lt;00:59, 19.93s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 71%|                             | 5/7 [01:39&lt;00:39, 19.85s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 86%|              | 6/7 [01:58&lt;00:19, 19.85s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n100%|| 7/7 [02:19&lt;00:00, 19.90s/it]\n\n\nINFO     Found 100.0% reference vars in query data.                                                                \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 99.66666666666667% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 99.33333333333333% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 98.33333333333333% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 96.66666666666667% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 93.33333333333333% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 83.33333333333334% reference vars in query data.                                                    \nINFO     Training for 100 epochs."
  },
  {
    "objectID": "notebooks/11_xgboost_vs_scanvi.html#human",
    "href": "notebooks/11_xgboost_vs_scanvi.html#human",
    "title": "11 - XGBoost vs scANVI",
    "section": "2 Human",
    "text": "2 Human\n\n2.1 XGBoost [scANVI]\n\n%run ../scripts/helpers.py\n\n\n# base dataset\nhuman = sc.read(\"../results/02_human_integration/05_scanvi_ns15/adata.h5ad\")\n\n\nvae = scvi.model.SCVI.load(\"../results/02_human_integration/scvi/\")\nvae_df = pd.DataFrame(vae.get_normalized_expression(return_mean=True))\nvae_df['target'] = human.obs.C_scANVI_nsamples\n\nX_train, y_train, X_test, y_test = train_test_split_by_group(vae_df)\nvae_xgboost = train_xgboost(vae_df, X_train, y_train, X_test, y_test)\nvae_xgboost.save_model(\"../results/02_human_integration/11_scVI_xgboost.json\")\n\nINFO     File ../results/02_human_integration/scvi/model.pt already downloaded                                     \n[0] validation_0-merror:0.06048 validation_0-mlogloss:1.25520   validation_1-merror:0.22081 validation_1-mlogloss:1.52118\n[1] validation_0-merror:0.03240 validation_0-mlogloss:0.89775   validation_1-merror:0.18471 validation_1-mlogloss:1.22860\n[2] validation_0-merror:0.01674 validation_0-mlogloss:0.66799   validation_1-merror:0.18471 validation_1-mlogloss:1.04108\n[3] validation_0-merror:0.01242 validation_0-mlogloss:0.50784   validation_1-merror:0.16985 validation_1-mlogloss:0.89968\n[4] validation_0-merror:0.00756 validation_0-mlogloss:0.39042   validation_1-merror:0.16561 validation_1-mlogloss:0.79915\n[5] validation_0-merror:0.00486 validation_0-mlogloss:0.30346   validation_1-merror:0.16348 validation_1-mlogloss:0.71425\n[6] validation_0-merror:0.00162 validation_0-mlogloss:0.23622   validation_1-merror:0.15711 validation_1-mlogloss:0.64952\n[7] validation_0-merror:0.00108 validation_0-mlogloss:0.18595   validation_1-merror:0.16136 validation_1-mlogloss:0.60371\n[8] validation_0-merror:0.00000 validation_0-mlogloss:0.14786   validation_1-merror:0.15287 validation_1-mlogloss:0.56304\n[9] validation_0-merror:0.00000 validation_0-mlogloss:0.11881   validation_1-merror:0.15287 validation_1-mlogloss:0.53307\n[10]    validation_0-merror:0.00000 validation_0-mlogloss:0.09605   validation_1-merror:0.14650 validation_1-mlogloss:0.50828\n[11]    validation_0-merror:0.00000 validation_0-mlogloss:0.07801   validation_1-merror:0.14437 validation_1-mlogloss:0.48943\n[12]    validation_0-merror:0.00000 validation_0-mlogloss:0.06405   validation_1-merror:0.14650 validation_1-mlogloss:0.47413\n[13]    validation_0-merror:0.00000 validation_0-mlogloss:0.05343   validation_1-merror:0.14225 validation_1-mlogloss:0.46252\n[14]    validation_0-merror:0.00000 validation_0-mlogloss:0.04508   validation_1-merror:0.14013 validation_1-mlogloss:0.45311\n[15]    validation_0-merror:0.00000 validation_0-mlogloss:0.03852   validation_1-merror:0.13376 validation_1-mlogloss:0.44334\n[16]    validation_0-merror:0.00000 validation_0-mlogloss:0.03314   validation_1-merror:0.13588 validation_1-mlogloss:0.43681\n[17]    validation_0-merror:0.00000 validation_0-mlogloss:0.02886   validation_1-merror:0.13376 validation_1-mlogloss:0.43222\n[18]    validation_0-merror:0.00000 validation_0-mlogloss:0.02532   validation_1-merror:0.13376 validation_1-mlogloss:0.42889\n[19]    validation_0-merror:0.00000 validation_0-mlogloss:0.02246   validation_1-merror:0.13376 validation_1-mlogloss:0.42132\n[20]    validation_0-merror:0.00000 validation_0-mlogloss:0.02018   validation_1-merror:0.13163 validation_1-mlogloss:0.42073\n[21]    validation_0-merror:0.00000 validation_0-mlogloss:0.01824   validation_1-merror:0.13800 validation_1-mlogloss:0.41866\n[22]    validation_0-merror:0.00000 validation_0-mlogloss:0.01658   validation_1-merror:0.13163 validation_1-mlogloss:0.41665\n[23]    validation_0-merror:0.00000 validation_0-mlogloss:0.01526   validation_1-merror:0.13376 validation_1-mlogloss:0.41581\n[24]    validation_0-merror:0.00000 validation_0-mlogloss:0.01408   validation_1-merror:0.13163 validation_1-mlogloss:0.41359\n[25]    validation_0-merror:0.00000 validation_0-mlogloss:0.01306   validation_1-merror:0.12739 validation_1-mlogloss:0.41323\n[26]    validation_0-merror:0.00000 validation_0-mlogloss:0.01218   validation_1-merror:0.13376 validation_1-mlogloss:0.41286\n[27]    validation_0-merror:0.00000 validation_0-mlogloss:0.01146   validation_1-merror:0.13163 validation_1-mlogloss:0.41128\n[28]    validation_0-merror:0.00000 validation_0-mlogloss:0.01085   validation_1-merror:0.13163 validation_1-mlogloss:0.41166\n[29]    validation_0-merror:0.00000 validation_0-mlogloss:0.01030   validation_1-merror:0.13163 validation_1-mlogloss:0.41150\n[30]    validation_0-merror:0.00000 validation_0-mlogloss:0.00985   validation_1-merror:0.13163 validation_1-mlogloss:0.41179\n[31]    validation_0-merror:0.00000 validation_0-mlogloss:0.00939   validation_1-merror:0.13376 validation_1-mlogloss:0.41202\n[32]    validation_0-merror:0.00000 validation_0-mlogloss:0.00902   validation_1-merror:0.13163 validation_1-mlogloss:0.41252\n[33]    validation_0-merror:0.00000 validation_0-mlogloss:0.00867   validation_1-merror:0.13376 validation_1-mlogloss:0.41329\n[34]    validation_0-merror:0.00000 validation_0-mlogloss:0.00837   validation_1-merror:0.13376 validation_1-mlogloss:0.41391\n[35]    validation_0-merror:0.00000 validation_0-mlogloss:0.00811   validation_1-merror:0.13588 validation_1-mlogloss:0.41318\n[36]    validation_0-merror:0.00000 validation_0-mlogloss:0.00786   validation_1-merror:0.13588 validation_1-mlogloss:0.41324\n[37]    validation_0-merror:0.00000 validation_0-mlogloss:0.00760   validation_1-merror:0.13588 validation_1-mlogloss:0.41341\n\n\n\n\n\n\n\n2.2 Comparison\n\n# XGBoost\nhuman_xg_scVI = xgb.XGBClassifier()\nhuman_xg_scVI.load_model(\"../results/02_human_integration/11_scVI_xgboost.json\")\n\n# scANVI\nhuman_scANVI = scvi.model.SCANVI.load(\"../results/02_human_integration/05_scanvi_ns15/\")\n\nINFO     File ../results/02_human_integration/05_scanvi_ns15/model.pt already downloaded                           \n\n\n\nhuman_stats = cripple_classifiers(human, human_scANVI, human_xg_scVI, groupby='C_scANVI_nsamples')\n\n  0%|                                                                                                              | 0/7 [00:00&lt;?, ?it/s]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 14%|                                                                                       | 1/7 [00:22&lt;02:13, 22.20s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 29%|                                                                        | 2/7 [00:46&lt;01:56, 23.34s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 43%|                                                          | 3/7 [01:10&lt;01:34, 23.63s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 57%|                                           | 4/7 [01:33&lt;01:10, 23.61s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 71%|                             | 5/7 [01:57&lt;00:47, 23.62s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n 86%|              | 6/7 [02:21&lt;00:23, 23.77s/it]GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n`Trainer.fit` stopped: `max_epochs=100` reached.\n100%|| 7/7 [02:44&lt;00:00, 23.53s/it]\n\n\nINFO     Found 100.0% reference vars in query data.                                                                \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 99.66666666666667% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 99.33333333333333% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 98.33333333333333% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 96.66666666666667% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 93.33333333333333% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nINFO     Found 83.33333333333334% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \n\n\n\nfig, ax = plt.subplots(2, 2, figsize=[10, 6], sharey=True, sharex=True)\n\npd.DataFrame.from_dict(mouse_stats['XGBoost']).plot.line(marker='x', ylim=(0,1), title='Mouse [XGBoost]', legend=None, ax=ax[0, 0])\npd.DataFrame.from_dict(mouse_stats['scANVI']).plot.line(marker='x', ylim=(0,1), title='Mouse [scANVI]', legend=None, ax=ax[0, 1])\npd.DataFrame.from_dict(human_stats['XGBoost']).plot.line(marker='x', ylim=(0,1), title='Human [XGBoost]', legend=None, ax=ax[1, 0])\npd.DataFrame.from_dict(human_stats['scANVI']).plot.line(marker='x', ylim=(0,1), title='Human [scANVI]', legend=None, ax=ax[1, 1])\n\nfor i in range(2):\n    ax[1, i].set_xticklabels(['', '0', '10', '20', '50', '100', '200', '500'])\n    ax[0, i].axhline(0.5, c='r', ls='--')\n    ax[1, i].axhline(0.5, c='r', ls='--')\n\nax[0, 1].legend(('Accuracy','Bal. accuracy', 'F1 (micro)', 'F1 (macro)'))\n\nfig.supxlabel('Number of dropouts')\nfig.supylabel('Score')\nfig.tight_layout()\nfig.savefig('../figures/xgboost_vs_scanvi_v1.svg')\n\n\n\n\n\nfig, ax = plt.subplots(1, 4, figsize=[14, 3.5], sharey=True, sharex=True)\n\npd.DataFrame.from_dict(mouse_stats['XGBoost']).plot.line(marker='x', ylim=(-0.1,1), title='Mouse [XGBoost]', legend=None, ax=ax[0])\npd.DataFrame.from_dict(mouse_stats['scANVI']).plot.line(marker='x', ylim=(-0.1,1), title='Mouse [scANVI]', legend=None, ax=ax[1])\npd.DataFrame.from_dict(human_stats['XGBoost']).plot.line(marker='x', ylim=(-0.1,1), title='Human [XGBoost]', legend=None, ax=ax[2])\npd.DataFrame.from_dict(human_stats['scANVI']).plot.line(marker='x', ylim=(-0.1,1), title='Human [scANVI]', legend=None, ax=ax[3])\n\nfor i in range(4):\n    ax[i].set_xticklabels(['', '0', '10', '20', '50', '100', '200', '500'])\n    ax[i].axhline(0.5, c='r', ls='--')\n\n# ax[3].legend(('Accuracy','Bal. accuracy', 'F1 (micro)', 'F1 (macro)'), ncol=4)\n\nfig.supxlabel('Number of dropouts')\nfig.supylabel('Score')\nfig.tight_layout()\nfig.savefig('../figures/xgboost_vs_scanvi_v2.svg')\n\n\n\n\n\npd.concat([\n    pd.DataFrame.from_dict(mouse_stats['XGBoost']).assign(clf = 'XGBoost').assign(species = 'mouse'),\n    pd.DataFrame.from_dict(mouse_stats['scANVI']).assign(clf = 'scANVI').assign(species = 'mouse'),\n    pd.DataFrame.from_dict(human_stats['XGBoost']).assign(clf = 'XGBoost').assign(species = 'human'),\n    pd.DataFrame.from_dict(human_stats['scANVI']).assign(clf = 'scANVI').assign(species = 'human')\n]).to_excel('../results/suppl-tab-3.xlsx')"
  },
  {
    "objectID": "notebooks/12_upload_models.html",
    "href": "notebooks/12_upload_models.html",
    "title": "Upload AI models",
    "section": "",
    "text": "# !pip install huggingface_hub\n\n\nDATASETS = [{\n    \"repo_name\": \"brickmanlab/mouse-scanvi\",\n    \"model_path\": \"../results/02_mouse_integration/scanvi_ns_15/\",\n    \"description\": \"Mouse scANVI reference model\",\n    \"references\": \"Proks, Salehin et al., biorXiv\",\n    \"training_data_url\": \"https://zenodo.org/records/10669600/files/01_mouse_reprocessed.h5ad?download=1\",\n    \"training_code_url\": \"https://github.com/brickmanlab/proks-salehin-et-al\",\n}, {\n    \"repo_name\": \"brickmanlab/human-scanvi\",\n    \"model_path\": \"../results/02_human_integration/05_scanvi_ns15/\",\n    \"description\": \"Human scANVI reference model\",\n    \"references\": \"Proks, Salehin et al., biorXiv\",\n    \"training_data_url\": \"https://zenodo.org/records/10669600/files/32_human_adata.h5ad?download=1\",\n    \"training_code_url\": \"https://github.com/brickmanlab/proks-salehin-et-al\",\n}]\n\n\nimport os\n\nimport anndata\nimport scanpy as sc\nimport scvi\nimport torch\nfrom scvi.hub import HubMetadata, HubModel, HubModelCardHelper\n\nscvi.settings.seed = 0\nprint(\"Last run with scvi-tools version:\", scvi.__version__)\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n  self.seed = seed\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.0.0/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n  self.dl_pin_memory_gpu_training = (\n[rank: 0] Global seed set to 0\n\n\nLast run with scvi-tools version: 1.0.0\n\n\n\ntry:\n    os.environ['HF_TOKEN']\nexcept:\n    print(\"Make sure you setup `HF_TOKEN` in shell !\")\n\n\nfor ds in DATASETS:\n    hm = HubMetadata.from_dir(ds['model_path'], anndata_version=anndata.__version__)\n    hmch = HubModelCardHelper.from_dir(\n        ds['model_path'],\n        license_info=\"cc-by-4.0\",\n        anndata_version=anndata.__version__,\n        data_modalities=[\"rna\"],\n        data_is_annotated=True,\n        description=ds['description'],\n        references=ds['references'],\n        model_parent_module=ds['training_data_url'],\n        training_data_url=ds['training_code_url']\n    )\n    hmo = HubModel(ds['model_path'], metadata=hm, model_card=hmch)\n\n    hmo.push_to_huggingface_hub(\n        repo_name=ds['repo_name'], repo_token=os.environ['HF_TOKEN'], repo_create=True\n    )\n\nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded                             \nINFO     File ../results/02_mouse_integration/scanvi_ns_15/model.pt already downloaded                             \nINFO     File ../results/02_human_integration/05_scanvi_ns15/model.pt already downloaded                           \nINFO     File ../results/02_human_integration/05_scanvi_ns15/model.pt already downloaded"
  }
]